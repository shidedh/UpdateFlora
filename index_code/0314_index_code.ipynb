{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_path = '../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 1.pdf'\n",
    "vol2_path = '../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 2.pdf'\n",
    "vol3_path = '../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 3.pdf'\n",
    "\n",
    "vol1_doc = fitz.open(vol1_path)\n",
    "vol2_doc = fitz.open(vol2_path)\n",
    "vol3_doc = fitz.open(vol3_path)\n",
    "\n",
    "vol1_pages = [vol1_doc[i] for i in range(vol1_doc.page_count)]\n",
    "vol2_pages = [vol2_doc[i] for i in range(vol2_doc.page_count)]\n",
    "vol3_pages = [vol3_doc[i] for i in range(vol3_doc.page_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_char_df = pd.read_pickle(\"../input/char_df/vol1_df.pkl\")\n",
    "vol2_char_df = pd.read_pickle(\"../input/char_df/vol2_df.pkl\")\n",
    "vol3_char_df = pd.read_pickle(\"../input/char_df/vol3_df.pkl\")\n",
    "\n",
    "vol1_index = list(range(616, 639)) #inclusive\n",
    "vol2_index = list(range(703, 725))\n",
    "vol3_index = list(range(555, 583))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DPI = 300\n",
    "mat = fitz.Matrix(TARGET_DPI/ 72, TARGET_DPI/ 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding the columns \n",
    "### & checking if a word is a strict match for the genus / epithet pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epithet_match(row):\n",
    "    return row['word_num'] == 0 and \\\n",
    "           row['word'].isalpha() and \\\n",
    "           row['word'].islower()\n",
    "\n",
    "def genus_match(row):\n",
    "    return row['word_num'] == 0 and \\\n",
    "           row['word'].isalpha() and \\\n",
    "           row['word'][0].isupper() and row['word'][1:].islower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:13<00:00,  1.72it/s]\n",
      "100%|██████████| 22/22 [00:14<00:00,  1.56it/s]\n",
      "100%|██████████| 28/28 [00:14<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "#rightmost point of any bounding box:\n",
    "def get_center_x0(vol_char_df, page_num, bias = 30):\n",
    "    \"\"\"WARNING: large bias causes miscatagorization in page number in book\"\"\"\n",
    "    df = vol_char_df[vol_char_df['page_num'] == page_num]\n",
    "    \n",
    "    right_bound = df['line_bbox'].apply(lambda x : x[2]).max() \n",
    "    #leftmost point of any bounding box:\n",
    "    left_bound = df['line_bbox'].apply(lambda x : x[0]).min()\n",
    "\n",
    "    return 0.5*(right_bound + left_bound) - bias\n",
    "\n",
    "\n",
    "def get_col_num(coords, center_x0):\n",
    "    x0, y0, x1, y1 = coords\n",
    "    return int(x0 >= center_x0)\n",
    "\n",
    "\n",
    "all_vol_data = [(vol1_char_df, vol1_index, vol1_doc),\n",
    "                (vol2_char_df, vol2_index, vol2_doc),\n",
    "                (vol3_char_df, vol3_index, vol3_doc)]\n",
    "\n",
    "for vol_char_df ,vol_index, doc in all_vol_data: \n",
    "    #for each volume check if genus pattern / epithet pattern exists within the index part of the book\n",
    "    vol_char_df['genus_index_pat_match'] = vol_char_df.apply(lambda r : r['page_num'] in vol_index and genus_match(r), axis = 1) #does this for whole books which is bad\n",
    "    vol_char_df['epithet_index_pat_match'] = vol_char_df.apply(lambda r : r['page_num'] in vol_index and epithet_match(r), axis = 1) #does this for whole books which is bad\n",
    "    \n",
    "    for page_num in tqdm(vol_index):\n",
    "        center_x0 = get_center_x0(vol_char_df, page_num)\n",
    "        #find center based on x0 coordinate of each line\n",
    "        vol_char_df['col_num'] = vol_char_df['line_bbox'].apply(lambda coords : get_col_num(coords, center_x0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing if col num correctly assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  5.58it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  5.59it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  5.87it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data = [(vol1_char_df, vol1_index, vol1_doc, \"index_col_vol1\"),\n",
    "                (vol2_char_df, vol2_index, vol2_doc, \"index_col_vol2\"),\n",
    "                (vol3_char_df, vol3_index, vol3_doc, \"index_col_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, vol_doc, output_name in all_vol_data:\n",
    "    image_list = []\n",
    "    keep_cols = vol_char_df.columns.difference([\"char_num\", \"char\", \"char_origin\", \"char_bbox\", \"char_x0\", \"char_y0\", \"char_x1\", \"char_y1\", \"pruned_char_x0\", \"pruned_char_y0\", \"pruned_char_x1\", \"pruned_char_y1\"], sort=False).tolist()\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = vol_doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        temp_df = vol_char_df[vol_char_df[\"page_num\"] == page_num].loc[:, keep_cols].drop_duplicates()\n",
    "\n",
    "        for coord in temp_df[temp_df['col_num'] == 0]['line_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "\n",
    "        for coord in temp_df[temp_df['col_num'] == 1]['line_bbox']:\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=5)\n",
    "            \n",
    "        image_list.append(image)\n",
    "        #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genus / epithet flagging \n",
    "flagging pages where number of strict genus or epithet patern matches is less than 3 per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 82.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***FLAGS***\n",
      " number of pages to check: 4\n",
      "  genera\n",
      "\t number of genera: 1, page number: 2, column number: 0\n",
      "\t number of genera: 2, page number: 15, column number: 1\n",
      "\t number of genera: 0, page number: 20, column number: 1\n",
      "\t number of genera: 1, page number: 23, column number: 0\n",
      "  epithets\n",
      "\t number of epithets: 2, page number: 23, column number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 78.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***FLAGS***\n",
      " number of pages to check: 4\n",
      "  genera\n",
      "\t number of genera: 2, page number: 4, column number: 0\n",
      "\t number of genera: 1, page number: 4, column number: 1\n",
      "\t number of genera: 0, page number: 5, column number: 0\n",
      "\t number of genera: 1, page number: 12, column number: 0\n",
      "\t number of genera: 2, page number: 14, column number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 90.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***FLAGS***\n",
      " number of pages to check: 7\n",
      "  genera\n",
      "\t number of genera: 1, page number: 2, column number: 1\n",
      "\t number of genera: 0, page number: 6, column number: 0\n",
      "\t number of genera: 1, page number: 21, column number: 0\n",
      "\t number of genera: 1, page number: 22, column number: 0\n",
      "\t number of genera: 2, page number: 24, column number: 1\n",
      "\t number of genera: 2, page number: 26, column number: 0\n",
      "\t number of genera: 0, page number: 26, column number: 1\n",
      "\t number of genera: 2, page number: 28, column number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_vol_data = [(vol1_char_df, vol1_index, vol1_doc, \"strickt_match_vol1\"),\n",
    "                (vol2_char_df, vol2_index, vol2_doc, \"strickt_match_vol2\"),\n",
    "                (vol3_char_df, vol3_index, vol3_doc, \"strickt_match_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "    genus_flag_list = []\n",
    "    epithet_flag_list = []\n",
    "    for page_num in tqdm(vol_index):\n",
    "        genus_db = vol_char_df[(vol_char_df['page_num'] == page_num)\n",
    "                                & (vol_char_df['genus_index_pat_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['epithet_index_pat_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #genus pattern match flag should check with half page and not entire page:\n",
    "        for col in range(2):\n",
    "            num_genus_col = genus_db[genus_db[\"col_num\"] == col].shape[0]\n",
    "            num_epithet_col = epithet_db[epithet_db[\"col_num\"] == col].shape[0]\n",
    "            if num_genus_col <= 2:\n",
    "                genus_flag_list.append((num_genus_col, page_num - vol_index[0] + 1, col))\n",
    "            if num_epithet_col <= 2:\n",
    "                epithet_flag_list.append((num_epithet_col, page_num - vol_index[0] + 1, col))\n",
    "    num_flag_pages = len(set([g[1] for g in genus_flag_list] + [e[1] for e in epithet_flag_list]))\n",
    "    if num_flag_pages > 0: \n",
    "        print(\"***FLAGS***\")\n",
    "        print(f\" number of pages to check: {num_flag_pages}\")\n",
    "        if genus_flag_list:\n",
    "            print(\"  genera\")\n",
    "            [print(f\"\\t number of genera: {g_flag[0]}, page number: {g_flag[1]}, column number: {g_flag[2]}\") for g_flag in genus_flag_list]\n",
    "        if epithet_flag_list:\n",
    "            print(\"  epithets\")\n",
    "            [print(f\"\\t number of epithets: {e_flag[0]}, page number: {e_flag[1]}, column number: {e_flag[2]}\") for e_flag in epithet_flag_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### match  based on coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_coord_match(x, x_ref_left, x_ref_right, margin):\n",
    "    return (x_ref_left - margin <= x[0] and x[0] <= x_ref_left + margin) or (x_ref_right - margin <= x[0] and x[0] <= x_ref_right + margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### epithet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 22.33it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 21.02it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 23.81it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data = [(vol1_char_df, vol1_index),\n",
    "                (vol2_char_df, vol2_index),\n",
    "                (vol3_char_df, vol3_index)]\n",
    "\n",
    "for vol_char_df, vol_index in all_vol_data: \n",
    "    vol_char_df[\"epithet_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"epithet_index_pat_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        epithet_char_df = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"epithet_index_pat_match\"] == True)]\n",
    "        epithet_df = epithet_char_df.loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"])].drop_duplicates()\n",
    "        page_epithet_2dic = [{}, {}]\n",
    "        \n",
    "        for i in range(epithet_df.shape[0]):\n",
    "            e_index = str(page_num) + \"_\" + str(i)\n",
    "            p0 = epithet_df['word_bbox'].iloc[i]\n",
    "            x_ref = p0[0]\n",
    "            col = epithet_df['col_num'].iloc[i]\n",
    "\n",
    "            ref_neighbors_df = epithet_df[(epithet_df[\"page_num\"] == page_num) & \n",
    "                                          (epithet_df[\"word_bbox\"].apply(lambda x : x_ref - margin <= x[0] and x[0] <= x_ref + margin))]\n",
    "            \n",
    "            num_neighbors = ref_neighbors_df.shape[0]\n",
    "            mean_neighbors = ref_neighbors_df[\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            page_epithet_2dic[col][e_index] = (num_neighbors, mean_neighbors)\n",
    "        \n",
    "        mean_left_epithet = max(page_epithet_2dic[0].values(), default = [-1, -1])[1]\n",
    "        mean_right_epithet = max(page_epithet_2dic[1].values(), default = [-1, -1])[1]\n",
    "\n",
    "        if mean_left_epithet == -1 or mean_right_epithet == -1:\n",
    "            mean_valid_col = max(mean_left_epithet, mean_right_epithet)\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"epithet_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_valid_col, mean_valid_col, margin))\n",
    "        elif mean_left_epithet == -1 and mean_right_epithet == -1:\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"epithet_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : False)\n",
    "        else: \n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"epithet_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_left_epithet, mean_right_epithet, margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  5.60it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  5.66it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  5.89it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data = [(vol1_char_df, vol1_index, vol1_doc, \"epithet_coord_match_pruned_vol1\"),\n",
    "                (vol2_char_df, vol2_index, vol2_doc, \"epithet_coord_match_pruned_vol2\"),\n",
    "                (vol3_char_df, vol3_index, vol3_doc, \"epithet_coord_match_pruned_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "    \n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        epithet_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['epithet_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['epithet_index_pat_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #epithet Coord is orange-pinkish, 5\n",
    "        for coord in epithet_coord_db[\"pruned_word_bbox\"] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "\n",
    "        #epithet is blue, 3\n",
    "        for coord in epithet_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=3)\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genus coord match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add something about genus should come before epithet? \n",
    "    # assert df[df['epithet_coord_match'] == True]['word_bbox'].apply(lambda x: x[0]).mean() \n",
    "    #     >  df[df['genus_coord_match'] == True]['word_bbox'].apply(lambda x: x[0]).mean() \n",
    "    # and if False it shouldn't be a genus_coord?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 53.94it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 49.46it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 57.37it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data = [(vol1_char_df, vol1_index),\n",
    "                (vol2_char_df, vol2_index),\n",
    "                (vol3_char_df, vol3_index)]\n",
    "\n",
    "for vol_char_df, vol_index in all_vol_data: \n",
    "    #genus and not epithet\n",
    "    vol_char_df[\"genus_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"genus_index_pat_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        genus_char_df = vol_char_df[(vol_char_df[\"page_num\"] == page_num) &\n",
    "                                    (vol_char_df[\"genus_index_pat_match\"] == True)]\n",
    "        genus_df = genus_char_df.loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"])].drop_duplicates()\n",
    "        page_genus_2dic = [{}, {}]\n",
    "        \n",
    "        for i in range(genus_df.shape[0]):\n",
    "            g_index = str(page_num) + \"_\" + str(i)\n",
    "            p0 = genus_df['word_bbox'].iloc[i]\n",
    "            x_ref = p0[0]\n",
    "            col = genus_df['col_num'].iloc[i]\n",
    "\n",
    "            ref_neighbors_df = genus_df[(genus_df[\"page_num\"] == page_num) & \n",
    "                                        (genus_df[\"word_bbox\"].apply(lambda x : x_ref - margin <= x[0] and x[0] <= x_ref + margin))]\n",
    "\n",
    "            num_neighbors = ref_neighbors_df.shape[0]\n",
    "            mean_neighbors = ref_neighbors_df[\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            page_genus_2dic[col][g_index] = (num_neighbors, mean_neighbors)\n",
    "        \n",
    "        mean_left_genus = max(page_genus_2dic[0].values(), default = [-1, -1])[1]\n",
    "        mean_right_genus = max(page_genus_2dic[1].values(), default = [-1, -1])[1]\n",
    "\n",
    "        if mean_left_genus == -1 or mean_right_genus == -1:\n",
    "            mean_valid_col = max(mean_left_genus, mean_right_genus)\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"genus_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_valid_col, mean_valid_col, margin))\n",
    "        elif mean_left_genus == -1 and mean_right_genus == -1:\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"genus_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : False)\n",
    "        else: \n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"genus_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_left_genus, mean_right_genus, margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  5.63it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  5.56it/s]\n",
      "  7%|▋         | 2/28 [00:00<00:04,  5.92it/s]"
     ]
    }
   ],
   "source": [
    "all_vol_data = [(vol1_char_df, vol1_index, vol1_doc, \"genus_coord_match_vol1\"),\n",
    "                (vol2_char_df, vol2_index, vol2_doc, \"genus_coord_match_vol2\"),\n",
    "                (vol3_char_df, vol3_index, vol3_doc, \"genus_coord_match_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "\n",
    "        genus_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['genus_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['epithet_coord_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in genus_coord_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # #epithet is red, 3\n",
    "        for coord in epithet_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#000099\"), width=3)\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add column for genus / epithet coord mean for each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vol_data = [(vol1_char_df, vol1_index),\n",
    "                (vol2_char_df, vol2_index),\n",
    "                (vol3_char_df, vol3_index)]\n",
    "for vol_char_df, vol_index in all_vol_data:\n",
    "    for page_num in vol_index:\n",
    "        for c_i in [0, 1]:\n",
    "            genus_mean_coord = vol_char_df[(vol_char_df['page_num'] == page_num) & (vol_char_df['genus_coord_match'] == True) & (vol_char_df['col_num'] == c_i)]['word_bbox'].apply(lambda x: x[0]).mean()\n",
    "            epithet_mean_coord = vol_char_df[(vol_char_df['page_num'] == page_num) & (vol_char_df['epithet_coord_match'] == True) & (vol_char_df['col_num'] == c_i)]['word_bbox'].apply(lambda x: x[0]).mean()\n",
    "        \n",
    "            #doing this because you can have no genus in one page but not no genus but an epithet...\n",
    "            if np.isnan(genus_mean_coord):\n",
    "                genus_mean_coord == 0\n",
    "            if np.isnan(epithet_mean_coord):\n",
    "                epithet_mean_coord = 1\n",
    "\n",
    "            vol_char_df.loc[(vol_char_df['page_num'] == page_num) & (vol_char_df['col_num'] == c_i), 'genus_mean_coord'] = genus_mean_coord\n",
    "            vol_char_df.loc[(vol_char_df['page_num'] == page_num) & (vol_char_df['col_num'] == c_i), 'epithet_mean_coord'] = epithet_mean_coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract potential genus / epithet matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_genus_match(row):\n",
    "    return row['genus_coord_match'] == True and \\\n",
    "           row['epithet_coord_match'] == False and \\\n",
    "           row['word'].isupper() == False and \\\n",
    "           row['word'].isnumeric() == False and \\\n",
    "           row['word'].find(\"Flore\") == -1 and \\\n",
    "           row['genus_mean_coord'] < row['epithet_mean_coord'] #important to check this only when epithet_coord_match is false?\n",
    "\n",
    "def potential_epithet_match(row):\n",
    "    return row['epithet_coord_match'] == True and \\\n",
    "           row['word'].isnumeric() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_char_df['potential_genus_match'] = vol1_char_df.apply(potential_genus_match, axis = 1)\n",
    "vol1_char_df['potential_epithet_match'] = vol1_char_df.apply(potential_epithet_match, axis = 1)\n",
    "\n",
    "vol2_char_df['potential_genus_match'] = vol2_char_df.apply(potential_genus_match, axis = 1)\n",
    "vol2_char_df['potential_epithet_match'] = vol2_char_df.apply(potential_epithet_match, axis = 1)\n",
    "\n",
    "vol3_char_df['potential_genus_match'] = vol3_char_df.apply(potential_genus_match, axis = 1)\n",
    "vol3_char_df['potential_epithet_match'] = vol3_char_df.apply(potential_epithet_match, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  5.54it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  5.62it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  5.88it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data = [(vol1_char_df, vol1_index, vol1_doc, \"GE_potential_match_vol1\"),\n",
    "                (vol2_char_df, vol2_index, vol2_doc, \"GE_potential_match_vol2\"),\n",
    "                (vol3_char_df, vol3_index, vol3_doc, \"GE_potential_match_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "\n",
    "        genus_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['potential_genus_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['potential_epithet_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in genus_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # #epithet is red, 3\n",
    "        for coord in epithet_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#000099\"), width=3)\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### infra species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 18.72it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 18.23it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 20.92it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data = [(vol1_char_df, vol1_index),\n",
    "                (vol2_char_df, vol2_index),\n",
    "                (vol3_char_df, vol3_index)]\n",
    "\n",
    "for vol_char_df, vol_index in all_vol_data: \n",
    "    vol_char_df[\"infra_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"epithet_coord_match\"] == True) | (vol_char_df[\"genus_coord_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        \n",
    "        mean_left_epithet = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"epithet_coord_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        mean_left_genus = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"genus_coord_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        if math.isnan(mean_left_genus):\n",
    "            mean_left_genus_all = vol_char_df[(vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"genus_coord_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_left_epithet_all = vol_char_df[(vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"epithet_coord_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_left_tab = mean_left_epithet_all - mean_left_genus_all\n",
    "        else: \n",
    "            mean_left_tab = mean_left_epithet - mean_left_genus\n",
    "        \n",
    "        mean_right_epithet = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"epithet_coord_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        mean_right_genus = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"genus_coord_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        if math.isnan(mean_right_genus):\n",
    "            mean_right_genus_all = vol_char_df[(vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"genus_coord_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_right_epithet_all = vol_char_df[(vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"epithet_coord_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_right_tab = mean_right_epithet_all - mean_right_genus_all\n",
    "        else: \n",
    "            mean_right_tab = mean_right_epithet - mean_right_genus\n",
    "\n",
    "        vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"word_num\"] == 0)  , \"infra_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"word_num\"] == 0)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_left_epithet + mean_left_tab, mean_right_epithet + mean_right_tab, margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 19.55it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 18.09it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 20.81it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data = [(vol1_char_df, vol1_index),\n",
    "                (vol2_char_df, vol2_index),\n",
    "                (vol3_char_df, vol3_index)]\n",
    "\n",
    "for vol_char_df, vol_index in all_vol_data: \n",
    "    vol_char_df[\"infra_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"potential_epithet_match\"] == True) | (vol_char_df[\"potential_genus_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        \n",
    "        mean_left_epithet = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        mean_left_genus = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        if math.isnan(mean_left_genus):\n",
    "            mean_left_genus_all = vol_char_df[(vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_left_epithet_all = vol_char_df[(vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_left_tab = mean_left_epithet_all - mean_left_genus_all\n",
    "        else: \n",
    "            mean_left_tab = mean_left_epithet - mean_left_genus\n",
    "        \n",
    "        mean_right_epithet = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        mean_right_genus = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        if math.isnan(mean_right_genus):\n",
    "            mean_right_genus_all = vol_char_df[(vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_right_epithet_all = vol_char_df[(vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_right_tab = mean_right_epithet_all - mean_right_genus_all\n",
    "        else: \n",
    "            mean_right_tab = mean_right_epithet - mean_right_genus\n",
    "\n",
    "\n",
    "        vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"word_num\"] == 0)  , \"infra_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"word_num\"] == 0)][\"word_bbox\"].apply(lambda x : is_coord_match(x, mean_left_epithet + mean_left_tab, mean_right_epithet + mean_right_tab, margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_author_match_infra_coord(word):\n",
    "    lower_word = word.lower()\n",
    "    latin_connectives = r\"^\\s?et[\\s|.]?$|^\\s?in[\\s|.]?$|^\\s?non[\\s|.]?$|^\\s?&[\\s|.]?$|^\\s?er[\\s|.]?$|^\\s?nec[\\s|.]?$|^\\s?mult[\\s|.]?$|^\\s?ex[\\s|.]?$|^\\s?fil[\\s|.]?$\"\n",
    "    infra_symbols = r\"^var[\\s|.|\\b]?$|^subsp[\\s|.|\\b]?$|^ssp[\\s|.|\\b]?$|^spp[\\s|.|\\b]?$|^x[\\s|.|\\b]?$|^×[\\s|.|\\b]?$\"\n",
    "    is_latin_connectives = re.search(latin_connectives, word) != None\n",
    "    is_infra_symbol = re.search(infra_symbols, lower_word) != None\n",
    "    return (not is_infra_symbol) and (word[0].isupper() or is_latin_connectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potential_author_match_infra_coord(\"fil.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vol_data = [(vol1_char_df, vol1_index),\n",
    "                (vol2_char_df, vol2_index),\n",
    "                (vol3_char_df, vol3_index)]\n",
    "for vol_char_df, _ in all_vol_data:\n",
    "    vol_char_df[\"potential_infra_match\"] = (vol_char_df[\"infra_coord_match\"] == True) & (vol_char_df['word'].apply(potential_author_match_infra_coord) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_infra_symbols(word):\n",
    "    infra_symbols = r\"^var[\\s|.|\\b]?$|^subsp[\\s|.|\\b]?$|^ssp[\\s|.|\\b]?$|^spp[\\s|.|\\b]?$|^x[\\s|.|\\b]?$|^×[\\s|.|\\b]?$\"\n",
    "    return re.search(infra_symbols, word) != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:25<00:00,  1.11it/s]\n",
      "100%|██████████| 22/22 [00:23<00:00,  1.06s/it]\n",
      "100%|██████████| 23/23 [00:22<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data = [(vol1_char_df, vol1_index, vol1_doc, \"potential_infra_match_vol1\"),\n",
    "                (vol2_char_df, vol2_index, vol2_doc, \"potential_infra_match_vol2\"),\n",
    "                (vol3_char_df, vol3_index, vol3_doc, \"potential_infra_match_vol3\")][::-1]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "\n",
    "        infra_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['infra_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        infra_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['potential_infra_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        with_infra_symbols = vol_char_df[(vol_char_df['page_num'] == page_num) &\n",
    "                                         (vol_char_df['infra_coord_match'] == True) & \n",
    "                                         (vol_char_df['word'].apply(has_infra_symbols) == True)\n",
    "                                        ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                        ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in infra_coord_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0-5, y0-5, x1+5, y1+5), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=7)\n",
    "\n",
    "        for coord in infra_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0-3, y0-3, x1+3, y1+3), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # #epithet is red, 3\n",
    "        for coord in with_infra_symbols['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#990000\"), width=3)\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions for author matching \n",
    "to detect anamolies in epithet and infra indentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_char_df['index_page_num'] = vol1_char_df['page_num'] - vol1_index[0] + 1\n",
    "vol2_char_df['index_page_num'] = vol2_char_df['page_num'] - vol2_index[0] + 1\n",
    "vol3_char_df['index_page_num'] = vol3_char_df['page_num'] - vol3_index[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_page_num, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_infra_match'] == True) & (vol1_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_page_num, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_infra_match'] == True) & (vol2_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1559345</th>\n",
       "      <td>3</td>\n",
       "      <td>(3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559874</th>\n",
       "      <td>3</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561502</th>\n",
       "      <td>4</td>\n",
       "      <td>fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566359</th>\n",
       "      <td>6</td>\n",
       "      <td>deris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570483</th>\n",
       "      <td>8</td>\n",
       "      <td>cock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576678</th>\n",
       "      <td>11</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578491</th>\n",
       "      <td>12</td>\n",
       "      <td>picha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581443</th>\n",
       "      <td>13</td>\n",
       "      <td>adoxifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582167</th>\n",
       "      <td>14</td>\n",
       "      <td>fil.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584378</th>\n",
       "      <td>15</td>\n",
       "      <td>yar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587338</th>\n",
       "      <td>16</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589927</th>\n",
       "      <td>17</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592932</th>\n",
       "      <td>19</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594835</th>\n",
       "      <td>20</td>\n",
       "      <td>turcicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596384</th>\n",
       "      <td>20</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598587</th>\n",
       "      <td>22</td>\n",
       "      <td>berlain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num         word\n",
       "1559345               3           (3\n",
       "1559874               3           f.\n",
       "1561502               4           fa\n",
       "1566359               6       deris \n",
       "1570483               8         cock\n",
       "1576678              11           f.\n",
       "1578491              12       picha \n",
       "1581443              13  adoxifolium\n",
       "1582167              14        fil. \n",
       "1584378              15         yar.\n",
       "1587338              16           f.\n",
       "1589927              17           f.\n",
       "1592932              19           f.\n",
       "1594835              20     turcicus\n",
       "1596384              20            y\n",
       "1598587              22      berlain"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_infra_match'] == True) & (vol3_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upper case beggining / latin words in epithet coordd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_author_match_epithet_coord(word):\n",
    "    latin_connectives = r\"^\\s?et[\\s|.]?$|^\\s?in[\\s|.]?$|^\\s?non[\\s|.]?$|^\\s?&[\\s|.]?$|^\\s?er[\\s|.]?$|^\\s?nec[\\s|.]?$|^\\s?mult[\\s|.]?$|^\\s?ex[\\s|.]?$|^\\s?fil[\\s|.]?$|^\\s?f[\\s|.]?$\"\n",
    "    is_latin_connectives = re.search(latin_connectives, word) != None\n",
    "    is_hybrid = word == \"X\"\n",
    "    return is_latin_connectives or (word[0].isupper() and (not is_hybrid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1734317</th>\n",
       "      <td>9</td>\n",
       "      <td>J.d,IlLIlU.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753028</th>\n",
       "      <td>18</td>\n",
       "      <td>Phoenicia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753527</th>\n",
       "      <td>18</td>\n",
       "      <td>Syriacus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755122</th>\n",
       "      <td>19</td>\n",
       "      <td>Jilicaulis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num         word\n",
       "1734317               9  J.d,IlLIlU.\n",
       "1753028              18    Phoenicia\n",
       "1753527              18     Syriacus\n",
       "1755122              19   Jilicaulis"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_epithet_match'] == True) & (vol1_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1915513</th>\n",
       "      <td>4</td>\n",
       "      <td>Hbanoticus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922530</th>\n",
       "      <td>8</td>\n",
       "      <td>Hppii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937158</th>\n",
       "      <td>14</td>\n",
       "      <td>Ma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num        word\n",
       "1915513               4  Hbanoticus\n",
       "1922530               8       Hppii\n",
       "1937158              14          Ma"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_epithet_match'] == True) & (vol2_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1554632</th>\n",
       "      <td>1</td>\n",
       "      <td>Krascheninnikovii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565497</th>\n",
       "      <td>6</td>\n",
       "      <td>Wagenitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566524</th>\n",
       "      <td>6</td>\n",
       "      <td>Fritsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575185</th>\n",
       "      <td>10</td>\n",
       "      <td>Holub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575488</th>\n",
       "      <td>11</td>\n",
       "      <td>Holub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577207</th>\n",
       "      <td>11</td>\n",
       "      <td>et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578956</th>\n",
       "      <td>12</td>\n",
       "      <td>Eichwaldii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579044</th>\n",
       "      <td>12</td>\n",
       "      <td>Schrank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582101</th>\n",
       "      <td>14</td>\n",
       "      <td>Kuntze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583001</th>\n",
       "      <td>14</td>\n",
       "      <td>Kuntze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584639</th>\n",
       "      <td>15</td>\n",
       "      <td>Majoranamaracus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586349</th>\n",
       "      <td>16</td>\n",
       "      <td>Schiman-Czeika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586394</th>\n",
       "      <td>16</td>\n",
       "      <td>Czeika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592464</th>\n",
       "      <td>19</td>\n",
       "      <td>Berth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603606</th>\n",
       "      <td>24</td>\n",
       "      <td>DOteriifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608442</th>\n",
       "      <td>26</td>\n",
       "      <td>Turra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609136</th>\n",
       "      <td>26</td>\n",
       "      <td>Moretti,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610970</th>\n",
       "      <td>27</td>\n",
       "      <td>Fischer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611185</th>\n",
       "      <td>27</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num               word\n",
       "1554632               1  Krascheninnikovii\n",
       "1565497               6          Wagenitz \n",
       "1566524               6           Fritsch \n",
       "1575185              10              Holub\n",
       "1575488              11             Holub \n",
       "1577207              11                 et\n",
       "1578956              12         Eichwaldii\n",
       "1579044              12           Schrank \n",
       "1582101              14            Kuntze \n",
       "1583001              14             Kuntze\n",
       "1584639              15    Majoranamaracus\n",
       "1586349              16     Schiman-Czeika\n",
       "1586394              16             Czeika\n",
       "1592464              19             Berth.\n",
       "1603606              24      DOteriifolium\n",
       "1608442              26             Turra \n",
       "1609136              26           Moretti,\n",
       "1610970              27           Fischer \n",
       "1611185              27                non"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_epithet_match'] == True) & (vol3_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### epithet coord word has uppper case in the middle (but not the first letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_upper_not_first(word):\n",
    "    return word[1:].lower() != word[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1716055</th>\n",
       "      <td>1</td>\n",
       "      <td>peregrina(Hack.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716156</th>\n",
       "      <td>1</td>\n",
       "      <td>umbeUulata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734317</th>\n",
       "      <td>9</td>\n",
       "      <td>J.d,IlLIlU.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734633</th>\n",
       "      <td>9</td>\n",
       "      <td>elatior'L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736494</th>\n",
       "      <td>10</td>\n",
       "      <td>sessUis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737303</th>\n",
       "      <td>11</td>\n",
       "      <td>pilosaHuds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741588</th>\n",
       "      <td>13</td>\n",
       "      <td>phleoides^Vill.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747388</th>\n",
       "      <td>15</td>\n",
       "      <td>albaL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752078</th>\n",
       "      <td>18</td>\n",
       "      <td>aegUops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752829</th>\n",
       "      <td>18</td>\n",
       "      <td>glaucaVahl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761043</th>\n",
       "      <td>22</td>\n",
       "      <td>auCheriana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num              word\n",
       "1716055               1  peregrina(Hack.)\n",
       "1716156               1        umbeUulata\n",
       "1734317               9       J.d,IlLIlU.\n",
       "1734633               9        elatior'L.\n",
       "1736494              10           sessUis\n",
       "1737303              11       pilosaHuds.\n",
       "1741588              13  phleoides^Vill.)\n",
       "1747388              15            albaL.\n",
       "1752078              18           aegUops\n",
       "1752829              18        glaucaVahl\n",
       "1761043              22        auCheriana"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_epithet_match'] == True) & (vol1_char_df['word'].apply(has_upper_not_first))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1914061</th>\n",
       "      <td>4</td>\n",
       "      <td>corîdûpUcaÈu^Sretoï.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917935</th>\n",
       "      <td>6</td>\n",
       "      <td>securidacaiÇL.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941855</th>\n",
       "      <td>17</td>\n",
       "      <td>corymbulosum(Planch.)Reichenb.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953489</th>\n",
       "      <td>22</td>\n",
       "      <td>aqUatilis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num                            word\n",
       "1914061               4            corîdûpUcaÈu^Sretoï.\n",
       "1917935               6                 securidacaiÇL.)\n",
       "1941855              17  corymbulosum(Planch.)Reichenb.\n",
       "1953489              22                       aqUatilis"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_epithet_match'] == True) & (vol2_char_df['word'].apply(has_upper_not_first))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1568523</th>\n",
       "      <td>7</td>\n",
       "      <td>gaiUardotii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579879</th>\n",
       "      <td>13</td>\n",
       "      <td>albu^L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585656</th>\n",
       "      <td>15</td>\n",
       "      <td>sieberiC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586349</th>\n",
       "      <td>16</td>\n",
       "      <td>Schiman-Czeika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597633</th>\n",
       "      <td>21</td>\n",
       "      <td>desertiTUéh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603606</th>\n",
       "      <td>24</td>\n",
       "      <td>DOteriifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608206</th>\n",
       "      <td>26</td>\n",
       "      <td>agMmoniifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612787</th>\n",
       "      <td>28</td>\n",
       "      <td>'Abd-el-'asissi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num             word\n",
       "1568523               7      gaiUardotii\n",
       "1579879              13          albu^L.\n",
       "1585656              15        sieberiC.\n",
       "1586349              16   Schiman-Czeika\n",
       "1597633              21     desertiTUéh.\n",
       "1603606              24    DOteriifolium\n",
       "1608206              26   agMmoniifolium\n",
       "1612787              28  'Abd-el-'asissi"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_epithet_match'] == True) & (vol3_char_df['word'].apply(has_upper_not_first))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "potential genus match but name is not alphabetic or is of length < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_genus_name(word):\n",
    "    word_no_space = word.replace(\" \", \"\")\n",
    "    return ((not word_no_space.isalpha()) or (len(word_no_space) < 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1730943</th>\n",
       "      <td>8</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738656</th>\n",
       "      <td>11</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num word\n",
       "1730943               8    c\n",
       "1738656              11    f"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921256</th>\n",
       "      <td>7</td>\n",
       "      <td>•Ceratophyllum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921779</th>\n",
       "      <td>7</td>\n",
       "      <td>Chelidonium^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939484</th>\n",
       "      <td>16</td>\n",
       "      <td>Jussiaea-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939606</th>\n",
       "      <td>16</td>\n",
       "      <td>VV.1l.*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num            word\n",
       "1921256               7  •Ceratophyllum\n",
       "1921779               7    Chelidonium^\n",
       "1939484              16       Jussiaea-\n",
       "1939606              16         VV.1l.*"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_genus_match'] == True) & (vol2_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1559728</th>\n",
       "      <td>3</td>\n",
       "      <td>BallotaL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584638</th>\n",
       "      <td>15</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num        word\n",
       "1559728               3  BallotaL. \n",
       "1584638              15           x"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_genus_match'] == True) & (vol3_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flag if we had 2 genus in the same line or 1 or more genus + 1 or more epithet on the same line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doesn't pick up all the issues because sometimes when the space if large enough \n",
    "# it thinks we're on a \"new line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>block_num</th>\n",
       "      <th>line_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1762657</th>\n",
       "      <td>638</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>Zea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762660</th>\n",
       "      <td>638</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>mays</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         page_num  block_num  line_num  word\n",
       "1762657       638         19         0   Zea\n",
       "1762660       638         19         0  mays"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_groups = [c for c in vol1_char_df.columns if c.startswith(\"vol\")] + \\\n",
    "              [c for c in vol1_char_df.columns if c.startswith(\"page\")] + \\\n",
    "              [c for c in vol1_char_df.columns if c.startswith(\"block\")] +\\\n",
    "              [c for c in vol1_char_df.columns if c.startswith(\"line\")]\n",
    "              \n",
    "line_group_df = vol1_char_df.groupby(line_groups)\n",
    "temp_line_df = vol1_char_df[line_group_df['potential_genus_match'].transform('any') & line_group_df['potential_epithet_match'].transform('any')]\n",
    "temp_line_df[(temp_line_df['potential_genus_match'] == True) | (temp_line_df['potential_epithet_match'] == True)][[\"page_num\", \"block_num\", \"line_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>block_num</th>\n",
       "      <th>line_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [page_num, block_num, line_num, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_groups = [c for c in vol2_char_df.columns if c.startswith(\"vol\")] + \\\n",
    "              [c for c in vol2_char_df.columns if c.startswith(\"page\")] + \\\n",
    "              [c for c in vol2_char_df.columns if c.startswith(\"block\")] +\\\n",
    "              [c for c in vol2_char_df.columns if c.startswith(\"line\")]\n",
    "              \n",
    "line_group_df = vol2_char_df.groupby(line_groups)\n",
    "temp_line_df = vol2_char_df[line_group_df['potential_genus_match'].transform('any') & line_group_df['potential_epithet_match'].transform('any')]\n",
    "temp_line_df[(temp_line_df['potential_genus_match'] == True) | (temp_line_df['potential_epithet_match'] == True)][[\"page_num\", \"block_num\", \"line_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>block_num</th>\n",
       "      <th>line_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1584638</th>\n",
       "      <td>569</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584639</th>\n",
       "      <td>569</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>Majoranamaracus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         page_num  block_num  line_num             word\n",
       "1584638       569         36         0                x\n",
       "1584639       569         36         0  Majoranamaracus"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_groups = [c for c in vol3_char_df.columns if c.startswith(\"vol\")] + \\\n",
    "              [c for c in vol3_char_df.columns if c.startswith(\"page\")] + \\\n",
    "              [c for c in vol3_char_df.columns if c.startswith(\"block\")] +\\\n",
    "              [c for c in vol3_char_df.columns if c.startswith(\"line\")]\n",
    "              \n",
    "line_group_df = vol3_char_df.groupby(line_groups)\n",
    "temp_line_df = vol3_char_df[line_group_df['potential_genus_match'].transform('any') & line_group_df['potential_epithet_match'].transform('any')]\n",
    "temp_line_df[(temp_line_df['potential_genus_match'] == True) | (temp_line_df['potential_epithet_match'] == True)][[\"page_num\", \"block_num\", \"line_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing highlighting instead of making image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "page.add_highlight_annot(quads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol3_char_df['']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
