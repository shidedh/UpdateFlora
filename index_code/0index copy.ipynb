{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING BOOKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_path = '../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 1.pdf'\n",
    "vol2_path = '../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 2.pdf'\n",
    "vol3_path = '../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 3.pdf'\n",
    "\n",
    "vol1_doc = fitz.open(vol1_path)\n",
    "vol2_doc = fitz.open(vol2_path)\n",
    "vol3_doc = fitz.open(vol3_path)\n",
    "\n",
    "vol1_pages = [vol1_doc[i] for i in range(vol1_doc.page_count)]\n",
    "vol2_pages = [vol2_doc[i] for i in range(vol2_doc.page_count)]\n",
    "vol3_pages = [vol3_doc[i] for i in range(vol3_doc.page_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_char_df = pd.read_pickle(\"../input/char_df/vol1_df.pkl\")\n",
    "vol2_char_df = pd.read_pickle(\"../input/char_df/vol2_df.pkl\")\n",
    "vol3_char_df = pd.read_pickle(\"../input/char_df/vol3_df.pkl\")\n",
    "\n",
    "vol1_index = list(range(616, 639)) #inclusive\n",
    "vol2_index = list(range(703, 725))\n",
    "vol3_index = list(range(555, 583))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DPI = 300\n",
    "mat = fitz.Matrix(TARGET_DPI/ 72, TARGET_DPI/ 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding strict matching genera, epithet, and column numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genus_match(row):\n",
    "    word_rspace_removed = row['word']\n",
    "    return row['word_num'] == 0 and \\\n",
    "           word_rspace_removed.isalpha() and \\\n",
    "           word_rspace_removed[0].isupper() and word_rspace_removed[1:].islower()\n",
    "           \n",
    "def epithet_match(row):\n",
    "    word_rspace_removed = row['word']\n",
    "    return row['word_num'] == 0 and \\\n",
    "           word_rspace_removed.isalpha() and \\\n",
    "           word_rspace_removed.islower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rightmost point of any bounding box:\n",
    "def get_center_x0(vol_char_df, page_num, bias = 30):\n",
    "    \"\"\"WARNING: Bias = 30 large bias causes miscatagorization in page number in book\"\"\"\n",
    "    df = vol_char_df[vol_char_df['page_num'] == page_num]\n",
    "    \n",
    "    right_bound = df['line_bbox'].apply(lambda x : x[2]).max() \n",
    "    #leftmost point of any bounding box:\n",
    "    left_bound = df['line_bbox'].apply(lambda x : x[0]).min()\n",
    "\n",
    "    return 0.5*(right_bound + left_bound) - bias\n",
    "\n",
    "\n",
    "def get_col_num(coords, center_x0):\n",
    "    x0, y0, x1, y1 = coords\n",
    "    return int(x0 >= center_x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:12<00:00,  1.80it/s]\n",
      "100%|██████████| 22/22 [00:13<00:00,  1.61it/s]\n",
      "100%|██████████| 28/28 [00:14<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_col_num = [(vol1_char_df, vol1_index, vol1_doc),\n",
    "                        (vol2_char_df, vol2_index, vol2_doc),\n",
    "                        (vol3_char_df, vol3_index, vol3_doc)]\n",
    "\n",
    "for vol_char_df ,vol_index, doc in all_vol_data_col_num: \n",
    "    #for each volume check if genus pattern / epithet pattern exists within the index part of the book\n",
    "    vol_char_df['genus_index_pat_match'] = (vol_char_df['page_num'].isin(vol_index)) & (vol_char_df.apply(genus_match, axis = 1))\n",
    "    vol_char_df['epithet_index_pat_match'] = (vol_char_df['page_num'].isin(vol_index)) & (vol_char_df.apply(epithet_match, axis = 1))\n",
    "    \n",
    "    for page_num in tqdm(vol_index):\n",
    "        center_x0 = get_center_x0(vol_char_df, page_num)\n",
    "        #find center based on x0 coordinate of each line\n",
    "        vol_char_df['col_num'] = vol_char_df['line_bbox'].apply(lambda coords : get_col_num(coords, center_x0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genus / epithet flagging \n",
    "flagging pages where number of strict genus or epithet patern matches is less than 3 per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***FLAGS***\n",
      " number of pages to check: 3\n",
      "  genera\n",
      "\t number of genera: 1, page number: 2, column number: 0\n",
      "\t number of genera: 0, page number: 20, column number: 1\n",
      "\t number of genera: 1, page number: 23, column number: 0\n",
      "  epithets\n",
      "\t number of epithets: 2, page number: 23, column number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:03<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***FLAGS***\n",
      " number of pages to check: 2\n",
      "  genera\n",
      "\t number of genera: 2, page number: 4, column number: 0\n",
      "\t number of genera: 1, page number: 4, column number: 1\n",
      "\t number of genera: 0, page number: 5, column number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:04<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***FLAGS***\n",
      " number of pages to check: 7\n",
      "  genera\n",
      "\t number of genera: 1, page number: 2, column number: 1\n",
      "\t number of genera: 1, page number: 6, column number: 0\n",
      "\t number of genera: 1, page number: 21, column number: 0\n",
      "\t number of genera: 1, page number: 22, column number: 0\n",
      "\t number of genera: 2, page number: 24, column number: 1\n",
      "\t number of genera: 0, page number: 26, column number: 1\n",
      "\t number of genera: 2, page number: 28, column number: 0\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_flagg_strict_match = [(vol1_char_df, vol1_index, vol1_doc, \"strickt_match_vol1\"),\n",
    "                                   (vol2_char_df, vol2_index, vol2_doc, \"strickt_match_vol2\"),\n",
    "                                   (vol3_char_df, vol3_index, vol3_doc, \"strickt_match_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, vol_doc, output_name in all_vol_data_flagg_strict_match: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "    genus_flag_list = []\n",
    "    epithet_flag_list = []\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = vol_doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        genus_db = vol_char_df[(vol_char_df['page_num'] == page_num)\n",
    "                                & (vol_char_df['genus_index_pat_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['epithet_index_pat_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #genus pattern match flag should check with half page and not entire page:\n",
    "        for col in range(2):\n",
    "            num_genus_col = genus_db[genus_db[\"col_num\"] == col].shape[0]\n",
    "            num_epithet_col = epithet_db[epithet_db[\"col_num\"] == col].shape[0]\n",
    "            if num_genus_col <= 2:\n",
    "                genus_flag_list.append((num_genus_col, page_num - vol_index[0] + 1, col))\n",
    "            if num_epithet_col <= 2:\n",
    "                epithet_flag_list.append((num_epithet_col, page_num - vol_index[0] + 1, col))\n",
    "\n",
    "        for coord in genus_db['word_bbox']:\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "\n",
    "        for coord in epithet_db['word_bbox']:\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=5)\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])    \n",
    "    \n",
    "    num_flag_pages = len(set([g[1] for g in genus_flag_list] + [e[1] for e in epithet_flag_list]))\n",
    "    if num_flag_pages > 0: \n",
    "        print(\"***FLAGS***\")\n",
    "        print(f\" number of pages to check: {num_flag_pages}\")\n",
    "        if genus_flag_list:\n",
    "            print(\"  genera\")\n",
    "            [print(f\"\\t number of genera: {g_flag[0]}, page number: {g_flag[1]}, column number: {g_flag[2]}\") for g_flag in genus_flag_list]\n",
    "        if epithet_flag_list:\n",
    "            print(\"  epithets\")\n",
    "            [print(f\"\\t number of epithets: {e_flag[0]}, page number: {e_flag[1]}, column number: {e_flag[2]}\") for e_flag in epithet_flag_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on flags need to make sure: \n",
    "- first find epithet coord match \n",
    "- then find genus coord match s.t. word is not in epithet coord match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### match based on coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_coord_match(x, x_ref_left, x_ref_right, margin):\n",
    "    return (x_ref_left - margin <= x[0] and x[0] <= x_ref_left + margin) or (x_ref_right - margin <= x[0] and x[0] <= x_ref_right + margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### epithets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 21.61it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 20.91it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 24.65it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "                            (vol2_char_df, vol2_index),\n",
    "                            (vol3_char_df, vol3_index)]\n",
    "\n",
    "for vol_char_df, vol_index in all_vol_data_coord_match: \n",
    "    vol_char_df[\"epithet_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"epithet_index_pat_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        epithet_char_df = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"epithet_index_pat_match\"] == True)]\n",
    "        epithet_df = epithet_char_df.loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"])].drop_duplicates()\n",
    "        page_epithet_2dic = [{}, {}]\n",
    "        \n",
    "        for i in range(epithet_df.shape[0]):\n",
    "            e_index = str(page_num) + \"_\" + str(i)\n",
    "            p0 = epithet_df['word_bbox'].iloc[i]\n",
    "            x_ref = p0[0]\n",
    "            col = epithet_df['col_num'].iloc[i]\n",
    "\n",
    "            ref_neighbors_df = epithet_df[(epithet_df[\"page_num\"] == page_num) & \n",
    "                                          (epithet_df[\"word_bbox\"].apply(lambda x : x_ref - margin <= x[0] and x[0] <= x_ref + margin))]\n",
    "            \n",
    "            num_neighbors = ref_neighbors_df.shape[0]\n",
    "            mean_neighbors = ref_neighbors_df[\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            page_epithet_2dic[col][e_index] = (num_neighbors, mean_neighbors)\n",
    "        \n",
    "        mean_left_epithet = max(page_epithet_2dic[0].values(), default = [-1, -1])[1]\n",
    "        mean_right_epithet = max(page_epithet_2dic[1].values(), default = [-1, -1])[1]\n",
    "\n",
    "        if mean_left_epithet == -1 or mean_right_epithet == -1:\n",
    "            mean_valid_col = max(mean_left_epithet, mean_right_epithet)\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"epithet_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_valid_col, mean_valid_col, margin))\n",
    "        elif mean_left_epithet == -1 and mean_right_epithet == -1:\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"epithet_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : False)\n",
    "        else: \n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"epithet_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_left_epithet, mean_right_epithet, margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  5.72it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  5.77it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  5.95it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_epithet_coord_match_test = [(vol1_char_df, vol1_index, vol1_doc, \"epithet_coord_match_pruned_vol1\"),\n",
    "                                         (vol2_char_df, vol2_index, vol2_doc, \"epithet_coord_match_pruned_vol2\"),\n",
    "                                         (vol3_char_df, vol3_index, vol3_doc, \"epithet_coord_match_pruned_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_epithet_coord_match_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "    \n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        epithet_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['epithet_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['epithet_index_pat_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #epithet Coord is orange-pinkish, 5\n",
    "        for coord in epithet_coord_db[\"pruned_word_bbox\"] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "\n",
    "        #epithet is blue, 3\n",
    "        for coord in epithet_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=3)\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 31.85it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 27.69it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 33.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reminder:\n",
    "# all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "#                             (vol2_char_df, vol2_index),\n",
    "#                             (vol3_char_df, vol3_index)]\n",
    "# DOES NOT CHECK IF COORD IS SAME AS EPITHET UNTIL NEXT SECTION!\n",
    "\n",
    "for vol_char_df, vol_index in all_vol_data_coord_match: \n",
    "    #genus and not epithet\n",
    "    vol_char_df[\"genus_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"genus_index_pat_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        genus_char_df = vol_char_df[(vol_char_df[\"page_num\"] == page_num) &\n",
    "                                    (vol_char_df[\"genus_index_pat_match\"] == True)]\n",
    "        genus_df = genus_char_df.loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"])].drop_duplicates()\n",
    "        page_genus_2dic = [{}, {}]\n",
    "        \n",
    "        epithet_left_coord_mean = vol_char_df[(vol_char_df[\"epithet_coord_match\"] == True) &\n",
    "                                              (vol_char_df[\"page_num\"] == page_num) &\n",
    "                                              (vol_char_df[\"col_num\"] == 0)\n",
    "                                             ]['pruned_word_bbox'].apply(lambda x : x[0]).mean()\n",
    "        epithet_right_coord_mean = vol_char_df[(vol_char_df[\"epithet_coord_match\"] == True) &\n",
    "                                               (vol_char_df[\"page_num\"] == page_num) &\n",
    "                                               (vol_char_df[\"col_num\"] == 1)\n",
    "                                             ]['pruned_word_bbox'].apply(lambda x : x[0]).mean()\n",
    "        epithet_coord_mean_list = [epithet_left_coord_mean, epithet_right_coord_mean]\n",
    "\n",
    "        for i in range(genus_df.shape[0]):\n",
    "            g_index = str(page_num) + \"_\" + str(i)\n",
    "            p0 = genus_df['word_bbox'].iloc[i]\n",
    "            x_ref = p0[0]\n",
    "            col = genus_df['col_num'].iloc[i]\n",
    "\n",
    "            ref_neighbors_df = genus_df[(genus_df[\"page_num\"] == page_num) & \n",
    "                                        (genus_df[\"word_bbox\"].apply(lambda x : x_ref - margin <= x[0] and x[0] <= x_ref + margin))]\n",
    "\n",
    "            num_neighbors = ref_neighbors_df.shape[0]\n",
    "            mean_neighbors = ref_neighbors_df[\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            if mean_neighbors > epithet_coord_mean_list[col]: \n",
    "                mean_neighbors = -1\n",
    "            page_genus_2dic[col][g_index] = (num_neighbors, mean_neighbors)\n",
    "        \n",
    "        mean_left_genus = max(page_genus_2dic[0].values(), default = [-1, -1])[1]\n",
    "        mean_right_genus = max(page_genus_2dic[1].values(), default = [-1, -1])[1]\n",
    "\n",
    "        if mean_left_genus == -1 or mean_right_genus == -1:\n",
    "            mean_valid_col = max(mean_left_genus, mean_right_genus)\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"genus_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_valid_col, mean_valid_col, margin))\n",
    "        elif mean_left_genus == -1 and mean_right_genus == -1:\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"genus_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : False)\n",
    "        else: \n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"genus_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_left_genus, mean_right_genus, margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  5.77it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  5.84it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  5.98it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_genus_coord_match_test = [(vol1_char_df, vol1_index, vol1_doc, \"genus_coord_match_vol1\"),\n",
    "                                       (vol2_char_df, vol2_index, vol2_doc, \"genus_coord_match_vol2\"),\n",
    "                                       (vol3_char_df, vol3_index, vol3_doc, \"genus_coord_match_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_genus_coord_match_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "\n",
    "        genus_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['genus_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['epithet_coord_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in genus_coord_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # #epithet is red, 3\n",
    "        for coord in epithet_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#000099\"), width=3)\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### improving the coord matches \n",
    "takes genus coming before epithet into account now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_genus_match(row):\n",
    "    word_rspace_removed = row['word']\n",
    "    return row['genus_coord_match'] == True and \\\n",
    "           row['epithet_coord_match'] == False and \\\n",
    "           word_rspace_removed.find(\"Flore\") == -1 and \\\n",
    "           ((word_rspace_removed.isupper() == False and \\\n",
    "             word_rspace_removed.isnumeric() == False) or \\\n",
    "            ((word_rspace_removed == 'X') or (word_rspace_removed =='×')))\n",
    "           # removing this for-    hg now ... and row['genus_mean_coord'] < row['epithet_mean_coord'] #important to check this only when epithet_coord_match is false?\n",
    "\n",
    "def potential_epithet_match(row):\n",
    "    word_rspace_removed = row['word']\n",
    "    return row['epithet_coord_match'] == True and \\\n",
    "           ((word_rspace_removed.isupper() == False and \\\n",
    "             word_rspace_removed.isnumeric() == False) or \\\n",
    "            (word_rspace_removed == 'X') or (word_rspace_removed =='×'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_char_df['potential_genus_match'] = vol1_char_df.apply(potential_genus_match, axis = 1)\n",
    "vol1_char_df['potential_epithet_match'] = vol1_char_df.apply(potential_epithet_match, axis = 1)\n",
    "\n",
    "vol2_char_df['potential_genus_match'] = vol2_char_df.apply(potential_genus_match, axis = 1)\n",
    "vol2_char_df['potential_epithet_match'] = vol2_char_df.apply(potential_epithet_match, axis = 1)\n",
    "\n",
    "vol3_char_df['potential_genus_match'] = vol3_char_df.apply(potential_genus_match, axis = 1)\n",
    "vol3_char_df['potential_epithet_match'] = vol3_char_df.apply(potential_epithet_match, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  5.70it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  5.79it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  6.07it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_GE_potential_match_test = [(vol1_char_df, vol1_index, vol1_doc, \"GE_potential_match_vol1\"),\n",
    "                                        (vol2_char_df, vol2_index, vol2_doc, \"GE_potential_match_vol2\"),\n",
    "                                        (vol3_char_df, vol3_index, vol3_doc, \"GE_potential_match_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_GE_potential_match_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        genus_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['potential_genus_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['potential_epithet_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in genus_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # #epithet is red, 3\n",
    "        for coord in epithet_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#000099\"), width=3)\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must take or of flag properties:\n",
    "def flags_decomposer(flags):\n",
    "    \"\"\"Make font flags human readable.\"\"\"\n",
    "    l = []\n",
    "    if flags & 2 ** 0:\n",
    "        l.append(\"superscript\")\n",
    "    if flags & 2 ** 1:\n",
    "        l.append(\"italic\")\n",
    "    if flags & 2 ** 2:\n",
    "        l.append(\"serifed\")\n",
    "    else:\n",
    "        l.append(\"sans\")\n",
    "    if flags & 2 ** 3:\n",
    "        l.append(\"monospaced\")\n",
    "    else:\n",
    "        l.append(\"proportional\")\n",
    "    if flags & 2 ** 4:\n",
    "        l.append(\"bold\")\n",
    "    return \", \".join(l)\n",
    "\n",
    "span_flags = []\n",
    "result = 0\n",
    "for b in span_flags:\n",
    "    result = span_flags | result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINES! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vol_num', 'page_num', 'block_num', 'block_num_absolute', 'block_bbox',\n",
       "       'line_num', 'line_wmode', 'line_dir', 'line_bbox', 'span_num',\n",
       "       'span_size', 'span_flags', 'span_font', 'span_color', 'span_ascender',\n",
       "       'span_descender', 'span_origin', 'span_bbox', 'word_num', 'word',\n",
       "       'word_bbox', 'pruned_word', 'pruned_word_bbox', 'char_num', 'char',\n",
       "       'char_origin', 'char_bbox', 'genus_index_pat_match',\n",
       "       'epithet_index_pat_match', 'col_num', 'epithet_coord_match',\n",
       "       'genus_coord_match', 'potential_genus_match',\n",
       "       'potential_epithet_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in vol1_char_df.columns:\n",
    "    len(vol1_char_df[col_name].unique()) == 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINES END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOME HARDCODING PARTS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erianthus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol_num</th>\n",
       "      <th>page_num</th>\n",
       "      <th>block_num</th>\n",
       "      <th>block_num_absolute</th>\n",
       "      <th>block_bbox</th>\n",
       "      <th>line_num</th>\n",
       "      <th>line_wmode</th>\n",
       "      <th>line_dir</th>\n",
       "      <th>line_bbox</th>\n",
       "      <th>span_num</th>\n",
       "      <th>...</th>\n",
       "      <th>char</th>\n",
       "      <th>char_origin</th>\n",
       "      <th>char_bbox</th>\n",
       "      <th>genus_index_pat_match</th>\n",
       "      <th>epithet_index_pat_match</th>\n",
       "      <th>col_num</th>\n",
       "      <th>epithet_coord_match</th>\n",
       "      <th>genus_coord_match</th>\n",
       "      <th>potential_genus_match</th>\n",
       "      <th>potential_epithet_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1731817</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>J</td>\n",
       "      <td>(239.9900665283203, 357.20001220703125)</td>\n",
       "      <td>(239.9900665283203, 352.70001220703125, 242.33...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731818</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>(242.32186889648438, 357.20001220703125)</td>\n",
       "      <td>(242.32186889648438, 352.70001220703125, 243.8...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731819</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>d</td>\n",
       "      <td>(243.81723022460938, 357.20001220703125)</td>\n",
       "      <td>(243.81723022460938, 352.70001220703125, 246.8...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731820</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>,</td>\n",
       "      <td>(246.8169708251953, 357.20001220703125)</td>\n",
       "      <td>(246.8169708251953, 352.70001220703125, 248.32...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731821</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>(248.3123321533203, 357.20001220703125)</td>\n",
       "      <td>(248.3123321533203, 352.70001220703125, 250.31...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731822</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>l</td>\n",
       "      <td>(250.30714416503906, 357.20001220703125)</td>\n",
       "      <td>(250.30714416503906, 352.70001220703125, 251.9...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731823</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>(251.9709930419922, 357.20001220703125)</td>\n",
       "      <td>(251.9709930419922, 352.70001220703125, 255.64...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731824</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>(255.638671875, 357.20001220703125)</td>\n",
       "      <td>(255.638671875, 352.70001220703125, 257.642547...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731825</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>l</td>\n",
       "      <td>(257.63348388671875, 357.20001220703125)</td>\n",
       "      <td>(257.63348388671875, 352.70001220703125, 259.3...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731826</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>(259.2973327636719, 357.20001220703125)</td>\n",
       "      <td>(259.2973327636719, 352.70001220703125, 263.64...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731827</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>(263.6429138183594, 357.20001220703125)</td>\n",
       "      <td>(263.6429138183594, 352.70001220703125, 265.14...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        vol_num  page_num  block_num  block_num_absolute  \\\n",
       "1731817       1       624         75                 120   \n",
       "1731818       1       624         75                 120   \n",
       "1731819       1       624         75                 120   \n",
       "1731820       1       624         75                 120   \n",
       "1731821       1       624         75                 120   \n",
       "1731822       1       624         75                 120   \n",
       "1731823       1       624         75                 120   \n",
       "1731824       1       624         75                 120   \n",
       "1731825       1       624         75                 120   \n",
       "1731826       1       624         75                 120   \n",
       "1731827       1       624         75                 120   \n",
       "\n",
       "                                                block_bbox  line_num  \\\n",
       "1731817  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1731818  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1731819  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1731820  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1731821  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1731822  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1731823  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1731824  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1731825  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1731826  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1731827  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "\n",
       "         line_wmode    line_dir  \\\n",
       "1731817           0  (1.0, 0.0)   \n",
       "1731818           0  (1.0, 0.0)   \n",
       "1731819           0  (1.0, 0.0)   \n",
       "1731820           0  (1.0, 0.0)   \n",
       "1731821           0  (1.0, 0.0)   \n",
       "1731822           0  (1.0, 0.0)   \n",
       "1731823           0  (1.0, 0.0)   \n",
       "1731824           0  (1.0, 0.0)   \n",
       "1731825           0  (1.0, 0.0)   \n",
       "1731826           0  (1.0, 0.0)   \n",
       "1731827           0  (1.0, 0.0)   \n",
       "\n",
       "                                                 line_bbox  span_num  ...  \\\n",
       "1731817  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1731818  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1731819  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1731820  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1731821  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1731822  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1731823  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1731824  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1731825  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1731826  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1731827  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "\n",
       "         char                               char_origin  \\\n",
       "1731817     J   (239.9900665283203, 357.20001220703125)   \n",
       "1731818     .  (242.32186889648438, 357.20001220703125)   \n",
       "1731819     d  (243.81723022460938, 357.20001220703125)   \n",
       "1731820     ,   (246.8169708251953, 357.20001220703125)   \n",
       "1731821     I   (248.3123321533203, 357.20001220703125)   \n",
       "1731822     l  (250.30714416503906, 357.20001220703125)   \n",
       "1731823     L   (251.9709930419922, 357.20001220703125)   \n",
       "1731824     I       (255.638671875, 357.20001220703125)   \n",
       "1731825     l  (257.63348388671875, 357.20001220703125)   \n",
       "1731826     U   (259.2973327636719, 357.20001220703125)   \n",
       "1731827     .   (263.6429138183594, 357.20001220703125)   \n",
       "\n",
       "                                                 char_bbox  \\\n",
       "1731817  (239.9900665283203, 352.70001220703125, 242.33...   \n",
       "1731818  (242.32186889648438, 352.70001220703125, 243.8...   \n",
       "1731819  (243.81723022460938, 352.70001220703125, 246.8...   \n",
       "1731820  (246.8169708251953, 352.70001220703125, 248.32...   \n",
       "1731821  (248.3123321533203, 352.70001220703125, 250.31...   \n",
       "1731822  (250.30714416503906, 352.70001220703125, 251.9...   \n",
       "1731823  (251.9709930419922, 352.70001220703125, 255.64...   \n",
       "1731824  (255.638671875, 352.70001220703125, 257.642547...   \n",
       "1731825  (257.63348388671875, 352.70001220703125, 259.3...   \n",
       "1731826  (259.2973327636719, 352.70001220703125, 263.64...   \n",
       "1731827  (263.6429138183594, 352.70001220703125, 265.14...   \n",
       "\n",
       "         genus_index_pat_match  epithet_index_pat_match  col_num  \\\n",
       "1731817                  False                    False        1   \n",
       "1731818                  False                    False        1   \n",
       "1731819                  False                    False        1   \n",
       "1731820                  False                    False        1   \n",
       "1731821                  False                    False        1   \n",
       "1731822                  False                    False        1   \n",
       "1731823                  False                    False        1   \n",
       "1731824                  False                    False        1   \n",
       "1731825                  False                    False        1   \n",
       "1731826                  False                    False        1   \n",
       "1731827                  False                    False        1   \n",
       "\n",
       "        epithet_coord_match genus_coord_match  potential_genus_match  \\\n",
       "1731817                True             False                  False   \n",
       "1731818                True             False                  False   \n",
       "1731819                True             False                  False   \n",
       "1731820                True             False                  False   \n",
       "1731821                True             False                  False   \n",
       "1731822                True             False                  False   \n",
       "1731823                True             False                  False   \n",
       "1731824                True             False                  False   \n",
       "1731825                True             False                  False   \n",
       "1731826                True             False                  False   \n",
       "1731827                True             False                  False   \n",
       "\n",
       "        potential_epithet_match  \n",
       "1731817                    True  \n",
       "1731818                    True  \n",
       "1731819                    True  \n",
       "1731820                    True  \n",
       "1731821                    True  \n",
       "1731822                    True  \n",
       "1731823                    True  \n",
       "1731824                    True  \n",
       "1731825                    True  \n",
       "1731826                    True  \n",
       "1731827                    True  \n",
       "\n",
       "[11 rows x 34 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[vol1_char_df['word'].str.contains('d,IlLIlU')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on this image output in volumen 1:\n",
    " ![Erianthus](Erianthus.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1731810          Bieb.\n",
       "1731811          Bieb.\n",
       "1731812          Bieb.\n",
       "1731813           J_JI\n",
       "1731814           J_JI\n",
       "1731815           J_JI\n",
       "1731816           J_JI\n",
       "1731817    J.d,IlLIlU.\n",
       "1731818    J.d,IlLIlU.\n",
       "1731819    J.d,IlLIlU.\n",
       "1731820    J.d,IlLIlU.\n",
       "1731821    J.d,IlLIlU.\n",
       "1731822    J.d,IlLIlU.\n",
       "1731823    J.d,IlLIlU.\n",
       "1731824    J.d,IlLIlU.\n",
       "1731825    J.d,IlLIlU.\n",
       "1731826    J.d,IlLIlU.\n",
       "1731827    J.d,IlLIlU.\n",
       "1731828         hostii\n",
       "1731829         hostii\n",
       "1731830         hostii\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_old_char_vol1 = vol1_char_df.loc[1731810:1731830]\n",
    "weird_old_char_vol1['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_num_Erianthus1, page_num_Erianthus1, block_num_Erianthus1, line_num_Erianthus1, span_num_Erianthus1, word_num_Erianthus1 = vol1_char_df[vol1_char_df['word'].str.contains('J_JI')][['vol_num', 'page_num', 'block_num', 'line_num', 'span_num', 'word_num']].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vol_num', 'page_num', 'block_num', 'block_num_absolute', 'block_bbox',\n",
       "       'line_num', 'line_wmode', 'line_dir', 'line_bbox', 'span_num',\n",
       "       'span_size', 'span_flags', 'span_font', 'span_color', 'span_ascender',\n",
       "       'span_descender', 'span_origin', 'span_bbox', 'word_num', 'word',\n",
       "       'word_bbox', 'pruned_word', 'pruned_word_bbox', 'char_num', 'char',\n",
       "       'char_origin', 'char_bbox', 'genus_index_pat_match',\n",
       "       'epithet_index_pat_match', 'col_num', 'epithet_coord_match',\n",
       "       'genus_coord_match', 'potential_genus_match',\n",
       "       'potential_epithet_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_num_Erianthu2, page_num_Erianthus2, block_num_Erianthus2, line_num_Erianthus2, span_num_Erianthus2, word_num_Erianthus2 = vol1_char_df[vol1_char_df['word'].str.contains('J.d,IlLIlU.')][['vol_num', 'page_num', 'block_num', 'line_num', 'span_num','word_num']].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_index = vol1_char_df[((vol1_char_df['vol_num'] == vol_num_Erianthus1) | (vol1_char_df['vol_num'] == vol_num_Erianthu2)) &\n",
    "                            ((vol1_char_df['page_num'] == page_num_Erianthus1) | (vol1_char_df['page_num'] == page_num_Erianthus2)) &\n",
    "                            ((vol1_char_df['block_num'] == block_num_Erianthus1) | (vol1_char_df['block_num'] == block_num_Erianthus2)) & \n",
    "                            ((vol1_char_df['line_num'] == line_num_Erianthus1) | (vol1_char_df['line_num'] == line_num_Erianthus2)) &  \n",
    "                            ((vol1_char_df['span_num'] == span_num_Erianthus1) | (vol1_char_df['span_num'] == span_num_Erianthus2)) & \n",
    "                            ((vol1_char_df['word_num'] == word_num_Erianthus1) | (vol1_char_df['word_num'] == word_num_Erianthus2)) \n",
    "                            ].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1731813           J_JI\n",
       "1731814           J_JI\n",
       "1731815           J_JI\n",
       "1731816           J_JI\n",
       "1731817    J.d,IlLIlU.\n",
       "1731818    J.d,IlLIlU.\n",
       "1731819    J.d,IlLIlU.\n",
       "1731820    J.d,IlLIlU.\n",
       "1731821    J.d,IlLIlU.\n",
       "1731822    J.d,IlLIlU.\n",
       "1731823    J.d,IlLIlU.\n",
       "1731824    J.d,IlLIlU.\n",
       "1731825    J.d,IlLIlU.\n",
       "1731826    J.d,IlLIlU.\n",
       "1731827    J.d,IlLIlU.\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index = 1731813\n",
    "end_index = 1731827\n",
    "weird_old_char_vol1 = vol1_char_df.loc[target_index]\n",
    "weird_old_char_vol1['word']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make comment about this part is hard coded thingi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1731813    0\n",
       "1731814    0\n",
       "1731815    0\n",
       "1731816    0\n",
       "1731817    1\n",
       "1731818    1\n",
       "1731819    1\n",
       "1731820    1\n",
       "1731821    1\n",
       "1731822    1\n",
       "1731823    1\n",
       "1731824    1\n",
       "1731825    1\n",
       "1731826    1\n",
       "1731827    1\n",
       "Name: word_num, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_old_char_vol1['word_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually fixing the OCR error for J_JI J.d,IlLIlU. hostii Griseb.\n",
    "vol1_char_df.loc[target_index, 'word'] = 'Erianthus'\n",
    "vol1_char_df.loc[target_index, 'word_num'] = 0\n",
    "vol1_char_df.loc[target_index, 'pruned_word'] = 'Erianthus'\n",
    "temp_word_x0 = vol1_char_df.loc[target_index, 'word_bbox'].apply(lambda x : x[0]).min()\n",
    "temp_word_y0 = vol1_char_df.loc[target_index, 'word_bbox'].apply(lambda x : x[1]).min()\n",
    "temp_word_x1 = vol1_char_df.loc[target_index, 'word_bbox'].apply(lambda x : x[2]).max()\n",
    "temp_word_y1 = vol1_char_df.loc[target_index, 'word_bbox'].apply(lambda x : x[3]).max()\n",
    "vol1_char_df.loc[target_index, 'word_bbox'] =vol1_char_df.loc[target_index, 'word_bbox'].apply(lambda x : (temp_word_x0, temp_word_y0, temp_word_x1, temp_word_y1))\n",
    "\n",
    "vol1_char_df.loc[target_index, 'potential_epithet_match'] = False\n",
    "vol1_char_df.loc[target_index, 'potential_genus_match'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infra species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 19.43it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 17.56it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 20.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reminder:\n",
    "# all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "#                             (vol2_char_df, vol2_index),\n",
    "#                             (vol3_char_df, vol3_index)]\n",
    "for vol_char_df, vol_index in all_vol_data_coord_match: \n",
    "    vol_char_df[\"infra_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"potential_epithet_match\"] == True) | (vol_char_df[\"potential_genus_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        \n",
    "        mean_left_epithet = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        mean_left_genus = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        if math.isnan(mean_left_genus):\n",
    "            mean_left_genus_all = vol_char_df[(vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_left_epithet_all = vol_char_df[(vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_left_tab = mean_left_epithet_all - mean_left_genus_all\n",
    "        else: \n",
    "            mean_left_tab = mean_left_epithet - mean_left_genus\n",
    "        \n",
    "        mean_right_epithet = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        mean_right_genus = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        if math.isnan(mean_right_genus):\n",
    "            mean_right_genus_all = vol_char_df[(vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_right_epithet_all = vol_char_df[(vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_right_tab = mean_right_epithet_all - mean_right_genus_all\n",
    "        else: \n",
    "            mean_right_tab = mean_right_epithet - mean_right_genus\n",
    "\n",
    "\n",
    "        vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"word_num\"] == 0)  , \"infra_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"word_num\"] == 0)][\"word_bbox\"].apply(lambda x : is_coord_match(x, mean_left_epithet + mean_left_tab, mean_right_epithet + mean_right_tab, margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes longer but makes more sense generally. We will skip it here\n",
    "# def potential_author_match_infra_coord(row):\n",
    "#     word = row['word']\n",
    "#     pruned_word = row['pruned_word']\n",
    "#     lower_word = word.lower()\n",
    "#     latin_connectives = r\"^\\s?et[\\s|.]?$|^\\s?in[\\s|.]?$|^\\s?non[\\s|.]?$|^\\s?&[\\s|.]?$|^\\s?er[\\s|.]?$|^\\s?nec[\\s|.]?$|^\\s?mult[\\s|.]?$|^\\s?ex[\\s|.]?$|^\\s?fil[\\s|.]?$\"\n",
    "#     infra_symbols = r\"^var[\\s|.|\\b]?$|^subsp[\\s|.|\\b]?$|^ssp[\\s|.|\\b]?$|^spp[\\s|.|\\b]?$|^x[\\s|.|\\b]?$|^×[\\s|.|\\b]?$\"\n",
    "#     is_latin_connectives = re.search(latin_connectives, word) != None\n",
    "#     is_infra_symbol = re.search(infra_symbols, lower_word) != None\n",
    "#     if pruned_word:\n",
    "#         is_upper_first = pruned_word[0].isupper()\n",
    "#     else:\n",
    "#         is_upper_first = False\n",
    "#     return (not is_infra_symbol) and (is_upper_first or is_latin_connectives)\n",
    "\n",
    "def potential_author_match_infra_coord(word):\n",
    "    lower_word = word.lower()\n",
    "    latin_connectives = r\"^\\s?et[\\s|.]?$|^\\s?in[\\s|.]?$|^\\s?non[\\s|.]?$|^\\s?&[\\s|.]?$|^\\s?er[\\s|.]?$|^\\s?nec[\\s|.]?$|^\\s?mult[\\s|.]?$|^\\s?ex[\\s|.]?$|^\\s?fil[\\s|.]?$\"\n",
    "    infra_symbols = r\"^var[\\s|.|\\b]?$|^subsp[\\s|.|\\b]?$|^ssp[\\s|.|\\b]?$|^spp[\\s|.|\\b]?$|^x[\\s|.|\\b]?$|^×[\\s|.|\\b]?$\"\n",
    "    is_latin_connectives = re.search(latin_connectives, word) != None\n",
    "    is_infra_symbol = re.search(infra_symbols, lower_word) != None\n",
    "    return (not is_infra_symbol) and (word[0].isupper() or is_latin_connectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_infra_symbols(word):\n",
    "    infra_symbols = r\"^var[\\s|.|\\b]?$|^subsp[\\s|.|\\b]?$|^ssp[\\s|.|\\b]?$|^spp[\\s|.|\\b]?$|^x[\\s|.|\\b]?$|^×[\\s|.|\\b]?$\"\n",
    "    return re.search(infra_symbols, word) != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder:\n",
    "# all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "#                             (vol2_char_df, vol2_index),\n",
    "#                             (vol3_char_df, vol3_index)]\n",
    "for vol_char_df, _ in all_vol_data_coord_match:\n",
    "    vol_char_df[\"potential_infra_match\"] = (vol_char_df['word'].apply(has_infra_symbols)) | \\\n",
    "                                           ((vol_char_df[\"infra_coord_match\"] == True) & (vol_char_df['word'].apply(potential_author_match_infra_coord) == False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:23<00:00,  1.20it/s]\n",
      "100%|██████████| 22/22 [00:21<00:00,  1.03it/s]\n",
      "100%|██████████| 23/23 [00:20<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_dat_infra_match_test = [(vol1_char_df, vol1_index, vol1_doc, \"potential_infra_match_vol1\"),\n",
    "                                (vol2_char_df, vol2_index, vol2_doc, \"potential_infra_match_vol2\"),\n",
    "                                (vol3_char_df, vol3_index, vol3_doc, \"potential_infra_match_vol3\")][::-1]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_dat_infra_match_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "\n",
    "        infra_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['infra_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        infra_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['potential_infra_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        with_infra_symbols = vol_char_df[(vol_char_df['page_num'] == page_num) &\n",
    "                                         (vol_char_df['infra_coord_match'] == True) & \n",
    "                                         (vol_char_df['word'].apply(has_infra_symbols) == True)\n",
    "                                        ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                        ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in infra_coord_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0-5, y0-5, x1+5, y1+5), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=7)\n",
    "\n",
    "        for coord in infra_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0-3, y0-3, x1+3, y1+3), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # #epithet is red, 3\n",
    "        for coord in with_infra_symbols['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#990000\"), width=3)\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### page num processings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_char_df['index_page_num'] = vol1_char_df['page_num'] - vol1_index[0] + 1\n",
    "vol2_char_df['index_page_num'] = vol2_char_df['page_num'] - vol2_index[0] + 1\n",
    "vol3_char_df['index_page_num'] = vol3_char_df['page_num'] - vol3_index[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:12<00:00,  1.78it/s]\n",
      "100%|██████████| 22/22 [00:13<00:00,  1.61it/s]\n",
      "100%|██████████| 28/28 [00:14<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# all_vol_data_col_num = [(vol1_char_df, vol1_index, vol1_doc),\n",
    "#                         (vol2_char_df, vol2_index, vol2_doc),\n",
    "#                         (vol3_char_df, vol3_index, vol3_doc)]\n",
    "\n",
    "for vol_char_df ,vol_index, vol_doc in all_vol_data_col_num: \n",
    "    #for each volume check if genus pattern / epithet pattern exists within the index part of the book\n",
    "    for page_num in tqdm(vol_index):\n",
    "        center_x0 = get_center_x0(vol_char_df, page_num, - 30)\n",
    "        #find center based on x0 coordinate of each line\n",
    "        vol_char_df['col_num_for_PN'] = vol_char_df['line_bbox'].apply(lambda coords : get_col_num(coords, center_x0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_page_num(row):\n",
    "    return row['pruned_word'].isnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 16.25it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 14.95it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 22.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reminder:\n",
    "# all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "#                             (vol2_char_df, vol2_index),\n",
    "#                             (vol3_char_df, vol3_index)]\n",
    "for vol_char_df, vol_index in all_vol_data_coord_match: \n",
    "    vol_char_df['page_num_index_pat_match'] = (vol_char_df['page_num'].isin(vol_index)) & (vol_char_df.apply(is_page_num, axis = 1))\n",
    "    vol_char_df[\"page_num_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"page_num_index_pat_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        page_num_char_df = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"page_num_index_pat_match\"] == True)]\n",
    "        page_num_df = page_num_char_df.loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"])].drop_duplicates()\n",
    "        page_page_num_2dic = [{}, {}]\n",
    "        \n",
    "        for i in range(page_num_df.shape[0]):\n",
    "            e_index = str(page_num) + \"_\" + str(i)\n",
    "            p0 = page_num_df['word_bbox'].iloc[i]\n",
    "            x_ref = p0[2]\n",
    "            col = page_num_df['col_num_for_PN'].iloc[i]\n",
    "\n",
    "            ref_neighbors_df = page_num_df[(page_num_df[\"page_num\"] == page_num) & \n",
    "                                           (page_num_df[\"word_bbox\"].apply(lambda x : x_ref - margin <= x[2] and x[2] <= x_ref + margin))]\n",
    "            \n",
    "            num_neighbors = ref_neighbors_df.shape[0]\n",
    "            mean_neighbors = ref_neighbors_df[\"word_bbox\"].apply(lambda x : x[2]).mean()\n",
    "            page_page_num_2dic[col][e_index] = (num_neighbors, mean_neighbors)\n",
    "        \n",
    "        mean_left_page_num = max(page_page_num_2dic[0].values(), default = [-1, -1])[1]\n",
    "        mean_right_page_num = max(page_page_num_2dic[1].values(), default = [-1, -1])[1]\n",
    "\n",
    "        if mean_left_page_num == -1 or mean_right_page_num == -1:\n",
    "            mean_valid_col = max(mean_left_page_num, mean_right_page_num)\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"page_num_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match([x[2]], mean_valid_col, mean_valid_col, margin))\n",
    "        elif mean_left_page_num == -1 and mean_right_page_num == -1:\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"page_num_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : False)\n",
    "        else: \n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"page_num_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match([x[2]], mean_left_page_num, mean_right_page_num, margin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:04<00:00,  6.28it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  6.06it/s]\n",
      "100%|██████████| 23/23 [00:03<00:00,  5.96it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_PN_test = [(vol1_char_df, vol1_index, vol1_doc, \"potential_page_num_match_vol1\"),\n",
    "                        (vol2_char_df, vol2_index, vol2_doc, \"potential_page_num_match_vol2\"),\n",
    "                        (vol3_char_df, vol3_index, vol3_doc, \"potential_page_num_match_vol3\")][::-1]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_PN_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "\n",
    "        page_num_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['page_num_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        # infra_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "        #                         & (vol_char_df['potential_infra_match'] == True)\n",
    "        #                         ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "        #                         ].drop_duplicates()\n",
    "\n",
    "        # with_infra_symbols = vol_char_df[(vol_char_df['page_num'] == page_num) &\n",
    "        #                                  (vol_char_df['infra_coord_match'] == True) & \n",
    "        #                                  (vol_char_df['word'].apply(has_infra_symbols) == True)\n",
    "        #                                 ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "        #                                 ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in page_num_coord_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=3)\n",
    "\n",
    "        # for coord in infra_db['word_bbox'] :\n",
    "        #     x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "        #     draw.rectangle((x0-3, y0-3, x1+3, y1+3), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # # #epithet is red, 3\n",
    "        # for coord in with_infra_symbols['word_bbox'] :\n",
    "        #     x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "        #     draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#990000\"), width=3)\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catching & hardcoding issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking potential_infra_match that are not with typical symbols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_page_num, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_infra_match'] == True) & (vol1_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_page_num, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_infra_match'] == True) & (vol2_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1557763</th>\n",
       "      <td>3</td>\n",
       "      <td>(3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558282</th>\n",
       "      <td>3</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559900</th>\n",
       "      <td>4</td>\n",
       "      <td>fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564627</th>\n",
       "      <td>6</td>\n",
       "      <td>deris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568637</th>\n",
       "      <td>8</td>\n",
       "      <td>cock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574726</th>\n",
       "      <td>11</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576530</th>\n",
       "      <td>12</td>\n",
       "      <td>picha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579429</th>\n",
       "      <td>13</td>\n",
       "      <td>adoxifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582311</th>\n",
       "      <td>15</td>\n",
       "      <td>yar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585217</th>\n",
       "      <td>16</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587806</th>\n",
       "      <td>17</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590717</th>\n",
       "      <td>19</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592600</th>\n",
       "      <td>20</td>\n",
       "      <td>turcicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594100</th>\n",
       "      <td>20</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596298</th>\n",
       "      <td>22</td>\n",
       "      <td>berlain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num         word\n",
       "1557763               3           (3\n",
       "1558282               3           f.\n",
       "1559900               4           fa\n",
       "1564627               6        deris\n",
       "1568637               8         cock\n",
       "1574726              11           f.\n",
       "1576530              12        picha\n",
       "1579429              13  adoxifolium\n",
       "1582311              15         yar.\n",
       "1585217              16           f.\n",
       "1587806              17           f.\n",
       "1590717              19           f.\n",
       "1592600              20     turcicus\n",
       "1594100              20            y\n",
       "1596298              22      berlain"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_infra_match'] == True) & (vol3_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_infra_index = [1566359, 1570483, 1578491, 1581443, 1582167, 1594835, 1598587]\n",
    "#temp_df_hard_code_infra = vol3_char_df[(vol3_char_df['potential_infra_match'] == True) & (vol3_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"pruned_word\"]].drop_duplicates()\n",
    "#temp_df_hard_code_infra[temp_df_hard_code_infra['pruned_word'].apply(lambda x : len(x) > 3)].index \n",
    "#nice ways but won't have everything in them ... so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1570493\n",
      "10 1566369\n",
      "8 1570891\n",
      "8 1570891\n",
      "3 1578494\n",
      "6 1581449\n",
      "9 1582176\n",
      "7 1594842\n",
      "3 1598590\n",
      "6 1581449\n"
     ]
    }
   ],
   "source": [
    "def get_index_end(vol_df, start_index):\n",
    "    len_word = len(vol_df.loc[start_index,'word'])\n",
    "    print(len_word, start_index + len_word)\n",
    "    return start_index + len_word - 1\n",
    "\n",
    "set_epithet_index = [1581443]\n",
    "remove_infra_index = [1570483, 1566359, 1570883, 1570883, 1578491, 1581443, 1582167, 1594835, 1598587]\n",
    "for i in remove_infra_index:\n",
    "    vol3_char_df.loc[i : get_index_end(vol3_char_df, i),'potential_infra_match'] = False\n",
    "\n",
    "for i in set_epithet_index:\n",
    "    vol3_char_df.loc[i : get_index_end(vol3_char_df, i),'potential_epithet_match'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1557763</th>\n",
       "      <td>3</td>\n",
       "      <td>(3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558282</th>\n",
       "      <td>3</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559900</th>\n",
       "      <td>4</td>\n",
       "      <td>fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564627</th>\n",
       "      <td>6</td>\n",
       "      <td>deris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568637</th>\n",
       "      <td>8</td>\n",
       "      <td>cock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574726</th>\n",
       "      <td>11</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576530</th>\n",
       "      <td>12</td>\n",
       "      <td>picha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579429</th>\n",
       "      <td>13</td>\n",
       "      <td>adoxifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582311</th>\n",
       "      <td>15</td>\n",
       "      <td>yar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585217</th>\n",
       "      <td>16</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587806</th>\n",
       "      <td>17</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590717</th>\n",
       "      <td>19</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592600</th>\n",
       "      <td>20</td>\n",
       "      <td>turcicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594100</th>\n",
       "      <td>20</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596298</th>\n",
       "      <td>22</td>\n",
       "      <td>berlain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num         word\n",
       "1557763               3           (3\n",
       "1558282               3           f.\n",
       "1559900               4           fa\n",
       "1564627               6        deris\n",
       "1568637               8         cock\n",
       "1574726              11           f.\n",
       "1576530              12        picha\n",
       "1579429              13  adoxifolium\n",
       "1582311              15         yar.\n",
       "1585217              16           f.\n",
       "1587806              17           f.\n",
       "1590717              19           f.\n",
       "1592600              20     turcicus\n",
       "1594100              20            y\n",
       "1596298              22      berlain"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cock keeps needing to be pruned multiple times ....??? not sure why ugh\n",
    "vol3_char_df[(vol3_char_df['potential_infra_match'] == True) & (vol3_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1596384 -> var with space in between it somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1596390\n"
     ]
    }
   ],
   "source": [
    "ending = get_index_end(vol3_char_df, 1596384)+2\n",
    "vol3_char_df.loc[1596384 : ending, 'word'] = 'var.'\n",
    "vol3_char_df.loc[1596384 : ending, 'word_num'] = 0\n",
    "vol3_char_df.loc[1596384 : ending, 'pruned_word'] = 'var'\n",
    "vol3_char_df.loc[1596384 : ending, 'potential_infra_match'] = True \n",
    "#have to run it again this is problematic now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upper case beggining / latin words in epithet coordd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_author_match_epithet_coord(word):\n",
    "    latin_connectives = r\"^\\s?et[\\s|.]?$|^\\s?in[\\s|.]?$|^\\s?non[\\s|.]?$|^\\s?&[\\s|.]?$|^\\s?er[\\s|.]?$|^\\s?nec[\\s|.]?$|^\\s?mult[\\s|.]?$|^\\s?ex[\\s|.]?$|^\\s?fil[\\s|.]?$|^\\s?f[\\s|.]?$\"\n",
    "    is_latin_connectives = re.search(latin_connectives, word) != None\n",
    "    is_hybrid = word == \"X\"\n",
    "    return is_latin_connectives or (word[0].isupper() and (not is_hybrid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKED: for vol1 all are okay and are just typos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1750223</th>\n",
       "      <td>18</td>\n",
       "      <td>Phoenicia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750722</th>\n",
       "      <td>18</td>\n",
       "      <td>Syriacus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752316</th>\n",
       "      <td>19</td>\n",
       "      <td>Jilicaulis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num        word\n",
       "1750223              18   Phoenicia\n",
       "1750722              18    Syriacus\n",
       "1752316              19  Jilicaulis"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_epithet_match'] == True) & (vol1_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKED Vol2 \n",
    "\n",
    "Hbanoticus -> typo for libanoticus \n",
    "\n",
    "Hppii -> typo for lippii\n",
    "\n",
    "letting fuzzy matching take care of it later :)\n",
    "\n",
    "**TODO**: Ma -> is supposed to be chia (not easy for fuzzy matching to fix...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1914060</th>\n",
       "      <td>4</td>\n",
       "      <td>Hbanoticus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921063</th>\n",
       "      <td>8</td>\n",
       "      <td>Hppii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935567</th>\n",
       "      <td>14</td>\n",
       "      <td>Ma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num        word\n",
       "1914060               4  Hbanoticus\n",
       "1921063               8       Hppii\n",
       "1935567              14          Ma"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_epithet_match'] == True) & (vol2_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKED vol3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1553087</th>\n",
       "      <td>1</td>\n",
       "      <td>Krascheninnikovii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563802</th>\n",
       "      <td>6</td>\n",
       "      <td>Wagenitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564785</th>\n",
       "      <td>6</td>\n",
       "      <td>Fritsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573283</th>\n",
       "      <td>10</td>\n",
       "      <td>Holub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573581</th>\n",
       "      <td>11</td>\n",
       "      <td>Holub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575255</th>\n",
       "      <td>11</td>\n",
       "      <td>et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576974</th>\n",
       "      <td>12</td>\n",
       "      <td>Eichwaldii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577060</th>\n",
       "      <td>12</td>\n",
       "      <td>Schrank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580067</th>\n",
       "      <td>14</td>\n",
       "      <td>Kuntze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581446</th>\n",
       "      <td>14</td>\n",
       "      <td>Chav.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582572</th>\n",
       "      <td>15</td>\n",
       "      <td>Majoranamaracus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584228</th>\n",
       "      <td>16</td>\n",
       "      <td>Schiman-Czeika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584273</th>\n",
       "      <td>16</td>\n",
       "      <td>Czeika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590249</th>\n",
       "      <td>19</td>\n",
       "      <td>Berth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601261</th>\n",
       "      <td>24</td>\n",
       "      <td>DOteriifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606021</th>\n",
       "      <td>26</td>\n",
       "      <td>Turra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606701</th>\n",
       "      <td>26</td>\n",
       "      <td>Moretti,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608508</th>\n",
       "      <td>27</td>\n",
       "      <td>Fischer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608715</th>\n",
       "      <td>27</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num               word\n",
       "1553087               1  Krascheninnikovii\n",
       "1563802               6           Wagenitz\n",
       "1564785               6            Fritsch\n",
       "1573283              10              Holub\n",
       "1573581              11              Holub\n",
       "1575255              11                 et\n",
       "1576974              12         Eichwaldii\n",
       "1577060              12            Schrank\n",
       "1580067              14             Kuntze\n",
       "1581446              14              Chav.\n",
       "1582572              15    Majoranamaracus\n",
       "1584228              16     Schiman-Czeika\n",
       "1584273              16             Czeika\n",
       "1590249              19             Berth.\n",
       "1601261              24      DOteriifolium\n",
       "1606021              26              Turra\n",
       "1606701              26           Moretti,\n",
       "1608508              27            Fischer\n",
       "1608715              27                non"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_epithet_match'] == True) & (vol3_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1565502\n",
      "6 1566530\n",
      "11 1575196\n",
      "3 1575491\n",
      "12 1577219\n",
      "5 1579049\n",
      "11 1582112\n",
      "3 1583004\n",
      "6 1586355\n",
      "15 1586409\n",
      "13 1592477\n",
      "6 1608448\n",
      "3 1609139\n",
      "13 1610983\n",
      "3 1611188\n"
     ]
    }
   ],
   "source": [
    "# Eichwaldii, Krascheninnikovii, DOteriifolium (p should be p) -> oki \n",
    "# Majoranamaracus -> hybrid situation -> fixed later\n",
    "not_epithet_index_list = [1565497, 1566524, 1575185, 1575488, 1577207, 1579044, 1582101, 1583001, 1586349, 1586394, 1592464, 1608442, 1609136, 1610970, 1611185]\n",
    "\n",
    "for i in not_epithet_index_list:\n",
    "    vol3_char_df.loc[i : get_index_end(vol3_char_df, i),'potential_epithet_match'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1553087</th>\n",
       "      <td>1</td>\n",
       "      <td>Krascheninnikovii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563802</th>\n",
       "      <td>6</td>\n",
       "      <td>Wagenitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564785</th>\n",
       "      <td>6</td>\n",
       "      <td>Fritsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573283</th>\n",
       "      <td>10</td>\n",
       "      <td>Holub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573581</th>\n",
       "      <td>11</td>\n",
       "      <td>Holub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575255</th>\n",
       "      <td>11</td>\n",
       "      <td>et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576974</th>\n",
       "      <td>12</td>\n",
       "      <td>Eichwaldii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577060</th>\n",
       "      <td>12</td>\n",
       "      <td>Schrank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580067</th>\n",
       "      <td>14</td>\n",
       "      <td>Kuntze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581446</th>\n",
       "      <td>14</td>\n",
       "      <td>Chav.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582572</th>\n",
       "      <td>15</td>\n",
       "      <td>Majoranamaracus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584228</th>\n",
       "      <td>16</td>\n",
       "      <td>Schiman-Czeika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584273</th>\n",
       "      <td>16</td>\n",
       "      <td>Czeika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590249</th>\n",
       "      <td>19</td>\n",
       "      <td>Berth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601261</th>\n",
       "      <td>24</td>\n",
       "      <td>DOteriifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606021</th>\n",
       "      <td>26</td>\n",
       "      <td>Turra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606701</th>\n",
       "      <td>26</td>\n",
       "      <td>Moretti,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608508</th>\n",
       "      <td>27</td>\n",
       "      <td>Fischer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608715</th>\n",
       "      <td>27</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num               word\n",
       "1553087               1  Krascheninnikovii\n",
       "1563802               6           Wagenitz\n",
       "1564785               6            Fritsch\n",
       "1573283              10              Holub\n",
       "1573581              11              Holub\n",
       "1575255              11                 et\n",
       "1576974              12         Eichwaldii\n",
       "1577060              12            Schrank\n",
       "1580067              14             Kuntze\n",
       "1581446              14              Chav.\n",
       "1582572              15    Majoranamaracus\n",
       "1584228              16     Schiman-Czeika\n",
       "1584273              16             Czeika\n",
       "1590249              19             Berth.\n",
       "1601261              24      DOteriifolium\n",
       "1606021              26              Turra\n",
       "1606701              26           Moretti,\n",
       "1608508              27            Fischer\n",
       "1608715              27                non"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_epithet_match'] == True) & (vol3_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [**TODO FIX LATER**] epithet coord word has uppper case in the middle (but not the first letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_upper_not_first(word):\n",
    "    return word[1:].lower() != word[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1713635</th>\n",
       "      <td>1</td>\n",
       "      <td>peregrina(Hack.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713736</th>\n",
       "      <td>1</td>\n",
       "      <td>umbeUulata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732133</th>\n",
       "      <td>9</td>\n",
       "      <td>elatior'L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733993</th>\n",
       "      <td>10</td>\n",
       "      <td>sessUis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734796</th>\n",
       "      <td>11</td>\n",
       "      <td>pilosaHuds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738966</th>\n",
       "      <td>13</td>\n",
       "      <td>phleoides^Vill.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744667</th>\n",
       "      <td>15</td>\n",
       "      <td>albaL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749322</th>\n",
       "      <td>18</td>\n",
       "      <td>aegUops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750031</th>\n",
       "      <td>18</td>\n",
       "      <td>glaucaVahl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758235</th>\n",
       "      <td>22</td>\n",
       "      <td>auCheriana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num              word\n",
       "1713635               1  peregrina(Hack.)\n",
       "1713736               1        umbeUulata\n",
       "1732133               9        elatior'L.\n",
       "1733993              10           sessUis\n",
       "1734796              11       pilosaHuds.\n",
       "1738966              13  phleoides^Vill.)\n",
       "1744667              15            albaL.\n",
       "1749322              18           aegUops\n",
       "1750031              18        glaucaVahl\n",
       "1758235              22        auCheriana"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_epithet_match'] == True) & (vol1_char_df['word'].apply(has_upper_not_first))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1912660</th>\n",
       "      <td>4</td>\n",
       "      <td>corîdûpUcaÈu^Sretoï.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916475</th>\n",
       "      <td>6</td>\n",
       "      <td>securidacaiÇL.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940242</th>\n",
       "      <td>17</td>\n",
       "      <td>corymbulosum(Planch.)Reichenb.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951749</th>\n",
       "      <td>22</td>\n",
       "      <td>aqUatilis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num                            word\n",
       "1912660               4            corîdûpUcaÈu^Sretoï.\n",
       "1916475               6                 securidacaiÇL.)\n",
       "1940242              17  corymbulosum(Planch.)Reichenb.\n",
       "1951749              22                       aqUatilis"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_epithet_match'] == True) & (vol2_char_df['word'].apply(has_upper_not_first))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1566755</th>\n",
       "      <td>7</td>\n",
       "      <td>gaiUardotii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577865</th>\n",
       "      <td>13</td>\n",
       "      <td>albu^L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583549</th>\n",
       "      <td>15</td>\n",
       "      <td>sieberiC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584228</th>\n",
       "      <td>16</td>\n",
       "      <td>Schiman-Czeika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595344</th>\n",
       "      <td>21</td>\n",
       "      <td>desertiTUéh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601261</th>\n",
       "      <td>24</td>\n",
       "      <td>DOteriifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605792</th>\n",
       "      <td>26</td>\n",
       "      <td>agMmoniifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610246</th>\n",
       "      <td>28</td>\n",
       "      <td>'Abd-el-'asissi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num             word\n",
       "1566755               7      gaiUardotii\n",
       "1577865              13          albu^L.\n",
       "1583549              15        sieberiC.\n",
       "1584228              16   Schiman-Czeika\n",
       "1595344              21     desertiTUéh.\n",
       "1601261              24    DOteriifolium\n",
       "1605792              26   agMmoniifolium\n",
       "1610246              28  'Abd-el-'asissi"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_epithet_match'] == True) & (vol3_char_df['word'].apply(has_upper_not_first))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hardcoding Genus Platanthera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_num</th>\n",
       "      <th>char_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1746680</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746681</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746682</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746683</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746684</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746685</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word_num  char_num\n",
       "1746680         0         0\n",
       "1746681         0         1\n",
       "1746682         0         2\n",
       "1746683         0         3\n",
       "1746684         0         4\n",
       "1746685         0         5"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'] == 'Platan')][['word_num', 'char_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1761804"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "page_num     631\n",
       "block_num     87\n",
       "line_num       0\n",
       "Name: 1746680, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'] == 'Platan')][['page_num', 'block_num','line_num']].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>block_num</th>\n",
       "      <th>line_num</th>\n",
       "      <th>word</th>\n",
       "      <th>word_num</th>\n",
       "      <th>char</th>\n",
       "      <th>span_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1746680</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platan</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746681</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platan</td>\n",
       "      <td>0</td>\n",
       "      <td>l</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746682</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platan</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746683</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platan</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746684</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platan</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746685</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platan</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746686</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>thera</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746687</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>thera</td>\n",
       "      <td>1</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746688</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>thera</td>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746689</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>thera</td>\n",
       "      <td>1</td>\n",
       "      <td>r</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746690</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>thera</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         page_num  block_num  line_num    word  word_num char  span_num\n",
       "1746680       631         87         0  Platan         0    P         0\n",
       "1746681       631         87         0  Platan         0    l         0\n",
       "1746682       631         87         0  Platan         0    a         0\n",
       "1746683       631         87         0  Platan         0    t         0\n",
       "1746684       631         87         0  Platan         0    a         0\n",
       "1746685       631         87         0  Platan         0    n         0\n",
       "1746686       631         87         0   thera         1    t         0\n",
       "1746687       631         87         0   thera         1    h         0\n",
       "1746688       631         87         0   thera         1    e         0\n",
       "1746689       631         87         0   thera         1    r         0\n",
       "1746690       631         87         0   thera         1    a         0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['page_num'] == 631) & (vol1_char_df['block_num'] == 87) & (vol1_char_df['line_num'] == 0)][['page_num', 'block_num','line_num', 'word', 'word_num', 'char', 'span_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_char_df.loc[(vol1_char_df['page_num'] == 631) & (vol1_char_df['block_num'] == 87) & (vol1_char_df['line_num'] == 0),'potential_genus_match'] = True\n",
    "vol1_char_df.loc[(vol1_char_df['page_num'] == 631) & (vol1_char_df['block_num'] == 87) & (vol1_char_df['line_num'] == 0),'potential_epithet_match'] = False\n",
    "vol1_char_df.loc[(vol1_char_df['page_num'] == 631) & (vol1_char_df['block_num'] == 87) & (vol1_char_df['line_num'] == 0),'word_num'] = 0\n",
    "vol1_char_df.loc[(vol1_char_df['page_num'] == 631) & (vol1_char_df['block_num'] == 87) & (vol1_char_df['line_num'] == 0),'word'] = 'Platanthera'\n",
    "vol1_char_df.loc[(vol1_char_df['page_num'] == 631) & (vol1_char_df['block_num'] == 87) & (vol1_char_df['line_num'] == 0),'pruned_word'] = 'Platanthera'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Platanthera'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df.loc[1746680, 'word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep_cols = vol1_char_df.columns.difference([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"])\n",
    "# first_entry = vol1_char_df.loc[(vol1_char_df['page_num'] == 631) & (vol1_char_df['block_num'] == 87) & (vol1_char_df['line_num'] == 0)].iloc[0]\n",
    "# for col_name in keep_cols: \n",
    "#     print(vol1_char_df.loc[(vol1_char_df['page_num'] == 631) & (vol1_char_df['block_num'] == 87) & (vol1_char_df['line_num'] == 0), col_name], first_entry[col_name])\n",
    "#     vol1_char_df.loc[(vol1_char_df['page_num'] == 631) & (vol1_char_df['block_num'] == 87) & (vol1_char_df['line_num'] == 0), col_name] = first_entry[col_name]\n",
    "#     #print(first_entry[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>block_num</th>\n",
       "      <th>line_num</th>\n",
       "      <th>word</th>\n",
       "      <th>word_num</th>\n",
       "      <th>char</th>\n",
       "      <th>char_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1746680</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platanthera</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746681</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platanthera</td>\n",
       "      <td>0</td>\n",
       "      <td>l</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746682</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platanthera</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746683</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platanthera</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746684</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platanthera</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746685</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platanthera</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746686</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platanthera</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746687</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platanthera</td>\n",
       "      <td>0</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746688</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platanthera</td>\n",
       "      <td>0</td>\n",
       "      <td>e</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746689</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platanthera</td>\n",
       "      <td>0</td>\n",
       "      <td>r</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746690</th>\n",
       "      <td>631</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>Platanthera</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         page_num  block_num  line_num         word  word_num char  char_num\n",
       "1746680       631         87         0  Platanthera         0    P         0\n",
       "1746681       631         87         0  Platanthera         0    l         1\n",
       "1746682       631         87         0  Platanthera         0    a         2\n",
       "1746683       631         87         0  Platanthera         0    t         3\n",
       "1746684       631         87         0  Platanthera         0    a         4\n",
       "1746685       631         87         0  Platanthera         0    n         5\n",
       "1746686       631         87         0  Platanthera         0    t         0\n",
       "1746687       631         87         0  Platanthera         0    h         1\n",
       "1746688       631         87         0  Platanthera         0    e         2\n",
       "1746689       631         87         0  Platanthera         0    r         3\n",
       "1746690       631         87         0  Platanthera         0    a         4"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['page_num'] == 631) & (vol1_char_df['block_num'] == 87) & (vol1_char_df['line_num'] == 0)][['page_num', 'block_num','line_num', 'word', 'word_num', 'char', 'char_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make same \n",
    "# iterate -> char_num = list(range(df.shape[0]))\n",
    "# get max \n",
    "# get min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data(df, src_index, dst_indecies, col_name, inplace = True):\n",
    "    \"\"\" used for modifying columns of datatype that can be dirrectly assigned to multiple rows\n",
    "        INPUT: \n",
    "              - df: target dataframe to modify \n",
    "              - \n",
    "        OUTPUT: returns df \n",
    "    \"\"\"\n",
    "    if inplace == False:\n",
    "        df = df.copy()\n",
    "    \n",
    "    src_value = df.loc[src_index, col_name]\n",
    "    if isinstance(src_value, tuple):\n",
    "        df.loc[dst_indecies, col_name] = [src_value] * len(dst_indecies)\n",
    "    else: \n",
    "        df.loc[dst_indecies, col_name] = src_value\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_tuple_data(df, src_index, dst_indecies, col_name, inplace = True):\n",
    "    \"\"\" Used for modifying columns with lists/tuples\n",
    "        INPUT: \n",
    "              - df: target dataframe to modify \n",
    "              - \n",
    "        OUTPUT: returns df \n",
    "    \"\"\"\n",
    "    if inplace == False:\n",
    "        df = df.copy()\n",
    "    \n",
    "    src_value = df.loc[src_index, col_name]\n",
    "    df.loc[dst_indecies, col_name] = [src_value] * len(dst_indecies)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reiterate(df, src_index, dst_indecies, col_name, inplace = True):\n",
    "    \"\"\" Used for modifying columns with lists/tuples\n",
    "        INPUT: \n",
    "              - df: target dataframe to modify \n",
    "              - \n",
    "        OUTPUT: returns df \n",
    "    \"\"\"\n",
    "    if inplace == False:\n",
    "        df = df.copy()\n",
    "    \n",
    "    df.loc[dst_indecies, col_name] = list(range(len(dst_indecies)))\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_values(df, src_index, dst_indecies, col_name, transformations, inplace = True):\n",
    "    \"\"\" Used for modifying columns with lists/tuples\n",
    "        INPUT: \n",
    "              - df: target dataframe to modify \n",
    "              - \n",
    "        OUTPUT: returns df \n",
    "    \"\"\"\n",
    "    if inplace == False:\n",
    "        df = df.copy()\n",
    "\n",
    "    # if src_value is of type list or tuple or something like that, make sure transformations are available for each index or the size is 1. \n",
    "    # the apply transformations to each index\n",
    "    \n",
    "\n",
    "    df.loc[dst_indecies, col_name]\n",
    "\n",
    "    src_value = df.loc[src_index, col_name]\n",
    "    \n",
    "    df.loc[dst_indecies, col_name] = src_value\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bbox(df, indecies, col_name, inplace = True):\n",
    "    \"\"\" Used for modifying columns with lists/tuples\n",
    "        INPUT: \n",
    "              - df: target dataframe to modify \n",
    "              - \n",
    "        OUTPUT: returns df \n",
    "    \"\"\"\n",
    "    if inplace == False:\n",
    "        df = df.copy()\n",
    "\n",
    "    # if src_value is of type list or tuple or something like that, make sure transformations are available for each index or the size is 1. \n",
    "    # the apply transformations to each index\n",
    "    \n",
    "\n",
    "    x0 = df.loc[indecies, col_name].apply(lambda x: x[0]).min()\n",
    "    y0 = df.loc[indecies, col_name].apply(lambda x: x[1]).min()\n",
    "    x1 = df.loc[indecies, col_name].apply(lambda x: x[2]).max()\n",
    "    y1 = df.loc[indecies, col_name].apply(lambda x: x[3]).max()\n",
    "    \n",
    "\n",
    "    new_bbox = (x0, y0, x1, y1)\n",
    "    df.loc[indecies, col_name] = [new_bbox] * len(indecies)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_str(df, src_index, dst_indecies, col_name, inplace = True):\n",
    "    \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scientifiques'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df.loc[100, 'word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to fix anything vol_index_df.columns.difference([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Potential genus mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "potential genus match but name is not alphabetic or is of length < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_genus_name(word):\n",
    "    word_no_space = word.replace(\" \", \"\")\n",
    "    return ((not word_no_space.isalpha()) or (len(word_no_space) < 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1728448</th>\n",
       "      <td>8</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736085</th>\n",
       "      <td>11</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751898</th>\n",
       "      <td>19</td>\n",
       "      <td>j.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num word\n",
       "1728448               8    c\n",
       "1736085              11    f\n",
       "1751898              19   j."
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()\n",
    "#skipping over all these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1730950\n",
      "9 1738665\n",
      "4 1754708\n"
     ]
    }
   ],
   "source": [
    "not_genus_index_list_vol1 = [1730943, 1738656, 1754704]\n",
    "for i in not_genus_index_list_vol1:\n",
    "    vol1_char_df.loc[i : get_index_end(vol1_char_df, i),'potential_genus_match'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1728448</th>\n",
       "      <td>8</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736085</th>\n",
       "      <td>11</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751898</th>\n",
       "      <td>19</td>\n",
       "      <td>j.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num word\n",
       "1728448               8    c\n",
       "1736085              11    f\n",
       "1751898              19   j."
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1919791</th>\n",
       "      <td>7</td>\n",
       "      <td>•Ceratophyllum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920312</th>\n",
       "      <td>7</td>\n",
       "      <td>Chelidonium^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937882</th>\n",
       "      <td>16</td>\n",
       "      <td>Jussiaea-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938004</th>\n",
       "      <td>16</td>\n",
       "      <td>VV.1l.*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num            word\n",
       "1919791               7  •Ceratophyllum\n",
       "1920312               7    Chelidonium^\n",
       "1937882              16       Jussiaea-\n",
       "1938004              16         VV.1l.*"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_genus_match'] == True) & (vol2_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1939613\n"
     ]
    }
   ],
   "source": [
    "not_genus_index_list_vol2 = [1939606]\n",
    "for i in not_genus_index_list_vol2:\n",
    "    vol2_char_df.loc[i : get_index_end(vol2_char_df, i),'potential_genus_match'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1919791</th>\n",
       "      <td>7</td>\n",
       "      <td>•Ceratophyllum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920312</th>\n",
       "      <td>7</td>\n",
       "      <td>Chelidonium^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937882</th>\n",
       "      <td>16</td>\n",
       "      <td>Jussiaea-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938004</th>\n",
       "      <td>16</td>\n",
       "      <td>VV.1l.*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num            word\n",
       "1919791               7  •Ceratophyllum\n",
       "1920312               7    Chelidonium^\n",
       "1937882              16       Jussiaea-\n",
       "1938004              16         VV.1l.*"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_genus_match'] == True) & (vol2_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1558145</th>\n",
       "      <td>3</td>\n",
       "      <td>BallotaL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568136</th>\n",
       "      <td>8</td>\n",
       "      <td>CordiaL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582571</th>\n",
       "      <td>15</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599304</th>\n",
       "      <td>23</td>\n",
       "      <td>SolidagoL.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num        word\n",
       "1558145               3   BallotaL.\n",
       "1568136               8    CordiaL.\n",
       "1582571              15           x\n",
       "1599304              23  SolidagoL."
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_genus_match'] == True) & (vol3_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()\n",
    "#all okay and hybrid will get fixed later :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1728448          c\n",
       "1736085          f\n",
       "1751898         j.\n",
       "1751899         j.\n",
       "1756566    apetala\n",
       "1756567    apetala\n",
       "1756568    apetala\n",
       "1756569    apetala\n",
       "1756570    apetala\n",
       "1756571    apetala\n",
       "1756572    apetala\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'].apply(lambda x : x[0].isupper() == False))]['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_apetala_correcting = vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'].apply(lambda x : x[0].isupper() == False))].index\n",
    "vol1_char_df.loc[index_apetala_correcting,'potential_genus_match'] = False\n",
    "vol1_char_df.loc[index_apetala_correcting,'potential_epithet_match'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: word, dtype: object)"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'].apply(lambda x : x[0].isupper() == False))]['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1919791    •Ceratophyllum\n",
       "1919792    •Ceratophyllum\n",
       "1919793    •Ceratophyllum\n",
       "1919794    •Ceratophyllum\n",
       "1919795    •Ceratophyllum\n",
       "1919796    •Ceratophyllum\n",
       "1919797    •Ceratophyllum\n",
       "1919798    •Ceratophyllum\n",
       "1919799    •Ceratophyllum\n",
       "1919800    •Ceratophyllum\n",
       "1919801    •Ceratophyllum\n",
       "1919802    •Ceratophyllum\n",
       "1919803    •Ceratophyllum\n",
       "1919804    •Ceratophyllum\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fuzzy matching will fix\n",
    "vol2_char_df[(vol2_char_df['potential_genus_match'] == True) & (vol2_char_df['word'].apply(lambda x : x[0].isupper() == False))]['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1582571    x\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fixed later when hybrids identified \n",
    "vol3_char_df[(vol3_char_df['potential_genus_match'] == True) & (vol3_char_df['word'].apply(lambda x : x[0].isupper() == False))]['word']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pruning char_df and getting index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['potential_genus_match', 'potential_epithet_match', 'potential_infra_match']"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in vol1_char_df.columns if c.startswith('potential')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making sure page_num is in index\n",
    "#making sure the genus level word is not all uppercase (a family name)\n",
    "#making sure the pruned_word is not numeric (removing page_number as it's not in order usually) and removing page_num_coord_match\n",
    "\n",
    "all_vol_data = [(vol1_char_df, vol1_index),\n",
    "                (vol2_char_df, vol2_index),\n",
    "                (vol3_char_df, vol3_index)]\n",
    "\n",
    "result = [] \n",
    "ignore_word_list = [\"NOUVELLE\", \"Flore\", \"FLORE\", \"INDEX\", \"\"]\n",
    "for vol_char_df, vol_index in all_vol_data:\n",
    "    curr_result_df = vol_char_df[(vol_char_df['page_num'].isin(vol_index)) &\n",
    "                                (~((vol_char_df[\"word\"].str.isupper()) & (vol_char_df[\"word\"].apply(lambda x : len(x) > 2)) & (vol_char_df['genus_coord_match'] == True))) & \n",
    "                                (~(vol_char_df[\"pruned_word\"].isin(ignore_word_list))) &\n",
    "                                (~(vol_char_df[\"pruned_word\"].str.isnumeric() & (vol_char_df[\"word\"] != \"(3\"))) & \n",
    "                                (~(vol_char_df[\"page_num_coord_match\"] == True)) & \n",
    "                                (~((vol_char_df.groupby(['page_num', 'block_num', 'line_num'])['char_num'].transform('max') == 0) & (vol_char_df['word'].str.isupper())))\n",
    "                                ].copy()\n",
    "    result.append(curr_result_df)\n",
    "\n",
    "vol1_index_df, vol2_index_df, vol3_index_df = result[0], result[1], result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  5.79it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  6.22it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  6.47it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_PN_test = [(vol1_index_df, vol1_index, vol1_doc, \"valid_words_vol1\"),\n",
    "                        (vol2_index_df, vol2_index, vol2_doc, \"valid_words_vol2\"),\n",
    "                        (vol3_index_df, vol3_index, vol3_doc, \"valid_words_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_PN_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        temp_coords = vol_char_df[vol_char_df['page_num'] == page_num]['word_bbox'].drop_duplicates()\n",
    "        for coord in temp_coords:\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=3)\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keeping word level\n",
    "vol_index_df_list = [vol1_index_df, vol2_index_df, vol3_index_df]\n",
    "result_df = []\n",
    "for vol_index_df in vol_index_df_list:\n",
    "    keep_cols = vol_index_df.columns.difference([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"], sort=False).tolist()\n",
    "\n",
    "    vol_index_df = vol_index_df.copy().loc[:,keep_cols].drop_duplicates().reset_index()\n",
    "    vol_index_df.rename(columns={\"index\": \"char_index\"}, inplace = True)\n",
    "    result_df.append(vol_index_df)\n",
    "\n",
    "vol1_index_df, vol2_index_df, vol3_index_df = result_df[0], result_df[1], result_df[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_hybrid_symbols(word):\n",
    "    infra_symbols = r\"^X[\\s|.|\\b]?$|^x[\\s|.|\\b]?$|^×[\\s|.|\\b]?$\"\n",
    "    return re.search(infra_symbols, word) != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_hybrids = []\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['is_hybrid'] = np.NaN\n",
    "    vol_index_df.loc[(vol_index_df['potential_infra_match'] == True) | (vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True), 'is_hybrid'] = (vol_index_df['word'].apply(has_hybrid_symbols) == True) & ((vol_index_df['potential_infra_match'] == True) | (vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True))\n",
    "    \n",
    "    hybrid_genera_indecies = vol_index_df[(vol_index_df['potential_genus_match'] == True) & (vol_index_df['word'].apply(has_hybrid_symbols) == True)].index + 1\n",
    "    hybrid_epithet_indecies = vol_index_df[(vol_index_df['potential_epithet_match'] == True) & (vol_index_df['word'].apply(has_hybrid_symbols) == True)].index + 1\n",
    "    \n",
    "    vol_index_df.loc[hybrid_epithet_indecies, 'is_hybrid'] = True\n",
    "    vol_index_df.loc[hybrid_epithet_indecies, 'potential_epithet_match'] = True \n",
    "\n",
    "    vol_index_df.loc[hybrid_genera_indecies, 'is_hybrid'] = True\n",
    "    vol_index_df.loc[hybrid_genera_indecies, 'potential_genus_match'] = True\n",
    "\n",
    "    drop_list = list(hybrid_epithet_indecies - 1) + list(hybrid_genera_indecies -1)\n",
    "    \n",
    "    vol_index_df = vol_index_df[~vol_index_df.index.isin(drop_list)].copy()\n",
    "    #vol_index_df['is_hybrid'].ffill(inplace=True) fowrward fill after checking hybrid for the infra species types too\n",
    "\n",
    "    result_df_hybrids.append(vol_index_df)\n",
    "\n",
    "vol1_index_df, vol2_index_df, vol3_index_df = result_df_hybrids[0], result_df_hybrids[1], result_df_hybrids[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['closest_epithet_v2'] = np.nan\n",
    "def extract_potential_genus_names(row):\n",
    "    if row['potential_genus_match'] == True:\n",
    "        return row['word'] + \"_\" + str(row['page_num']) + \"_\" + str(row['block_num']) + \"_\" + str(row['line_num'])\n",
    "    else:\n",
    "        return np.nan\n",
    "        \n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['closest_genus'] = vol_index_df.apply(extract_potential_genus_names, axis = 1)\n",
    "    vol_index_df['closest_genus'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['closest_epithet_v2'] = np.nan\n",
    "def extract_potential_epithet_names(row):\n",
    "    if row['potential_epithet_match'] == True:\n",
    "        return row['word'] + \"_\" + str(row['page_num']) + \"_\" + str(row['block_num']) + \"_\" + str(row['line_num'])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['closest_epithet'] = vol_index_df.apply(extract_potential_epithet_names, axis = 1)\n",
    "    vol_index_df.loc[vol_index_df['potential_genus_match'] == True, 'closest_epithet'] = -1\n",
    "    vol_index_df['closest_epithet'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_potential_infra_type(row):\n",
    "    if row['potential_infra_match'] == True:\n",
    "        return row['word'] + \"_\" + str(row['page_num']) + \"_\" + str(row['block_num']) + \"_\" + str(row['line_num'])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df.loc[(vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True), 'closest_infra_type'] = -1\n",
    "    vol_index_df['closest_infra_type'] = vol_index_df.apply(extract_potential_infra_type, axis = 1)\n",
    "    vol_index_df.loc[(vol_index_df['potential_infra_match'] == False) & ((vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True)), 'closest_infra_type'] = -1\n",
    "    vol_index_df['closest_infra_type'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    infra_name_match_indecies = vol_index_df[vol_index_df['potential_infra_match'] == True].index + 1\n",
    "    vol_index_df['closest_infra_name'] = np.NaN\n",
    "    vol_index_df.loc[infra_name_match_indecies, 'closest_infra_name'] = vol_index_df.apply(lambda row : row['word'] + \"_\" + str(row['page_num']) + \"_\" + str(row['block_num']) + \"_\" + str(row['line_num']) , axis = 1)\n",
    "    vol_index_df['potential_infra_name_match'] = vol_index_df.index.isin(infra_name_match_indecies)\n",
    "    vol_index_df.loc[(vol_index_df['potential_infra_match'] == True) | (vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True), 'closest_infra_name'] = -1\n",
    "    vol_index_df['closest_infra_name'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    cond = ((vol_index_df['closest_infra_name'] != '') | (vol_index_df['closest_infra_name'] != -1) | (~vol_index_df['closest_infra_name'].isna())) & \\\n",
    "           (vol_index_df['word'].apply(has_hybrid_symbols) == True)\n",
    "    \n",
    "    vol_index_df.loc[cond, 'is_hybrid'] = True\n",
    "    vol_index_df['is_hybrid'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['potential_author_match'] = (vol_index_df['potential_genus_match'] == False) & \\\n",
    "                                             (vol_index_df['potential_epithet_match'] == False) & \\\n",
    "                                             (vol_index_df['potential_infra_match'] == False) & \\\n",
    "                                             (vol_index_df['potential_infra_name_match'] == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df.replace(-1, np.NaN, inplace = True)\n",
    "    vol_index_df.replace(np.NaN, \"\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "#author grouping \n",
    "# \n",
    "author_grouping = ['closest_genus', 'closest_epithet', 'closest_infra_name']\n",
    "merge_on = ['closest_genus', 'closest_epithet', 'closest_infra_name']\n",
    "def concatenate(group):\n",
    "    return group.loc[group['potential_author_match'] == True, 'word'].str.cat(sep=' ')\n",
    "\n",
    "result_df_authors = [] \n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]: \n",
    "    #author_grouping = ['closest_genus', 'closest_epithet']\n",
    "    #merge_on = ['closest_genus', 'closest_epithet']\n",
    "    groups = vol_index_df.groupby(author_grouping)\n",
    "    concatenated = groups.apply(concatenate).reset_index()\n",
    "\n",
    "    # add the concatenated values to the original dataframe\n",
    "    result = vol_index_df.merge(concatenated[merge_on + [0]], on=merge_on, how='left').rename(columns={0: 'authors'})\n",
    "    result_df_authors.append(result)\n",
    "    \n",
    "vol1_index_df, vol2_index_df, vol3_index_df = result_df_authors[0], result_df_authors[1], result_df_authors[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "#     #vol_index_df.replace(\"\", np.NaN,inplace = True)\n",
    "#     vol_index_df.replace(np.NaN, \"\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  4.72it/s]\n",
      "100%|██████████| 22/22 [00:04<00:00,  4.76it/s]\n",
      "100%|██████████| 28/28 [00:05<00:00,  4.86it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_cat_test = [(vol1_index_df, vol1_index, vol1_doc, \"catagorized_vol1\"),\n",
    "                         (vol2_index_df, vol2_index, vol2_doc, \"catagorized_vol2\"),\n",
    "                         (vol3_index_df, vol3_index, vol3_doc, \"catagorized_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_cat_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        for col_num in [0, 1]:\n",
    "            temp_df = vol_char_df[(vol_char_df['page_num'] == page_num) & (vol_char_df['col_num'] == col_num)]\n",
    "            #genus Coord is orange-pinkish, 5\n",
    "            for name, group in temp_df.groupby(['closest_genus'])['word_bbox']:\n",
    "                x0 = (group.apply(lambda x : x[0]).min())*TARGET_DPI/ 72\n",
    "                y0 = (group.apply(lambda x : x[1]).min())*TARGET_DPI/ 72\n",
    "                x1 = (group.apply(lambda x : x[2]).max())*TARGET_DPI/ 72\n",
    "                y1 = (group.apply(lambda x : x[3]).max())*TARGET_DPI/ 72\n",
    "                draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#6939a3\"), width=3)\n",
    "\n",
    "            for name, group in temp_df.groupby(['closest_epithet'])['word_bbox']:\n",
    "                if name != '':\n",
    "                    x0 = (group.apply(lambda x : x[0]).min())*TARGET_DPI/ 72\n",
    "                    y0 = (group.apply(lambda x : x[1]).min())*TARGET_DPI/ 72\n",
    "                    x1 = (group.apply(lambda x : x[2]).max())*TARGET_DPI/ 72\n",
    "                    y1 = (group.apply(lambda x : x[3]).max())*TARGET_DPI/ 72\n",
    "                    draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=3)\n",
    "\n",
    "            for name, group in temp_df.groupby(['closest_infra_name'])['word_bbox']:\n",
    "                if name != '':\n",
    "                    x0 = (group.apply(lambda x : x[0]).min())*TARGET_DPI/ 72\n",
    "                    y0 = (group.apply(lambda x : x[1]).min())*TARGET_DPI/ 72\n",
    "                    x1 = (group.apply(lambda x : x[2]).max())*TARGET_DPI/ 72\n",
    "                    y1 = (group.apply(lambda x : x[3]).max())*TARGET_DPI/ 72\n",
    "                    draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#8c690b\"), width=3)\n",
    "\n",
    "            temp_df_author_only = temp_df[temp_df['potential_author_match'] == True]\n",
    "            for name, group in temp_df_author_only.groupby(['closest_genus', 'closest_epithet', 'closest_infra_name'])['word_bbox']:\n",
    "                x0 = (group.apply(lambda x : x[0]).min())*TARGET_DPI/ 72\n",
    "                y0 = (group.apply(lambda x : x[1]).min())*TARGET_DPI/ 72\n",
    "                x1 = (group.apply(lambda x : x[2]).max())*TARGET_DPI/ 72\n",
    "                y1 = (group.apply(lambda x : x[3]).max())*TARGET_DPI/ 72\n",
    "\n",
    "                draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#9e9e9e\"), width=3)\n",
    "\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_words(word):\n",
    "    head, sep, tail = word.partition('_')\n",
    "    return head \n",
    "\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['closest_genus'] = vol_index_df['closest_genus'].apply(fix_words)\n",
    "    vol_index_df['closest_epithet'] = vol_index_df['closest_epithet'].apply(fix_words)\n",
    "    vol_index_df['closest_infra_type'] = vol_index_df['closest_infra_type'].apply(fix_words)\n",
    "    vol_index_df['closest_infra_name'] = vol_index_df['closest_infra_name'].apply(fix_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_prune_authors_list = []\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    result_prune_authors = vol_index_df[(vol_index_df['potential_genus_match'] == True) |\n",
    "                                        (vol_index_df['potential_epithet_match'] == True) |\n",
    "                                        (vol_index_df['potential_infra_name_match'] == True)].copy()\n",
    "    result_prune_authors_list.append(result_prune_authors)\n",
    "\n",
    "prune_authors_vol1, prune_authors_vol2, prune_authors_vol3 =  result_prune_authors_list[0], result_prune_authors_list[1], result_prune_authors_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick fix for vol1 epithet on the same line as author situation\n",
    "cond = (prune_authors_vol1['closest_genus'] != '') & (prune_authors_vol1['closest_epithet'] == '') & (prune_authors_vol1['authors'] != '')\n",
    "prune_authors_vol1.loc[cond, 'closest_epithet'] = prune_authors_vol1.loc[cond,'authors'].str.split().apply(lambda s: s[0])\n",
    "prune_authors_vol1.loc[cond, 'authors'] = prune_authors_vol1.loc[cond,'authors'].str.split().apply(lambda s: \" \".join(s[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxon_rank_specific(row):\n",
    "    has_genus = (pd.isnull(row['closest_genus']) == False) & (row['closest_genus'] != \"\") & (row['closest_genus'] != -1)\n",
    "    has_epithet = (pd.isnull(row['closest_epithet']) == False) & (row['closest_epithet'] != \"\") & (row['closest_epithet'] != -1)\n",
    "    \n",
    "    has_infra = (pd.isnull(row['closest_infra_name']) == False) & (row['closest_infra_name'] != \"\") & (row['closest_infra_name'] != -1)\n",
    "    has_infra_type = (pd.isnull(row['closest_infra_type']) == False) & (row['closest_infra_type'] != \"\") & (row['closest_infra_type'] != -1)\n",
    "    infra_type = row['closest_infra_type']\n",
    "    is_infra_hybrid = has_hybrid_symbols(row['closest_infra_type']) == True\n",
    "    if is_infra_hybrid:\n",
    "        infra_type = \"hybrid\"\n",
    "    \n",
    "    is_hybrid  = row['is_hybrid'] == True\n",
    "    prefix  = \"\"\n",
    "    if is_hybrid:\n",
    "        prefix = \"hybrid \"\n",
    "\n",
    "    if has_infra or has_infra_type:\n",
    "        return f\"infra ({infra_type})\"\n",
    "    if has_epithet:\n",
    "        return prefix + \"epithet\"\n",
    "    if has_genus:\n",
    "        return prefix + \"genus\"\n",
    "\n",
    "def get_taxon_rank_general(row):\n",
    "    has_genus = (pd.isnull(row['closest_genus']) == False) & (row['closest_genus'] != \"\") & (row['closest_genus'] != -1)\n",
    "    has_epithet = (pd.isnull(row['closest_epithet']) == False) & (row['closest_epithet'] != \"\") & (row['closest_epithet'] != -1)\n",
    "    has_infra = (pd.isnull(row['closest_infra_name']) == False) & (row['closest_infra_name'] != \"\") & (row['closest_infra_name'] != -1)\n",
    "    has_infra_type = (pd.isnull(row['closest_infra_type']) == False) & (row['closest_infra_type'] != \"\") & (row['closest_infra_type'] != -1)\n",
    "    \n",
    "    if has_infra or has_infra_type:\n",
    "        return \"infra\"\n",
    "    if has_epithet:\n",
    "        return \"epithet\"\n",
    "    if has_genus:\n",
    "        return \"genus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_authors_vol1['closest_genus'] = prune_authors_vol1['closest_genus'].str.replace(\"œ\", \"oe\" )\n",
    "prune_authors_vol2['closest_genus'] = prune_authors_vol2['closest_genus'].str.replace(\"œ\", \"oe\" )\n",
    "prune_authors_vol3['closest_genus'] = prune_authors_vol3['closest_genus'].str.replace(\"œ\", \"oe\" )\n",
    "\n",
    "prune_authors_vol1['closest_epithet'] = prune_authors_vol1['closest_epithet'].str.replace(\"œ\", \"oe\" )\n",
    "prune_authors_vol2['closest_epithet'] = prune_authors_vol2['closest_epithet'].str.replace(\"œ\", \"oe\" )\n",
    "prune_authors_vol3['closest_epithet'] = prune_authors_vol3['closest_epithet'].str.replace(\"œ\", \"oe\" )\n",
    "\n",
    "prune_authors_vol1['closest_infra_name'] = prune_authors_vol1['closest_infra_name'].str.replace(\"œ\", \"oe\" )\n",
    "prune_authors_vol2['closest_infra_name'] = prune_authors_vol2['closest_infra_name'].str.replace(\"œ\", \"oe\" )\n",
    "prune_authors_vol3['closest_infra_name'] = prune_authors_vol3['closest_infra_name'].str.replace(\"œ\", \"oe\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol_index_df in [prune_authors_vol1, prune_authors_vol2, prune_authors_vol3]:\n",
    "    vol_index_df['taxon_rank'] = vol_index_df.apply(get_taxon_rank_general, axis = 1)\n",
    "    vol_index_df['taxon_rank_detailed'] = vol_index_df.apply(get_taxon_rank_specific, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_vol1 = prune_authors_vol1[['closest_genus',\n",
    "                                      'closest_epithet',\n",
    "                                      'closest_infra_name',\n",
    "                                      'authors',\n",
    "                                      'taxon_rank',\n",
    "                                      'taxon_rank_detailed']]\n",
    "simplified_vol1.to_csv('../output/local/index_output/vol1_index_output.csv')\n",
    "\n",
    "simplified_vol2 = prune_authors_vol2[['closest_genus',\n",
    "                                      'closest_epithet',\n",
    "                                      'closest_infra_name',\n",
    "                                      'authors',\n",
    "                                      'taxon_rank',\n",
    "                                      'taxon_rank_detailed']]\n",
    "simplified_vol2.to_csv('../output/local/index_output/vol2_index_output.csv')\n",
    "                                \n",
    "simplified_vol3 = prune_authors_vol3[['closest_genus',\n",
    "                                      'closest_epithet',\n",
    "                                      'closest_infra_name',\n",
    "                                      'authors',\n",
    "                                      'taxon_rank',\n",
    "                                      'taxon_rank_detailed']]\n",
    "simplified_vol3.to_csv('../output/local/index_output/vol3_index_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_italics_simplified_vol1 = prune_authors_vol1.loc[(prune_authors_vol1['span_flags'] != 6),\n",
    "                                                     ['closest_genus',\n",
    "                                                      'closest_epithet',\n",
    "                                                      'closest_infra_name',\n",
    "                                                      'authors',\n",
    "                                                      'taxon_rank',\n",
    "                                                      'taxon_rank_detailed']]\n",
    "non_italics_simplified_vol1.to_csv('../output/local/index_output/vol1_nonitalics.csv')\n",
    "\n",
    "non_italics_simplified_vol2 = prune_authors_vol2.loc[(prune_authors_vol2['span_flags'] != 6),\n",
    "                                                     ['closest_genus',\n",
    "                                                      'closest_epithet',\n",
    "                                                      'closest_infra_name',\n",
    "                                                      'authors',\n",
    "                                                      'taxon_rank',\n",
    "                                                      'taxon_rank_detailed']]\n",
    "non_italics_simplified_vol2.to_csv('../output/local/index_output/vol2_nonitalics.csv')\n",
    "\n",
    "non_italics_simplified_vol3 = prune_authors_vol3.loc[(prune_authors_vol3['span_flags'] != 6),\n",
    "                                                     ['closest_genus',\n",
    "                                                      'closest_epithet',\n",
    "                                                      'closest_infra_name',\n",
    "                                                      'authors',\n",
    "                                                      'taxon_rank',\n",
    "                                                      'taxon_rank_detailed']]\n",
    "non_italics_simplified_vol3.to_csv('../output/local/index_output/vol3_nonitalics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
