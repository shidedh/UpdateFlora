{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING BOOKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_path = '../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 1.pdf'\n",
    "vol2_path = '../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 2.pdf'\n",
    "vol3_path = '../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 3.pdf'\n",
    "\n",
    "vol1_doc = fitz.open(vol1_path)\n",
    "vol2_doc = fitz.open(vol2_path)\n",
    "vol3_doc = fitz.open(vol3_path)\n",
    "\n",
    "vol1_pages = [vol1_doc[i] for i in range(vol1_doc.page_count)]\n",
    "vol2_pages = [vol2_doc[i] for i in range(vol2_doc.page_count)]\n",
    "vol3_pages = [vol3_doc[i] for i in range(vol3_doc.page_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_char_df = pd.read_pickle(\"../input/char_df/vol1_df.pkl\")\n",
    "vol2_char_df = pd.read_pickle(\"../input/char_df/vol2_df.pkl\")\n",
    "vol3_char_df = pd.read_pickle(\"../input/char_df/vol3_df.pkl\")\n",
    "\n",
    "vol1_index = list(range(616, 639)) #inclusive\n",
    "vol2_index = list(range(703, 725))\n",
    "vol3_index = list(range(555, 583))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DPI = 300\n",
    "mat = fitz.Matrix(TARGET_DPI/ 72, TARGET_DPI/ 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding strict matching genera, epithet, and column numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genus_match(row):\n",
    "    word_rspace_removed = row['word'].rstrip()\n",
    "    return row['word_num'] == 0 and \\\n",
    "           word_rspace_removed.isalpha() and \\\n",
    "           word_rspace_removed[0].isupper() and word_rspace_removed[1:].islower()\n",
    "           \n",
    "def epithet_match(row):\n",
    "    word_rspace_removed = row['word'].rstrip()\n",
    "    return row['word_num'] == 0 and \\\n",
    "           word_rspace_removed.isalpha() and \\\n",
    "           word_rspace_removed.islower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rightmost point of any bounding box:\n",
    "def get_center_x0(vol_char_df, page_num, bias = 30):\n",
    "    \"\"\"WARNING: Bias = 30 large bias causes miscatagorization in page number in book\"\"\"\n",
    "    df = vol_char_df[vol_char_df['page_num'] == page_num]\n",
    "    \n",
    "    right_bound = df['line_bbox'].apply(lambda x : x[2]).max() \n",
    "    #leftmost point of any bounding box:\n",
    "    left_bound = df['line_bbox'].apply(lambda x : x[0]).min()\n",
    "\n",
    "    return 0.5*(right_bound + left_bound) - bias\n",
    "\n",
    "\n",
    "def get_col_num(coords, center_x0):\n",
    "    x0, y0, x1, y1 = coords\n",
    "    return int(x0 >= center_x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:12<00:00,  1.78it/s]\n",
      "100%|██████████| 22/22 [00:13<00:00,  1.62it/s]\n",
      "100%|██████████| 28/28 [00:14<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_col_num = [(vol1_char_df, vol1_index, vol1_doc),\n",
    "                        (vol2_char_df, vol2_index, vol2_doc),\n",
    "                        (vol3_char_df, vol3_index, vol3_doc)]\n",
    "\n",
    "for vol_char_df ,vol_index, doc in all_vol_data_col_num: \n",
    "    #for each volume check if genus pattern / epithet pattern exists within the index part of the book\n",
    "    vol_char_df['genus_index_pat_match'] = (vol_char_df['page_num'].isin(vol_index)) & (vol_char_df.apply(genus_match, axis = 1))\n",
    "    vol_char_df['epithet_index_pat_match'] = (vol_char_df['page_num'].isin(vol_index)) & (vol_char_df.apply(epithet_match, axis = 1))\n",
    "    \n",
    "    for page_num in tqdm(vol_index):\n",
    "        center_x0 = get_center_x0(vol_char_df, page_num)\n",
    "        #find center based on x0 coordinate of each line\n",
    "        vol_char_df['col_num'] = vol_char_df['line_bbox'].apply(lambda coords : get_col_num(coords, center_x0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genus / epithet flagging \n",
    "flagging pages where number of strict genus or epithet patern matches is less than 3 per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***FLAGS***\n",
      " number of pages to check: 3\n",
      "  genera\n",
      "\t number of genera: 1, page number: 2, column number: 0\n",
      "\t number of genera: 0, page number: 20, column number: 1\n",
      "\t number of genera: 1, page number: 23, column number: 0\n",
      "  epithets\n",
      "\t number of epithets: 2, page number: 23, column number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:03<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***FLAGS***\n",
      " number of pages to check: 2\n",
      "  genera\n",
      "\t number of genera: 2, page number: 4, column number: 0\n",
      "\t number of genera: 1, page number: 4, column number: 1\n",
      "\t number of genera: 0, page number: 5, column number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:04<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***FLAGS***\n",
      " number of pages to check: 7\n",
      "  genera\n",
      "\t number of genera: 1, page number: 2, column number: 1\n",
      "\t number of genera: 1, page number: 6, column number: 0\n",
      "\t number of genera: 1, page number: 21, column number: 0\n",
      "\t number of genera: 1, page number: 22, column number: 0\n",
      "\t number of genera: 2, page number: 24, column number: 1\n",
      "\t number of genera: 0, page number: 26, column number: 1\n",
      "\t number of genera: 2, page number: 28, column number: 0\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_flagg_strict_match = [(vol1_char_df, vol1_index, vol1_doc, \"strickt_match_vol1\"),\n",
    "                                   (vol2_char_df, vol2_index, vol2_doc, \"strickt_match_vol2\"),\n",
    "                                   (vol3_char_df, vol3_index, vol3_doc, \"strickt_match_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, vol_doc, output_name in all_vol_data_flagg_strict_match: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "    genus_flag_list = []\n",
    "    epithet_flag_list = []\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = vol_doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        genus_db = vol_char_df[(vol_char_df['page_num'] == page_num)\n",
    "                                & (vol_char_df['genus_index_pat_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['epithet_index_pat_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #genus pattern match flag should check with half page and not entire page:\n",
    "        for col in range(2):\n",
    "            num_genus_col = genus_db[genus_db[\"col_num\"] == col].shape[0]\n",
    "            num_epithet_col = epithet_db[epithet_db[\"col_num\"] == col].shape[0]\n",
    "            if num_genus_col <= 2:\n",
    "                genus_flag_list.append((num_genus_col, page_num - vol_index[0] + 1, col))\n",
    "            if num_epithet_col <= 2:\n",
    "                epithet_flag_list.append((num_epithet_col, page_num - vol_index[0] + 1, col))\n",
    "\n",
    "        for coord in genus_db['word_bbox']:\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "\n",
    "        for coord in epithet_db['word_bbox']:\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=5)\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])    \n",
    "    \n",
    "    num_flag_pages = len(set([g[1] for g in genus_flag_list] + [e[1] for e in epithet_flag_list]))\n",
    "    if num_flag_pages > 0: \n",
    "        print(\"***FLAGS***\")\n",
    "        print(f\" number of pages to check: {num_flag_pages}\")\n",
    "        if genus_flag_list:\n",
    "            print(\"  genera\")\n",
    "            [print(f\"\\t number of genera: {g_flag[0]}, page number: {g_flag[1]}, column number: {g_flag[2]}\") for g_flag in genus_flag_list]\n",
    "        if epithet_flag_list:\n",
    "            print(\"  epithets\")\n",
    "            [print(f\"\\t number of epithets: {e_flag[0]}, page number: {e_flag[1]}, column number: {e_flag[2]}\") for e_flag in epithet_flag_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on flags need to make sure: \n",
    "- first find epithet coord match \n",
    "- then find genus coord match s.t. word is not in epithet coord match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### match based on coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_coord_match(x, x_ref_left, x_ref_right, margin):\n",
    "    return (x_ref_left - margin <= x[0] and x[0] <= x_ref_left + margin) or (x_ref_right - margin <= x[0] and x[0] <= x_ref_right + margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### epithets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 23.74it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 22.34it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 25.63it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "                            (vol2_char_df, vol2_index),\n",
    "                            (vol3_char_df, vol3_index)]\n",
    "\n",
    "for vol_char_df, vol_index in all_vol_data_coord_match: \n",
    "    vol_char_df[\"epithet_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"epithet_index_pat_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        epithet_char_df = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"epithet_index_pat_match\"] == True)]\n",
    "        epithet_df = epithet_char_df.loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"])].drop_duplicates()\n",
    "        page_epithet_2dic = [{}, {}]\n",
    "        \n",
    "        for i in range(epithet_df.shape[0]):\n",
    "            e_index = str(page_num) + \"_\" + str(i)\n",
    "            p0 = epithet_df['word_bbox'].iloc[i]\n",
    "            x_ref = p0[0]\n",
    "            col = epithet_df['col_num'].iloc[i]\n",
    "\n",
    "            ref_neighbors_df = epithet_df[(epithet_df[\"page_num\"] == page_num) & \n",
    "                                          (epithet_df[\"word_bbox\"].apply(lambda x : x_ref - margin <= x[0] and x[0] <= x_ref + margin))]\n",
    "            \n",
    "            num_neighbors = ref_neighbors_df.shape[0]\n",
    "            mean_neighbors = ref_neighbors_df[\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            page_epithet_2dic[col][e_index] = (num_neighbors, mean_neighbors)\n",
    "        \n",
    "        mean_left_epithet = max(page_epithet_2dic[0].values(), default = [-1, -1])[1]\n",
    "        mean_right_epithet = max(page_epithet_2dic[1].values(), default = [-1, -1])[1]\n",
    "\n",
    "        if mean_left_epithet == -1 or mean_right_epithet == -1:\n",
    "            mean_valid_col = max(mean_left_epithet, mean_right_epithet)\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"epithet_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_valid_col, mean_valid_col, margin))\n",
    "        elif mean_left_epithet == -1 and mean_right_epithet == -1:\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"epithet_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : False)\n",
    "        else: \n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"epithet_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_left_epithet, mean_right_epithet, margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  5.78it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  5.82it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  5.97it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_epithet_coord_match_test = [(vol1_char_df, vol1_index, vol1_doc, \"epithet_coord_match_pruned_vol1\"),\n",
    "                                         (vol2_char_df, vol2_index, vol2_doc, \"epithet_coord_match_pruned_vol2\"),\n",
    "                                         (vol3_char_df, vol3_index, vol3_doc, \"epithet_coord_match_pruned_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_epithet_coord_match_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "    \n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        epithet_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['epithet_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['epithet_index_pat_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #epithet Coord is orange-pinkish, 5\n",
    "        for coord in epithet_coord_db[\"pruned_word_bbox\"] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "\n",
    "        #epithet is blue, 3\n",
    "        for coord in epithet_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=3)\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 31.22it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 29.42it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 34.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reminder:\n",
    "# all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "#                             (vol2_char_df, vol2_index),\n",
    "#                             (vol3_char_df, vol3_index)]\n",
    "# DOES NOT CHECK IF COORD IS SAME AS EPITHET UNTIL NEXT SECTION!\n",
    "\n",
    "for vol_char_df, vol_index in all_vol_data_coord_match: \n",
    "    #genus and not epithet\n",
    "    vol_char_df[\"genus_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"genus_index_pat_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        genus_char_df = vol_char_df[(vol_char_df[\"page_num\"] == page_num) &\n",
    "                                    (vol_char_df[\"genus_index_pat_match\"] == True)]\n",
    "        genus_df = genus_char_df.loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"])].drop_duplicates()\n",
    "        page_genus_2dic = [{}, {}]\n",
    "        \n",
    "        epithet_left_coord_mean = vol_char_df[(vol_char_df[\"epithet_coord_match\"] == True) &\n",
    "                                              (vol_char_df[\"page_num\"] == page_num) &\n",
    "                                              (vol_char_df[\"col_num\"] == 0)\n",
    "                                             ]['pruned_word_bbox'].apply(lambda x : x[0]).mean()\n",
    "        epithet_right_coord_mean = vol_char_df[(vol_char_df[\"epithet_coord_match\"] == True) &\n",
    "                                               (vol_char_df[\"page_num\"] == page_num) &\n",
    "                                               (vol_char_df[\"col_num\"] == 1)\n",
    "                                             ]['pruned_word_bbox'].apply(lambda x : x[0]).mean()\n",
    "        epithet_coord_mean_list = [epithet_left_coord_mean, epithet_right_coord_mean]\n",
    "\n",
    "        for i in range(genus_df.shape[0]):\n",
    "            g_index = str(page_num) + \"_\" + str(i)\n",
    "            p0 = genus_df['word_bbox'].iloc[i]\n",
    "            x_ref = p0[0]\n",
    "            col = genus_df['col_num'].iloc[i]\n",
    "\n",
    "            ref_neighbors_df = genus_df[(genus_df[\"page_num\"] == page_num) & \n",
    "                                        (genus_df[\"word_bbox\"].apply(lambda x : x_ref - margin <= x[0] and x[0] <= x_ref + margin))]\n",
    "\n",
    "            num_neighbors = ref_neighbors_df.shape[0]\n",
    "            mean_neighbors = ref_neighbors_df[\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            if mean_neighbors > epithet_coord_mean_list[col]: \n",
    "                mean_neighbors = -1\n",
    "            page_genus_2dic[col][g_index] = (num_neighbors, mean_neighbors)\n",
    "        \n",
    "        mean_left_genus = max(page_genus_2dic[0].values(), default = [-1, -1])[1]\n",
    "        mean_right_genus = max(page_genus_2dic[1].values(), default = [-1, -1])[1]\n",
    "\n",
    "        if mean_left_genus == -1 or mean_right_genus == -1:\n",
    "            mean_valid_col = max(mean_left_genus, mean_right_genus)\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"genus_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_valid_col, mean_valid_col, margin))\n",
    "        elif mean_left_genus == -1 and mean_right_genus == -1:\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"genus_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : False)\n",
    "        else: \n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"genus_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_left_genus, mean_right_genus, margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  5.79it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  5.84it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  6.12it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_genus_coord_match_test = [(vol1_char_df, vol1_index, vol1_doc, \"genus_coord_match_vol1\"),\n",
    "                                       (vol2_char_df, vol2_index, vol2_doc, \"genus_coord_match_vol2\"),\n",
    "                                       (vol3_char_df, vol3_index, vol3_doc, \"genus_coord_match_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_genus_coord_match_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "\n",
    "        genus_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['genus_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['epithet_coord_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in genus_coord_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # #epithet is red, 3\n",
    "        for coord in epithet_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#000099\"), width=3)\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### improving the coord matches \n",
    "takes genus coming before epithet into account now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_genus_match(row):\n",
    "    word_rspace_removed = row['word'].rstrip()\n",
    "    return row['genus_coord_match'] == True and \\\n",
    "           row['epithet_coord_match'] == False and \\\n",
    "           word_rspace_removed.find(\"Flore\") == -1 and \\\n",
    "           ((word_rspace_removed.isupper() == False and \\\n",
    "             word_rspace_removed.isnumeric() == False) or \\\n",
    "            ((word_rspace_removed == 'X') or (word_rspace_removed =='×')))\n",
    "           # removing this for-    hg now ... and row['genus_mean_coord'] < row['epithet_mean_coord'] #important to check this only when epithet_coord_match is false?\n",
    "\n",
    "def potential_epithet_match(row):\n",
    "    word_rspace_removed = row['word'].rstrip()\n",
    "    return row['epithet_coord_match'] == True and \\\n",
    "           ((word_rspace_removed.isupper() == False and \\\n",
    "             word_rspace_removed.isnumeric() == False) or \\\n",
    "            (word_rspace_removed == 'X') or (word_rspace_removed =='×'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_char_df['potential_genus_match'] = vol1_char_df.apply(potential_genus_match, axis = 1)\n",
    "vol1_char_df['potential_epithet_match'] = vol1_char_df.apply(potential_epithet_match, axis = 1)\n",
    "\n",
    "vol2_char_df['potential_genus_match'] = vol2_char_df.apply(potential_genus_match, axis = 1)\n",
    "vol2_char_df['potential_epithet_match'] = vol2_char_df.apply(potential_epithet_match, axis = 1)\n",
    "\n",
    "vol3_char_df['potential_genus_match'] = vol3_char_df.apply(potential_genus_match, axis = 1)\n",
    "vol3_char_df['potential_epithet_match'] = vol3_char_df.apply(potential_epithet_match, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  5.77it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  5.85it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  6.04it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_GE_potential_match_test = [(vol1_char_df, vol1_index, vol1_doc, \"GE_potential_match_vol1\"),\n",
    "                                        (vol2_char_df, vol2_index, vol2_doc, \"GE_potential_match_vol2\"),\n",
    "                                        (vol3_char_df, vol3_index, vol3_doc, \"GE_potential_match_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_GE_potential_match_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        genus_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['potential_genus_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['potential_epithet_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in genus_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # #epithet is red, 3\n",
    "        for coord in epithet_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#000099\"), width=3)\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOME HARDCODING PARTS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erianthus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol_num</th>\n",
       "      <th>page_num</th>\n",
       "      <th>block_num</th>\n",
       "      <th>block_num_absolute</th>\n",
       "      <th>block_bbox</th>\n",
       "      <th>line_num</th>\n",
       "      <th>line_wmode</th>\n",
       "      <th>line_dir</th>\n",
       "      <th>line_bbox</th>\n",
       "      <th>span_num</th>\n",
       "      <th>...</th>\n",
       "      <th>char</th>\n",
       "      <th>char_origin</th>\n",
       "      <th>char_bbox</th>\n",
       "      <th>genus_index_pat_match</th>\n",
       "      <th>epithet_index_pat_match</th>\n",
       "      <th>col_num</th>\n",
       "      <th>epithet_coord_match</th>\n",
       "      <th>genus_coord_match</th>\n",
       "      <th>potential_genus_match</th>\n",
       "      <th>potential_epithet_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1734317</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>J</td>\n",
       "      <td>(239.9900665283203, 357.20001220703125)</td>\n",
       "      <td>(239.9900665283203, 352.70001220703125, 242.33...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734318</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>(242.32186889648438, 357.20001220703125)</td>\n",
       "      <td>(242.32186889648438, 352.70001220703125, 243.8...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734319</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>d</td>\n",
       "      <td>(243.81723022460938, 357.20001220703125)</td>\n",
       "      <td>(243.81723022460938, 352.70001220703125, 246.8...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734320</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>,</td>\n",
       "      <td>(246.8169708251953, 357.20001220703125)</td>\n",
       "      <td>(246.8169708251953, 352.70001220703125, 248.32...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734321</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>(248.3123321533203, 357.20001220703125)</td>\n",
       "      <td>(248.3123321533203, 352.70001220703125, 250.31...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734322</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>l</td>\n",
       "      <td>(250.30714416503906, 357.20001220703125)</td>\n",
       "      <td>(250.30714416503906, 352.70001220703125, 251.9...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734323</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>(251.9709930419922, 357.20001220703125)</td>\n",
       "      <td>(251.9709930419922, 352.70001220703125, 255.64...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734324</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>(255.638671875, 357.20001220703125)</td>\n",
       "      <td>(255.638671875, 352.70001220703125, 257.642547...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734325</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>l</td>\n",
       "      <td>(257.63348388671875, 357.20001220703125)</td>\n",
       "      <td>(257.63348388671875, 352.70001220703125, 259.3...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734326</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>(259.2973327636719, 357.20001220703125)</td>\n",
       "      <td>(259.2973327636719, 352.70001220703125, 263.64...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734327</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>(263.6429138183594, 357.20001220703125)</td>\n",
       "      <td>(263.6429138183594, 352.70001220703125, 265.14...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        vol_num  page_num  block_num  block_num_absolute  \\\n",
       "1734317       1       624         75                 120   \n",
       "1734318       1       624         75                 120   \n",
       "1734319       1       624         75                 120   \n",
       "1734320       1       624         75                 120   \n",
       "1734321       1       624         75                 120   \n",
       "1734322       1       624         75                 120   \n",
       "1734323       1       624         75                 120   \n",
       "1734324       1       624         75                 120   \n",
       "1734325       1       624         75                 120   \n",
       "1734326       1       624         75                 120   \n",
       "1734327       1       624         75                 120   \n",
       "\n",
       "                                                block_bbox  line_num  \\\n",
       "1734317  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734318  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734319  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734320  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734321  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734322  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734323  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734324  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734325  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734326  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734327  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "\n",
       "         line_wmode    line_dir  \\\n",
       "1734317           0  (1.0, 0.0)   \n",
       "1734318           0  (1.0, 0.0)   \n",
       "1734319           0  (1.0, 0.0)   \n",
       "1734320           0  (1.0, 0.0)   \n",
       "1734321           0  (1.0, 0.0)   \n",
       "1734322           0  (1.0, 0.0)   \n",
       "1734323           0  (1.0, 0.0)   \n",
       "1734324           0  (1.0, 0.0)   \n",
       "1734325           0  (1.0, 0.0)   \n",
       "1734326           0  (1.0, 0.0)   \n",
       "1734327           0  (1.0, 0.0)   \n",
       "\n",
       "                                                 line_bbox  span_num  ...  \\\n",
       "1734317  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734318  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734319  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734320  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734321  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734322  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734323  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734324  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734325  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734326  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734327  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "\n",
       "         char                               char_origin  \\\n",
       "1734317     J   (239.9900665283203, 357.20001220703125)   \n",
       "1734318     .  (242.32186889648438, 357.20001220703125)   \n",
       "1734319     d  (243.81723022460938, 357.20001220703125)   \n",
       "1734320     ,   (246.8169708251953, 357.20001220703125)   \n",
       "1734321     I   (248.3123321533203, 357.20001220703125)   \n",
       "1734322     l  (250.30714416503906, 357.20001220703125)   \n",
       "1734323     L   (251.9709930419922, 357.20001220703125)   \n",
       "1734324     I       (255.638671875, 357.20001220703125)   \n",
       "1734325     l  (257.63348388671875, 357.20001220703125)   \n",
       "1734326     U   (259.2973327636719, 357.20001220703125)   \n",
       "1734327     .   (263.6429138183594, 357.20001220703125)   \n",
       "\n",
       "                                                 char_bbox  \\\n",
       "1734317  (239.9900665283203, 352.70001220703125, 242.33...   \n",
       "1734318  (242.32186889648438, 352.70001220703125, 243.8...   \n",
       "1734319  (243.81723022460938, 352.70001220703125, 246.8...   \n",
       "1734320  (246.8169708251953, 352.70001220703125, 248.32...   \n",
       "1734321  (248.3123321533203, 352.70001220703125, 250.31...   \n",
       "1734322  (250.30714416503906, 352.70001220703125, 251.9...   \n",
       "1734323  (251.9709930419922, 352.70001220703125, 255.64...   \n",
       "1734324  (255.638671875, 352.70001220703125, 257.642547...   \n",
       "1734325  (257.63348388671875, 352.70001220703125, 259.3...   \n",
       "1734326  (259.2973327636719, 352.70001220703125, 263.64...   \n",
       "1734327  (263.6429138183594, 352.70001220703125, 265.14...   \n",
       "\n",
       "         genus_index_pat_match  epithet_index_pat_match  col_num  \\\n",
       "1734317                  False                    False        1   \n",
       "1734318                  False                    False        1   \n",
       "1734319                  False                    False        1   \n",
       "1734320                  False                    False        1   \n",
       "1734321                  False                    False        1   \n",
       "1734322                  False                    False        1   \n",
       "1734323                  False                    False        1   \n",
       "1734324                  False                    False        1   \n",
       "1734325                  False                    False        1   \n",
       "1734326                  False                    False        1   \n",
       "1734327                  False                    False        1   \n",
       "\n",
       "        epithet_coord_match genus_coord_match  potential_genus_match  \\\n",
       "1734317                True             False                  False   \n",
       "1734318                True             False                  False   \n",
       "1734319                True             False                  False   \n",
       "1734320                True             False                  False   \n",
       "1734321                True             False                  False   \n",
       "1734322                True             False                  False   \n",
       "1734323                True             False                  False   \n",
       "1734324                True             False                  False   \n",
       "1734325                True             False                  False   \n",
       "1734326                True             False                  False   \n",
       "1734327                True             False                  False   \n",
       "\n",
       "        potential_epithet_match  \n",
       "1734317                    True  \n",
       "1734318                    True  \n",
       "1734319                    True  \n",
       "1734320                    True  \n",
       "1734321                    True  \n",
       "1734322                    True  \n",
       "1734323                    True  \n",
       "1734324                    True  \n",
       "1734325                    True  \n",
       "1734326                    True  \n",
       "1734327                    True  \n",
       "\n",
       "[11 rows x 34 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[vol1_char_df['word'].str.contains('d,IlLIlU')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on this image output in volumen 1:\n",
    " ![Erianthus](Erianthus.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1734312          Bieb.\n",
       "1734313           J_JI\n",
       "1734314           J_JI\n",
       "1734315           J_JI\n",
       "1734316           J_JI\n",
       "1734317    J.d,IlLIlU.\n",
       "1734318    J.d,IlLIlU.\n",
       "1734319    J.d,IlLIlU.\n",
       "1734320    J.d,IlLIlU.\n",
       "1734321    J.d,IlLIlU.\n",
       "1734322    J.d,IlLIlU.\n",
       "1734323    J.d,IlLIlU.\n",
       "1734324    J.d,IlLIlU.\n",
       "1734325    J.d,IlLIlU.\n",
       "1734326    J.d,IlLIlU.\n",
       "1734327    J.d,IlLIlU.\n",
       "1734328         hostii\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_old_char_vol1 = vol1_char_df.loc[1734312:1734328]\n",
    "weird_old_char_vol1['word']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make comment about this part is hard coded thingi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1734312    2\n",
       "1734313    0\n",
       "1734314    0\n",
       "1734315    0\n",
       "1734316    0\n",
       "1734317    1\n",
       "1734318    1\n",
       "1734319    1\n",
       "1734320    1\n",
       "1734321    1\n",
       "1734322    1\n",
       "1734323    1\n",
       "1734324    1\n",
       "1734325    1\n",
       "1734326    1\n",
       "1734327    1\n",
       "1734328    0\n",
       "Name: word_num, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_old_char_vol1['word_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually fixing the OCR error for J_JI J.d,IlLIlU. hostii Griseb.\n",
    "vol1_char_df.loc[1734313:1734327, 'word'] = 'Erianthus'\n",
    "vol1_char_df.loc[1734313:1734327, 'word_num'] = 0\n",
    "vol1_char_df.loc[1734313:1734327, 'pruned_word'] = 'Erianthus'\n",
    "temp_word_x0 = vol1_char_df.loc[1734313:1734327, 'word_bbox'].apply(lambda x : x[0]).min()\n",
    "temp_word_y0 = vol1_char_df.loc[1734313:1734327, 'word_bbox'].apply(lambda x : x[1]).min()\n",
    "temp_word_x1 = vol1_char_df.loc[1734313:1734327, 'word_bbox'].apply(lambda x : x[2]).max()\n",
    "temp_word_y1 = vol1_char_df.loc[1734313:1734327, 'word_bbox'].apply(lambda x : x[3]).max()\n",
    "vol1_char_df.loc[1734313:1734327, 'word_bbox'] =vol1_char_df.loc[1734313:1734327, 'word_bbox'].apply(lambda x : (temp_word_x0, temp_word_y0, temp_word_x1, temp_word_y1))\n",
    "\n",
    "vol1_char_df.loc[1734313:1734327, 'potential_epithet_match'] = False\n",
    "vol1_char_df.loc[1734313:1734327, 'potential_genus_match'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infra species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 21.21it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 19.16it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 22.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reminder:\n",
    "# all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "#                             (vol2_char_df, vol2_index),\n",
    "#                             (vol3_char_df, vol3_index)]\n",
    "for vol_char_df, vol_index in all_vol_data_coord_match: \n",
    "    vol_char_df[\"infra_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"potential_epithet_match\"] == True) | (vol_char_df[\"potential_genus_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        \n",
    "        mean_left_epithet = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        mean_left_genus = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        if math.isnan(mean_left_genus):\n",
    "            mean_left_genus_all = vol_char_df[(vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_left_epithet_all = vol_char_df[(vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_left_tab = mean_left_epithet_all - mean_left_genus_all\n",
    "        else: \n",
    "            mean_left_tab = mean_left_epithet - mean_left_genus\n",
    "        \n",
    "        mean_right_epithet = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        mean_right_genus = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        if math.isnan(mean_right_genus):\n",
    "            mean_right_genus_all = vol_char_df[(vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_right_epithet_all = vol_char_df[(vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_right_tab = mean_right_epithet_all - mean_right_genus_all\n",
    "        else: \n",
    "            mean_right_tab = mean_right_epithet - mean_right_genus\n",
    "\n",
    "\n",
    "        vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"word_num\"] == 0)  , \"infra_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"word_num\"] == 0)][\"word_bbox\"].apply(lambda x : is_coord_match(x, mean_left_epithet + mean_left_tab, mean_right_epithet + mean_right_tab, margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes longer but makes more sense generally. We will skip it here\n",
    "# def potential_author_match_infra_coord(row):\n",
    "#     word = row['word']\n",
    "#     pruned_word = row['pruned_word']\n",
    "#     lower_word = word.lower()\n",
    "#     latin_connectives = r\"^\\s?et[\\s|.]?$|^\\s?in[\\s|.]?$|^\\s?non[\\s|.]?$|^\\s?&[\\s|.]?$|^\\s?er[\\s|.]?$|^\\s?nec[\\s|.]?$|^\\s?mult[\\s|.]?$|^\\s?ex[\\s|.]?$|^\\s?fil[\\s|.]?$\"\n",
    "#     infra_symbols = r\"^var[\\s|.|\\b]?$|^subsp[\\s|.|\\b]?$|^ssp[\\s|.|\\b]?$|^spp[\\s|.|\\b]?$|^x[\\s|.|\\b]?$|^×[\\s|.|\\b]?$\"\n",
    "#     is_latin_connectives = re.search(latin_connectives, word) != None\n",
    "#     is_infra_symbol = re.search(infra_symbols, lower_word) != None\n",
    "#     if pruned_word:\n",
    "#         is_upper_first = pruned_word[0].isupper()\n",
    "#     else:\n",
    "#         is_upper_first = False\n",
    "#     return (not is_infra_symbol) and (is_upper_first or is_latin_connectives)\n",
    "\n",
    "def potential_author_match_infra_coord(word):\n",
    "    lower_word = word.lower()\n",
    "    latin_connectives = r\"^\\s?et[\\s|.]?$|^\\s?in[\\s|.]?$|^\\s?non[\\s|.]?$|^\\s?&[\\s|.]?$|^\\s?er[\\s|.]?$|^\\s?nec[\\s|.]?$|^\\s?mult[\\s|.]?$|^\\s?ex[\\s|.]?$|^\\s?fil[\\s|.]?$\"\n",
    "    infra_symbols = r\"^var[\\s|.|\\b]?$|^subsp[\\s|.|\\b]?$|^ssp[\\s|.|\\b]?$|^spp[\\s|.|\\b]?$|^x[\\s|.|\\b]?$|^×[\\s|.|\\b]?$\"\n",
    "    is_latin_connectives = re.search(latin_connectives, word) != None\n",
    "    is_infra_symbol = re.search(infra_symbols, lower_word) != None\n",
    "    return (not is_infra_symbol) and (word[0].isupper() or is_latin_connectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_infra_symbols(word):\n",
    "    infra_symbols = r\"^var[\\s|.|\\b]?$|^subsp[\\s|.|\\b]?$|^ssp[\\s|.|\\b]?$|^spp[\\s|.|\\b]?$|^x[\\s|.|\\b]?$|^×[\\s|.|\\b]?$\"\n",
    "    return re.search(infra_symbols, word) != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder:\n",
    "# all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "#                             (vol2_char_df, vol2_index),\n",
    "#                             (vol3_char_df, vol3_index)]\n",
    "for vol_char_df, _ in all_vol_data_coord_match:\n",
    "    vol_char_df[\"potential_infra_match\"] = (vol_char_df['word'].apply(has_infra_symbols)) | \\\n",
    "                                           ((vol_char_df[\"infra_coord_match\"] == True) & (vol_char_df['word'].apply(potential_author_match_infra_coord) == False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:23<00:00,  1.19it/s]\n",
      "100%|██████████| 22/22 [00:21<00:00,  1.02it/s]\n",
      "100%|██████████| 23/23 [00:20<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_dat_infra_match_test = [(vol1_char_df, vol1_index, vol1_doc, \"potential_infra_match_vol1\"),\n",
    "                                (vol2_char_df, vol2_index, vol2_doc, \"potential_infra_match_vol2\"),\n",
    "                                (vol3_char_df, vol3_index, vol3_doc, \"potential_infra_match_vol3\")][::-1]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_dat_infra_match_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "\n",
    "        infra_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['infra_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        infra_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['potential_infra_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        with_infra_symbols = vol_char_df[(vol_char_df['page_num'] == page_num) &\n",
    "                                         (vol_char_df['infra_coord_match'] == True) & \n",
    "                                         (vol_char_df['word'].apply(has_infra_symbols) == True)\n",
    "                                        ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                        ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in infra_coord_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0-5, y0-5, x1+5, y1+5), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=7)\n",
    "\n",
    "        for coord in infra_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0-3, y0-3, x1+3, y1+3), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # #epithet is red, 3\n",
    "        for coord in with_infra_symbols['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#990000\"), width=3)\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### page num processings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_char_df['index_page_num'] = vol1_char_df['page_num'] - vol1_index[0] + 1\n",
    "vol2_char_df['index_page_num'] = vol2_char_df['page_num'] - vol2_index[0] + 1\n",
    "vol3_char_df['index_page_num'] = vol3_char_df['page_num'] - vol3_index[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:12<00:00,  1.78it/s]\n",
      "100%|██████████| 22/22 [00:13<00:00,  1.61it/s]\n",
      "100%|██████████| 28/28 [00:14<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# all_vol_data_col_num = [(vol1_char_df, vol1_index, vol1_doc),\n",
    "#                         (vol2_char_df, vol2_index, vol2_doc),\n",
    "#                         (vol3_char_df, vol3_index, vol3_doc)]\n",
    "\n",
    "for vol_char_df ,vol_index, vol_doc in all_vol_data_col_num: \n",
    "    #for each volume check if genus pattern / epithet pattern exists within the index part of the book\n",
    "    for page_num in tqdm(vol_index):\n",
    "        center_x0 = get_center_x0(vol_char_df, page_num, - 30)\n",
    "        #find center based on x0 coordinate of each line\n",
    "        vol_char_df['col_num_for_PN'] = vol_char_df['line_bbox'].apply(lambda coords : get_col_num(coords, center_x0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_page_num(row):\n",
    "    return row['pruned_word'].isnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 16.97it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.74it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 22.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reminder:\n",
    "# all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "#                             (vol2_char_df, vol2_index),\n",
    "#                             (vol3_char_df, vol3_index)]\n",
    "for vol_char_df, vol_index in all_vol_data_coord_match: \n",
    "    vol_char_df['page_num_index_pat_match'] = (vol_char_df['page_num'].isin(vol_index)) & (vol_char_df.apply(is_page_num, axis = 1))\n",
    "    vol_char_df[\"page_num_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"page_num_index_pat_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        page_num_char_df = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"page_num_index_pat_match\"] == True)]\n",
    "        page_num_df = page_num_char_df.loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"])].drop_duplicates()\n",
    "        page_page_num_2dic = [{}, {}]\n",
    "        \n",
    "        for i in range(page_num_df.shape[0]):\n",
    "            e_index = str(page_num) + \"_\" + str(i)\n",
    "            p0 = page_num_df['word_bbox'].iloc[i]\n",
    "            x_ref = p0[2]\n",
    "            col = page_num_df['col_num_for_PN'].iloc[i]\n",
    "\n",
    "            ref_neighbors_df = page_num_df[(page_num_df[\"page_num\"] == page_num) & \n",
    "                                           (page_num_df[\"word_bbox\"].apply(lambda x : x_ref - margin <= x[2] and x[2] <= x_ref + margin))]\n",
    "            \n",
    "            num_neighbors = ref_neighbors_df.shape[0]\n",
    "            mean_neighbors = ref_neighbors_df[\"word_bbox\"].apply(lambda x : x[2]).mean()\n",
    "            page_page_num_2dic[col][e_index] = (num_neighbors, mean_neighbors)\n",
    "        \n",
    "        mean_left_page_num = max(page_page_num_2dic[0].values(), default = [-1, -1])[1]\n",
    "        mean_right_page_num = max(page_page_num_2dic[1].values(), default = [-1, -1])[1]\n",
    "\n",
    "        if mean_left_page_num == -1 or mean_right_page_num == -1:\n",
    "            mean_valid_col = max(mean_left_page_num, mean_right_page_num)\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"page_num_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match([x[2]], mean_valid_col, mean_valid_col, margin))\n",
    "        elif mean_left_page_num == -1 and mean_right_page_num == -1:\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"page_num_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : False)\n",
    "        else: \n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"page_num_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match([x[2]], mean_left_page_num, mean_right_page_num, margin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:04<00:00,  6.27it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  6.06it/s]\n",
      "100%|██████████| 23/23 [00:03<00:00,  5.97it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_PN_test = [(vol1_char_df, vol1_index, vol1_doc, \"potential_page_num_match_vol1\"),\n",
    "                        (vol2_char_df, vol2_index, vol2_doc, \"potential_page_num_match_vol2\"),\n",
    "                        (vol3_char_df, vol3_index, vol3_doc, \"potential_page_num_match_vol3\")][::-1]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_PN_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "\n",
    "        page_num_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['page_num_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        # infra_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "        #                         & (vol_char_df['potential_infra_match'] == True)\n",
    "        #                         ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "        #                         ].drop_duplicates()\n",
    "\n",
    "        # with_infra_symbols = vol_char_df[(vol_char_df['page_num'] == page_num) &\n",
    "        #                                  (vol_char_df['infra_coord_match'] == True) & \n",
    "        #                                  (vol_char_df['word'].apply(has_infra_symbols) == True)\n",
    "        #                                 ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "        #                                 ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in page_num_coord_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=3)\n",
    "\n",
    "        # for coord in infra_db['word_bbox'] :\n",
    "        #     x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "        #     draw.rectangle((x0-3, y0-3, x1+3, y1+3), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # # #epithet is red, 3\n",
    "        # for coord in with_infra_symbols['word_bbox'] :\n",
    "        #     x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "        #     draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#990000\"), width=3)\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catching & hardcoding issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking potential_infra_match that are not with typical symbols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_page_num, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_infra_match'] == True) & (vol1_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_page_num, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_infra_match'] == True) & (vol2_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1559345</th>\n",
       "      <td>3</td>\n",
       "      <td>(3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559874</th>\n",
       "      <td>3</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561502</th>\n",
       "      <td>4</td>\n",
       "      <td>fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566359</th>\n",
       "      <td>6</td>\n",
       "      <td>deris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570483</th>\n",
       "      <td>8</td>\n",
       "      <td>cock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576678</th>\n",
       "      <td>11</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578491</th>\n",
       "      <td>12</td>\n",
       "      <td>picha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581443</th>\n",
       "      <td>13</td>\n",
       "      <td>adoxifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582167</th>\n",
       "      <td>14</td>\n",
       "      <td>fil.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584378</th>\n",
       "      <td>15</td>\n",
       "      <td>yar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587338</th>\n",
       "      <td>16</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589927</th>\n",
       "      <td>17</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592932</th>\n",
       "      <td>19</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594835</th>\n",
       "      <td>20</td>\n",
       "      <td>turcicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596384</th>\n",
       "      <td>20</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598587</th>\n",
       "      <td>22</td>\n",
       "      <td>berlain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num         word\n",
       "1559345               3           (3\n",
       "1559874               3           f.\n",
       "1561502               4           fa\n",
       "1566359               6       deris \n",
       "1570483               8         cock\n",
       "1576678              11           f.\n",
       "1578491              12       picha \n",
       "1581443              13  adoxifolium\n",
       "1582167              14        fil. \n",
       "1584378              15         yar.\n",
       "1587338              16           f.\n",
       "1589927              17           f.\n",
       "1592932              19           f.\n",
       "1594835              20     turcicus\n",
       "1596384              20            y\n",
       "1598587              22      berlain"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_infra_match'] == True) & (vol3_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_infra_index = [1566359, 1570483, 1578491, 1581443, 1582167, 1594835, 1598587]\n",
    "#temp_df_hard_code_infra = vol3_char_df[(vol3_char_df['potential_infra_match'] == True) & (vol3_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"pruned_word\"]].drop_duplicates()\n",
    "#temp_df_hard_code_infra[temp_df_hard_code_infra['pruned_word'].apply(lambda x : len(x) > 3)].index \n",
    "#nice ways but won't have everything in them ... so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1570487\n",
      "6 1566365\n",
      "4 1570887\n",
      "4 1570887\n",
      "6 1578497\n",
      "11 1581454\n",
      "5 1582172\n",
      "8 1594843\n",
      "7 1598594\n",
      "11 1581454\n"
     ]
    }
   ],
   "source": [
    "def get_index_end(vol_df, start_index):\n",
    "    len_word = len(vol_df.loc[start_index,'word'])\n",
    "    print(len_word, start_index + len_word)\n",
    "    return start_index + len_word - 1\n",
    "\n",
    "set_epithet_index = [1581443]\n",
    "remove_infra_index = [1570483, 1566359, 1570883, 1570883, 1578491, 1581443, 1582167, 1594835, 1598587]\n",
    "for i in remove_infra_index:\n",
    "    vol3_char_df.loc[i : get_index_end(vol3_char_df, i),'potential_infra_match'] = False\n",
    "\n",
    "for i in set_epithet_index:\n",
    "    vol3_char_df.loc[i : get_index_end(vol3_char_df, i),'potential_epithet_match'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1559345</th>\n",
       "      <td>3</td>\n",
       "      <td>(3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559874</th>\n",
       "      <td>3</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561502</th>\n",
       "      <td>4</td>\n",
       "      <td>fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576678</th>\n",
       "      <td>11</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584378</th>\n",
       "      <td>15</td>\n",
       "      <td>yar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587338</th>\n",
       "      <td>16</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589927</th>\n",
       "      <td>17</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592932</th>\n",
       "      <td>19</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596384</th>\n",
       "      <td>20</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num  word\n",
       "1559345               3    (3\n",
       "1559874               3    f.\n",
       "1561502               4    fa\n",
       "1576678              11    f.\n",
       "1584378              15  yar.\n",
       "1587338              16    f.\n",
       "1589927              17    f.\n",
       "1592932              19    f.\n",
       "1596384              20     y"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cock keeps needing to be pruned multiple times ....??? not sure why ugh\n",
    "vol3_char_df[(vol3_char_df['potential_infra_match'] == True) & (vol3_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1596384 -> var with space in between it somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1596385\n"
     ]
    }
   ],
   "source": [
    "ending = get_index_end(vol3_char_df, 1596384)+2\n",
    "vol3_char_df.loc[1596384 : ending, 'word'] = 'var.'\n",
    "vol3_char_df.loc[1596384 : ending, 'word_num'] = 0\n",
    "vol3_char_df.loc[1596384 : ending, 'pruned_word'] = 'var'\n",
    "vol3_char_df.loc[1596384 : ending, 'potential_infra_match'] = True \n",
    "#have to run it again this is problematic now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upper case beggining / latin words in epithet coordd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_author_match_epithet_coord(word):\n",
    "    latin_connectives = r\"^\\s?et[\\s|.]?$|^\\s?in[\\s|.]?$|^\\s?non[\\s|.]?$|^\\s?&[\\s|.]?$|^\\s?er[\\s|.]?$|^\\s?nec[\\s|.]?$|^\\s?mult[\\s|.]?$|^\\s?ex[\\s|.]?$|^\\s?fil[\\s|.]?$|^\\s?f[\\s|.]?$\"\n",
    "    is_latin_connectives = re.search(latin_connectives, word) != None\n",
    "    is_hybrid = word == \"X\"\n",
    "    return is_latin_connectives or (word[0].isupper() and (not is_hybrid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKED: for vol1 all are okay and are just typos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1753028</th>\n",
       "      <td>18</td>\n",
       "      <td>Phoenicia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753527</th>\n",
       "      <td>18</td>\n",
       "      <td>Syriacus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755122</th>\n",
       "      <td>19</td>\n",
       "      <td>Jilicaulis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num        word\n",
       "1753028              18   Phoenicia\n",
       "1753527              18    Syriacus\n",
       "1755122              19  Jilicaulis"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_epithet_match'] == True) & (vol1_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKED Vol2 \n",
    "\n",
    "Hbanoticus -> typo for libanoticus \n",
    "\n",
    "Hppii -> typo for lippii\n",
    "\n",
    "letting fuzzy matching take care of it later :)\n",
    "\n",
    "**TODO**: Ma -> is supposed to be chia (not easy for fuzzy matching to fix...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1915513</th>\n",
       "      <td>4</td>\n",
       "      <td>Hbanoticus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922530</th>\n",
       "      <td>8</td>\n",
       "      <td>Hppii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937158</th>\n",
       "      <td>14</td>\n",
       "      <td>Ma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num        word\n",
       "1915513               4  Hbanoticus\n",
       "1922530               8       Hppii\n",
       "1937158              14          Ma"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_epithet_match'] == True) & (vol2_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKED vol3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1554632</th>\n",
       "      <td>1</td>\n",
       "      <td>Krascheninnikovii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565497</th>\n",
       "      <td>6</td>\n",
       "      <td>Wagenitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566524</th>\n",
       "      <td>6</td>\n",
       "      <td>Fritsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575185</th>\n",
       "      <td>10</td>\n",
       "      <td>Holub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575488</th>\n",
       "      <td>11</td>\n",
       "      <td>Holub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577207</th>\n",
       "      <td>11</td>\n",
       "      <td>et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578956</th>\n",
       "      <td>12</td>\n",
       "      <td>Eichwaldii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579044</th>\n",
       "      <td>12</td>\n",
       "      <td>Schrank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582101</th>\n",
       "      <td>14</td>\n",
       "      <td>Kuntze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583001</th>\n",
       "      <td>14</td>\n",
       "      <td>Kuntze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584639</th>\n",
       "      <td>15</td>\n",
       "      <td>Majoranamaracus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586349</th>\n",
       "      <td>16</td>\n",
       "      <td>Schiman-Czeika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586394</th>\n",
       "      <td>16</td>\n",
       "      <td>Czeika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592464</th>\n",
       "      <td>19</td>\n",
       "      <td>Berth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603606</th>\n",
       "      <td>24</td>\n",
       "      <td>DOteriifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608442</th>\n",
       "      <td>26</td>\n",
       "      <td>Turra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609136</th>\n",
       "      <td>26</td>\n",
       "      <td>Moretti,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610970</th>\n",
       "      <td>27</td>\n",
       "      <td>Fischer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611185</th>\n",
       "      <td>27</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num               word\n",
       "1554632               1  Krascheninnikovii\n",
       "1565497               6          Wagenitz \n",
       "1566524               6           Fritsch \n",
       "1575185              10              Holub\n",
       "1575488              11             Holub \n",
       "1577207              11                 et\n",
       "1578956              12         Eichwaldii\n",
       "1579044              12           Schrank \n",
       "1582101              14            Kuntze \n",
       "1583001              14             Kuntze\n",
       "1584639              15    Majoranamaracus\n",
       "1586349              16     Schiman-Czeika\n",
       "1586394              16             Czeika\n",
       "1592464              19             Berth.\n",
       "1603606              24      DOteriifolium\n",
       "1608442              26             Turra \n",
       "1609136              26           Moretti,\n",
       "1610970              27           Fischer \n",
       "1611185              27                non"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_epithet_match'] == True) & (vol3_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 1565506\n",
      "8 1566532\n",
      "5 1575190\n",
      "6 1575494\n",
      "2 1577209\n",
      "8 1579052\n",
      "7 1582108\n",
      "6 1583007\n",
      "14 1586363\n",
      "6 1586400\n",
      "6 1592470\n",
      "6 1608448\n",
      "8 1609144\n",
      "8 1610978\n",
      "3 1611188\n"
     ]
    }
   ],
   "source": [
    "# Eichwaldii, Krascheninnikovii, DOteriifolium (p should be p) -> oki \n",
    "# Majoranamaracus -> hybrid situation -> fixed later\n",
    "not_epithet_index_list = [1565497, 1566524, 1575185, 1575488, 1577207, 1579044, 1582101, 1583001, 1586349, 1586394, 1592464, 1608442, 1609136, 1610970, 1611185]\n",
    "\n",
    "for i in not_epithet_index_list:\n",
    "    vol3_char_df.loc[i : get_index_end(vol3_char_df, i),'potential_epithet_match'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1554632</th>\n",
       "      <td>1</td>\n",
       "      <td>Krascheninnikovii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578956</th>\n",
       "      <td>12</td>\n",
       "      <td>Eichwaldii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584639</th>\n",
       "      <td>15</td>\n",
       "      <td>Majoranamaracus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603606</th>\n",
       "      <td>24</td>\n",
       "      <td>DOteriifolium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num               word\n",
       "1554632               1  Krascheninnikovii\n",
       "1578956              12         Eichwaldii\n",
       "1584639              15    Majoranamaracus\n",
       "1603606              24      DOteriifolium"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_epithet_match'] == True) & (vol3_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [**TODO FIX LATER**] epithet coord word has uppper case in the middle (but not the first letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_upper_not_first(word):\n",
    "    return word[1:].lower() != word[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1716055</th>\n",
       "      <td>1</td>\n",
       "      <td>peregrina(Hack.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716156</th>\n",
       "      <td>1</td>\n",
       "      <td>umbeUulata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734633</th>\n",
       "      <td>9</td>\n",
       "      <td>elatior'L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736494</th>\n",
       "      <td>10</td>\n",
       "      <td>sessUis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737303</th>\n",
       "      <td>11</td>\n",
       "      <td>pilosaHuds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741588</th>\n",
       "      <td>13</td>\n",
       "      <td>phleoides^Vill.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747388</th>\n",
       "      <td>15</td>\n",
       "      <td>albaL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752078</th>\n",
       "      <td>18</td>\n",
       "      <td>aegUops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752829</th>\n",
       "      <td>18</td>\n",
       "      <td>glaucaVahl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761043</th>\n",
       "      <td>22</td>\n",
       "      <td>auCheriana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num              word\n",
       "1716055               1  peregrina(Hack.)\n",
       "1716156               1        umbeUulata\n",
       "1734633               9        elatior'L.\n",
       "1736494              10           sessUis\n",
       "1737303              11       pilosaHuds.\n",
       "1741588              13  phleoides^Vill.)\n",
       "1747388              15            albaL.\n",
       "1752078              18           aegUops\n",
       "1752829              18        glaucaVahl\n",
       "1761043              22        auCheriana"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_epithet_match'] == True) & (vol1_char_df['word'].apply(has_upper_not_first))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1914061</th>\n",
       "      <td>4</td>\n",
       "      <td>corîdûpUcaÈu^Sretoï.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917935</th>\n",
       "      <td>6</td>\n",
       "      <td>securidacaiÇL.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941855</th>\n",
       "      <td>17</td>\n",
       "      <td>corymbulosum(Planch.)Reichenb.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953489</th>\n",
       "      <td>22</td>\n",
       "      <td>aqUatilis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num                            word\n",
       "1914061               4            corîdûpUcaÈu^Sretoï.\n",
       "1917935               6                 securidacaiÇL.)\n",
       "1941855              17  corymbulosum(Planch.)Reichenb.\n",
       "1953489              22                       aqUatilis"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_epithet_match'] == True) & (vol2_char_df['word'].apply(has_upper_not_first))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1568523</th>\n",
       "      <td>7</td>\n",
       "      <td>gaiUardotii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579879</th>\n",
       "      <td>13</td>\n",
       "      <td>albu^L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585656</th>\n",
       "      <td>15</td>\n",
       "      <td>sieberiC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597633</th>\n",
       "      <td>21</td>\n",
       "      <td>desertiTUéh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603606</th>\n",
       "      <td>24</td>\n",
       "      <td>DOteriifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608206</th>\n",
       "      <td>26</td>\n",
       "      <td>agMmoniifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612787</th>\n",
       "      <td>28</td>\n",
       "      <td>'Abd-el-'asissi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num             word\n",
       "1568523               7      gaiUardotii\n",
       "1579879              13          albu^L.\n",
       "1585656              15        sieberiC.\n",
       "1597633              21     desertiTUéh.\n",
       "1603606              24    DOteriifolium\n",
       "1608206              26   agMmoniifolium\n",
       "1612787              28  'Abd-el-'asissi"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_epithet_match'] == True) & (vol3_char_df['word'].apply(has_upper_not_first))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Potential genus mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "potential genus match but name is not alphabetic or is of length < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_genus_name(word):\n",
    "    word_no_space = word.replace(\" \", \"\")\n",
    "    return ((not word_no_space.isalpha()) or (len(word_no_space) < 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1730943</th>\n",
       "      <td>8</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738656</th>\n",
       "      <td>11</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754704</th>\n",
       "      <td>19</td>\n",
       "      <td>j.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num word\n",
       "1730943               8    c\n",
       "1738656              11    f\n",
       "1754704              19   j."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()\n",
    "#skipping over all these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1730944\n",
      "1 1738657\n",
      "2 1754706\n"
     ]
    }
   ],
   "source": [
    "not_genus_index_list_vol1 = [1730943, 1738656, 1754704]\n",
    "for i in not_genus_index_list_vol1:\n",
    "    vol1_char_df.loc[i : get_index_end(vol1_char_df, i),'potential_genus_match'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_page_num, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921256</th>\n",
       "      <td>7</td>\n",
       "      <td>•Ceratophyllum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921779</th>\n",
       "      <td>7</td>\n",
       "      <td>Chelidonium^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939484</th>\n",
       "      <td>16</td>\n",
       "      <td>Jussiaea-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939606</th>\n",
       "      <td>16</td>\n",
       "      <td>VV.1l.*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num            word\n",
       "1921256               7  •Ceratophyllum\n",
       "1921779               7    Chelidonium^\n",
       "1939484              16       Jussiaea-\n",
       "1939606              16         VV.1l.*"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_genus_match'] == True) & (vol2_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1939613\n"
     ]
    }
   ],
   "source": [
    "not_genus_index_list_vol2 = [1939606]\n",
    "for i in not_genus_index_list_vol2:\n",
    "    vol2_char_df.loc[i : get_index_end(vol2_char_df, i),'potential_genus_match'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921256</th>\n",
       "      <td>7</td>\n",
       "      <td>•Ceratophyllum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921779</th>\n",
       "      <td>7</td>\n",
       "      <td>Chelidonium^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939484</th>\n",
       "      <td>16</td>\n",
       "      <td>Jussiaea-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num            word\n",
       "1921256               7  •Ceratophyllum\n",
       "1921779               7    Chelidonium^\n",
       "1939484              16       Jussiaea-"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_genus_match'] == True) & (vol2_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1559728</th>\n",
       "      <td>3</td>\n",
       "      <td>BallotaL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569974</th>\n",
       "      <td>8</td>\n",
       "      <td>CordiaL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584638</th>\n",
       "      <td>15</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601635</th>\n",
       "      <td>23</td>\n",
       "      <td>SolidagoL.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num        word\n",
       "1559728               3  BallotaL. \n",
       "1569974               8   CordiaL. \n",
       "1584638              15           x\n",
       "1601635              23  SolidagoL."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_genus_match'] == True) & (vol3_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()\n",
    "#all okay and hybrid will get fixed later :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759374    apetala\n",
       "1759375    apetala\n",
       "1759376    apetala\n",
       "1759377    apetala\n",
       "1759378    apetala\n",
       "1759379    apetala\n",
       "1759380    apetala\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'].apply(lambda x : x[0].isupper() == False))]['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_apetala_correcting = vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'].apply(lambda x : x[0].isupper() == False))].index\n",
    "vol1_char_df.loc[index_apetala_correcting,'potential_genus_match'] = False\n",
    "vol1_char_df.loc[index_apetala_correcting,'potential_epithet_match'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: word, dtype: object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'].apply(lambda x : x[0].isupper() == False))]['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1921256    •Ceratophyllum\n",
       "1921257    •Ceratophyllum\n",
       "1921258    •Ceratophyllum\n",
       "1921259    •Ceratophyllum\n",
       "1921260    •Ceratophyllum\n",
       "1921261    •Ceratophyllum\n",
       "1921262    •Ceratophyllum\n",
       "1921263    •Ceratophyllum\n",
       "1921264    •Ceratophyllum\n",
       "1921265    •Ceratophyllum\n",
       "1921266    •Ceratophyllum\n",
       "1921267    •Ceratophyllum\n",
       "1921268    •Ceratophyllum\n",
       "1921269    •Ceratophyllum\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fuzzy matching will fix\n",
    "vol2_char_df[(vol2_char_df['potential_genus_match'] == True) & (vol2_char_df['word'].apply(lambda x : x[0].isupper() == False))]['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1584638    x\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fixed later when hybrids identified \n",
    "vol3_char_df[(vol3_char_df['potential_genus_match'] == True) & (vol3_char_df['word'].apply(lambda x : x[0].isupper() == False))]['word']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pruning char_df and getting index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['potential_genus_match', 'potential_epithet_match', 'potential_infra_match']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in vol1_char_df.columns if c.startswith('potential')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making sure page_num is in index\n",
    "#making sure the genus level word is not all uppercase (a family name)\n",
    "#making sure the pruned_word is not numeric (removing page_number as it's not in order usually) and removing page_num_coord_match\n",
    "\n",
    "all_vol_data = [(vol1_char_df, vol1_index),\n",
    "                (vol2_char_df, vol2_index),\n",
    "                (vol3_char_df, vol3_index)]\n",
    "\n",
    "result = [] \n",
    "ignore_word_list = [\"NOUVELLE\", \"Flore\", \"FLORE\", \"INDEX\", \"\"]\n",
    "for vol_char_df, vol_index in all_vol_data:\n",
    "    curr_result_df = vol_char_df[(vol_char_df['page_num'].isin(vol_index)) &\n",
    "                                (~((vol_char_df[\"word\"].str.isupper()) & (vol_char_df[\"word\"].apply(lambda x : len(x) > 2)) & (vol_char_df['genus_coord_match'] == True))) & \n",
    "                                (~(vol_char_df[\"pruned_word\"].isin(ignore_word_list))) &\n",
    "                                (~(vol_char_df[\"pruned_word\"].str.isnumeric() & (vol_char_df[\"word\"] != \"(3\"))) & \n",
    "                                (~(vol_char_df[\"page_num_coord_match\"] == True)) & \n",
    "                                (~((vol_char_df.groupby(['page_num', 'block_num', 'line_num'])['char_num'].transform('max') == 0) & (vol_char_df['word'].str.isupper())))\n",
    "                                ].copy()\n",
    "    result.append(curr_result_df)\n",
    "\n",
    "vol1_index_df, vol2_index_df, vol3_index_df = result[0], result[1], result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.10it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  6.25it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  6.52it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_PN_test = [(vol1_index_df, vol1_index, vol1_doc, \"valid_words_vol1\"),\n",
    "                        (vol2_index_df, vol2_index, vol2_doc, \"valid_words_vol2\"),\n",
    "                        (vol3_index_df, vol3_index, vol3_doc, \"valid_words_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_PN_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        temp_coords = vol_char_df[vol_char_df['page_num'] == page_num]['word_bbox'].drop_duplicates()\n",
    "        for coord in temp_coords:\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=3)\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keeping word level\n",
    "vol_index_df_list = [vol1_index_df, vol2_index_df, vol3_index_df]\n",
    "result_df = []\n",
    "for vol_index_df in vol_index_df_list:\n",
    "    keep_cols = vol_index_df.columns.difference([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"], sort=False).tolist()\n",
    "\n",
    "    vol_index_df = vol_index_df.copy().loc[:,keep_cols].drop_duplicates().reset_index()\n",
    "    vol_index_df.rename(columns={\"index\": \"char_index\"}, inplace = True)\n",
    "    result_df.append(vol_index_df)\n",
    "\n",
    "vol1_index_df, vol2_index_df, vol3_index_df = result_df[0], result_df[1], result_df[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_hybrid_symbols(word):\n",
    "    infra_symbols = r\"^X[\\s|.|\\b]?$|^x[\\s|.|\\b]?$|^×[\\s|.|\\b]?$\"\n",
    "    return re.search(infra_symbols, word) != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_hybrids = []\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['is_hybrid'] = np.NaN\n",
    "    vol_index_df.loc[(vol_index_df['potential_infra_match'] == True) | (vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True), 'is_hybrid'] = (vol_index_df['word'].apply(has_hybrid_symbols) == True) & ((vol_index_df['potential_infra_match'] == True) | (vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True))\n",
    "    \n",
    "    hybrid_genera_indecies = vol_index_df[(vol_index_df['potential_genus_match'] == True) & (vol_index_df['word'].apply(has_hybrid_symbols) == True)].index + 1\n",
    "    hybrid_epithet_indecies = vol_index_df[(vol_index_df['potential_epithet_match'] == True) & (vol_index_df['word'].apply(has_hybrid_symbols) == True)].index + 1\n",
    "    \n",
    "    vol_index_df.loc[hybrid_epithet_indecies, 'is_hybrid'] = True\n",
    "    vol_index_df.loc[hybrid_epithet_indecies, 'potential_epithet_match'] = True \n",
    "\n",
    "    vol_index_df.loc[hybrid_genera_indecies, 'is_hybrid'] = True\n",
    "    vol_index_df.loc[hybrid_genera_indecies, 'potential_genus_match'] = True\n",
    "\n",
    "    drop_list = list(hybrid_epithet_indecies - 1) + list(hybrid_genera_indecies -1)\n",
    "    \n",
    "    vol_index_df = vol_index_df[~vol_index_df.index.isin(drop_list)].copy()\n",
    "    #vol_index_df['is_hybrid'].ffill(inplace=True) fowrward fill after checking hybrid for the infra species types too\n",
    "\n",
    "    result_df_hybrids.append(vol_index_df)\n",
    "\n",
    "vol1_index_df, vol2_index_df, vol3_index_df = result_df_hybrids[0], result_df_hybrids[1], result_df_hybrids[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['closest_epithet_v2'] = np.nan\n",
    "def extract_potential_genus_names(row):\n",
    "    if row['potential_genus_match'] == True:\n",
    "        return row['word'] + \"_\" + str(row['page_num']) + \"_\" + str(row['block_num']) + \"_\" + str(row['line_num'])\n",
    "    else:\n",
    "        return np.nan\n",
    "        \n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['closest_genus'] = vol_index_df.apply(extract_potential_genus_names, axis = 1)\n",
    "    vol_index_df['closest_genus'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['closest_epithet_v2'] = np.nan\n",
    "def extract_potential_epithet_names(row):\n",
    "    if row['potential_epithet_match'] == True:\n",
    "        return row['word'] + \"_\" + str(row['page_num']) + \"_\" + str(row['block_num']) + \"_\" + str(row['line_num'])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['closest_epithet'] = vol_index_df.apply(extract_potential_epithet_names, axis = 1)\n",
    "    vol_index_df.loc[vol_index_df['potential_genus_match'] == True, 'closest_epithet'] = -1\n",
    "    vol_index_df['closest_epithet'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_potential_infra_type(row):\n",
    "    if row['potential_infra_match'] == True:\n",
    "        return row['word'] + \"_\" + str(row['page_num']) + \"_\" + str(row['block_num']) + \"_\" + str(row['line_num'])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df.loc[(vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True), 'closest_infra_type'] = -1\n",
    "    vol_index_df['closest_infra_type'] = vol_index_df.apply(extract_potential_infra_type, axis = 1)\n",
    "    vol_index_df.loc[(vol_index_df['potential_infra_match'] == False) & ((vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True)), 'closest_infra_type'] = -1\n",
    "    vol_index_df['closest_infra_type'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    infra_name_match_indecies = vol_index_df[vol_index_df['potential_infra_match'] == True].index + 1\n",
    "    vol_index_df['closest_infra_name'] = np.NaN\n",
    "    vol_index_df.loc[infra_name_match_indecies, 'closest_infra_name'] = vol_index_df.apply(lambda row : row['word'] + \"_\" + str(row['page_num']) + \"_\" + str(row['block_num']) + \"_\" + str(row['line_num']) , axis = 1)\n",
    "    vol_index_df['potential_infra_name_match'] = vol_index_df.index.isin(infra_name_match_indecies)\n",
    "    vol_index_df.loc[(vol_index_df['potential_infra_match'] == True) | (vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True), 'closest_infra_name'] = -1\n",
    "    vol_index_df['closest_infra_name'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    cond = ((vol_index_df['closest_infra_name'] != '') | (vol_index_df['closest_infra_name'] != -1) | (~vol_index_df['closest_infra_name'].isna())) & \\\n",
    "           (vol_index_df['word'].apply(has_hybrid_symbols) == True)\n",
    "    \n",
    "    vol_index_df.loc[cond, 'is_hybrid'] = True\n",
    "    vol_index_df['is_hybrid'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['potential_author_match'] = (vol_index_df['potential_genus_match'] == False) & \\\n",
    "                                             (vol_index_df['potential_epithet_match'] == False) & \\\n",
    "                                             (vol_index_df['potential_infra_match'] == False) & \\\n",
    "                                             (vol_index_df['potential_infra_name_match'] == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df.replace(-1, np.NaN, inplace = True)\n",
    "    vol_index_df.replace(np.NaN, \"\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#author grouping \n",
    "# \n",
    "author_grouping = ['closest_genus', 'closest_epithet', 'closest_infra_name']\n",
    "merge_on = ['closest_genus', 'closest_epithet', 'closest_infra_name']\n",
    "def concatenate(group):\n",
    "    return group.loc[group['potential_author_match'] == True, 'word'].str.cat(sep=' ')\n",
    "\n",
    "result_df_authors = [] \n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]: \n",
    "    #author_grouping = ['closest_genus', 'closest_epithet']\n",
    "    #merge_on = ['closest_genus', 'closest_epithet']\n",
    "    groups = vol_index_df.groupby(author_grouping)\n",
    "    concatenated = groups.apply(concatenate).reset_index()\n",
    "\n",
    "    # add the concatenated values to the original dataframe\n",
    "    result = vol_index_df.merge(concatenated[merge_on + [0]], on=merge_on, how='left').rename(columns={0: 'authors'})\n",
    "    result_df_authors.append(result)\n",
    "    \n",
    "vol1_index_df, vol2_index_df, vol3_index_df = result_df_authors[0], result_df_authors[1], result_df_authors[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "#     #vol_index_df.replace(\"\", np.NaN,inplace = True)\n",
    "#     vol_index_df.replace(np.NaN, \"\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  4.70it/s]\n",
      "100%|██████████| 22/22 [00:04<00:00,  4.62it/s]\n",
      "100%|██████████| 28/28 [00:05<00:00,  4.83it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_cat_test = [(vol1_index_df, vol1_index, vol1_doc, \"catagorized_vol1\"),\n",
    "                         (vol2_index_df, vol2_index, vol2_doc, \"catagorized_vol2\"),\n",
    "                         (vol3_index_df, vol3_index, vol3_doc, \"catagorized_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_cat_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        for col_num in [0, 1]:\n",
    "            temp_df = vol_char_df[(vol_char_df['page_num'] == page_num) & (vol_char_df['col_num'] == col_num)]\n",
    "            #genus Coord is orange-pinkish, 5\n",
    "            for name, group in temp_df.groupby(['closest_genus'])['word_bbox']:\n",
    "                x0 = (group.apply(lambda x : x[0]).min())*TARGET_DPI/ 72\n",
    "                y0 = (group.apply(lambda x : x[1]).min())*TARGET_DPI/ 72\n",
    "                x1 = (group.apply(lambda x : x[2]).max())*TARGET_DPI/ 72\n",
    "                y1 = (group.apply(lambda x : x[3]).max())*TARGET_DPI/ 72\n",
    "                draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#6939a3\"), width=3)\n",
    "\n",
    "            for name, group in temp_df.groupby(['closest_epithet'])['word_bbox']:\n",
    "                if name != '':\n",
    "                    x0 = (group.apply(lambda x : x[0]).min())*TARGET_DPI/ 72\n",
    "                    y0 = (group.apply(lambda x : x[1]).min())*TARGET_DPI/ 72\n",
    "                    x1 = (group.apply(lambda x : x[2]).max())*TARGET_DPI/ 72\n",
    "                    y1 = (group.apply(lambda x : x[3]).max())*TARGET_DPI/ 72\n",
    "                    draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=3)\n",
    "\n",
    "            for name, group in temp_df.groupby(['closest_infra_name'])['word_bbox']:\n",
    "                if name != '':\n",
    "                    x0 = (group.apply(lambda x : x[0]).min())*TARGET_DPI/ 72\n",
    "                    y0 = (group.apply(lambda x : x[1]).min())*TARGET_DPI/ 72\n",
    "                    x1 = (group.apply(lambda x : x[2]).max())*TARGET_DPI/ 72\n",
    "                    y1 = (group.apply(lambda x : x[3]).max())*TARGET_DPI/ 72\n",
    "                    draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#8c690b\"), width=3)\n",
    "\n",
    "            temp_df_author_only = temp_df[temp_df['potential_author_match'] == True]\n",
    "            for name, group in temp_df_author_only.groupby(['closest_genus', 'closest_epithet', 'closest_infra_name'])['word_bbox']:\n",
    "                x0 = (group.apply(lambda x : x[0]).min())*TARGET_DPI/ 72\n",
    "                y0 = (group.apply(lambda x : x[1]).min())*TARGET_DPI/ 72\n",
    "                x1 = (group.apply(lambda x : x[2]).max())*TARGET_DPI/ 72\n",
    "                y1 = (group.apply(lambda x : x[3]).max())*TARGET_DPI/ 72\n",
    "\n",
    "                draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#9e9e9e\"), width=3)\n",
    "\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_words(word):\n",
    "    head, sep, tail = word.partition('_')\n",
    "    return head \n",
    "\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['closest_genus'] = vol_index_df['closest_genus'].apply(fix_words)\n",
    "    vol_index_df['closest_epithet'] = vol_index_df['closest_epithet'].apply(fix_words)\n",
    "    vol_index_df['closest_infra_type'] = vol_index_df['closest_infra_type'].apply(fix_words)\n",
    "    vol_index_df['closest_infra_name'] = vol_index_df['closest_infra_name'].apply(fix_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_prune_authors_list = []\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    result_prune_authors = vol_index_df[(vol_index_df['potential_genus_match'] == True) |\n",
    "                                        (vol_index_df['potential_epithet_match'] == True) |\n",
    "                                        (vol_index_df['potential_infra_name_match'] == True)].copy()\n",
    "    result_prune_authors_list.append(result_prune_authors)\n",
    "\n",
    "prune_authors_vol1, prune_authors_vol2, prune_authors_vol3 =  result_prune_authors_list[0], result_prune_authors_list[1], result_prune_authors_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick fix for vol1 epithet on the same line as author situation\n",
    "cond = (prune_authors_vol1['closest_genus'] != '') & (prune_authors_vol1['closest_epithet'] == '') & (prune_authors_vol1['authors'] != '')\n",
    "prune_authors_vol1.loc[cond, 'closest_epithet'] = prune_authors_vol1.loc[cond,'authors'].str.split().apply(lambda s: s[0])\n",
    "prune_authors_vol1.loc[cond, 'authors'] = prune_authors_vol1.loc[cond,'authors'].str.split().apply(lambda s: \" \".join(s[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxon_rank_specific(row):\n",
    "    has_genus = (pd.isnull(row['closest_genus']) == False) & (row['closest_genus'] != \"\") & (row['closest_genus'] != -1)\n",
    "    has_epithet = (pd.isnull(row['closest_epithet']) == False) & (row['closest_epithet'] != \"\") & (row['closest_epithet'] != -1)\n",
    "    \n",
    "    has_infra = (pd.isnull(row['closest_infra_name']) == False) & (row['closest_infra_name'] != \"\") & (row['closest_infra_name'] != -1)\n",
    "    has_infra_type = (pd.isnull(row['closest_infra_type']) == False) & (row['closest_infra_type'] != \"\") & (row['closest_infra_type'] != -1)\n",
    "    infra_type = row['closest_infra_type']\n",
    "    is_infra_hybrid = has_hybrid_symbols(row['closest_infra_type']) == True\n",
    "    if is_infra_hybrid:\n",
    "        infra_type = \"hybrid\"\n",
    "    \n",
    "    is_hybrid  = row['is_hybrid'] == True\n",
    "    prefix  = \"\"\n",
    "    if is_hybrid:\n",
    "        prefix = \"hybrid \"\n",
    "\n",
    "    if has_infra or has_infra_type:\n",
    "        return f\"infra ({infra_type})\"\n",
    "    if has_epithet:\n",
    "        return prefix + \"epithet\"\n",
    "    if has_genus:\n",
    "        return prefix + \"genus\"\n",
    "\n",
    "def get_taxon_rank_general(row):\n",
    "    has_genus = (pd.isnull(row['closest_genus']) == False) & (row['closest_genus'] != \"\") & (row['closest_genus'] != -1)\n",
    "    has_epithet = (pd.isnull(row['closest_epithet']) == False) & (row['closest_epithet'] != \"\") & (row['closest_epithet'] != -1)\n",
    "    has_infra = (pd.isnull(row['closest_infra_name']) == False) & (row['closest_infra_name'] != \"\") & (row['closest_infra_name'] != -1)\n",
    "    has_infra_type = (pd.isnull(row['closest_infra_type']) == False) & (row['closest_infra_type'] != \"\") & (row['closest_infra_type'] != -1)\n",
    "    \n",
    "    if has_infra or has_infra_type:\n",
    "        return \"infra\"\n",
    "    if has_epithet:\n",
    "        return \"epithet\"\n",
    "    if has_genus:\n",
    "        return \"genus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_authors_vol1['closest_genus'] = prune_authors_vol1['closest_genus'].str.replace(\"œ\", \"oe\" )\n",
    "prune_authors_vol2['closest_genus'] = prune_authors_vol2['closest_genus'].str.replace(\"œ\", \"oe\" )\n",
    "prune_authors_vol3['closest_genus'] = prune_authors_vol3['closest_genus'].str.replace(\"œ\", \"oe\" )\n",
    "\n",
    "prune_authors_vol1['closest_epithet'] = prune_authors_vol1['closest_epithet'].str.replace(\"œ\", \"oe\" )\n",
    "prune_authors_vol2['closest_epithet'] = prune_authors_vol2['closest_epithet'].str.replace(\"œ\", \"oe\" )\n",
    "prune_authors_vol3['closest_epithet'] = prune_authors_vol3['closest_epithet'].str.replace(\"œ\", \"oe\" )\n",
    "\n",
    "prune_authors_vol1['closest_infra_name'] = prune_authors_vol1['closest_infra_name'].str.replace(\"œ\", \"oe\" )\n",
    "prune_authors_vol2['closest_infra_name'] = prune_authors_vol2['closest_infra_name'].str.replace(\"œ\", \"oe\" )\n",
    "prune_authors_vol3['closest_infra_name'] = prune_authors_vol3['closest_infra_name'].str.replace(\"œ\", \"oe\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol_index_df in [prune_authors_vol1, prune_authors_vol2, prune_authors_vol3]:\n",
    "    vol_index_df['taxon_rank'] = vol_index_df.apply(get_taxon_rank_general, axis = 1)\n",
    "    vol_index_df['taxon_rank_detailed'] = vol_index_df.apply(get_taxon_rank_specific, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_vol1 = prune_authors_vol1[['closest_genus',\n",
    "                                      'closest_epithet',\n",
    "                                      'closest_infra_name',\n",
    "                                      'authors',\n",
    "                                      'taxon_rank',\n",
    "                                      'taxon_rank_detailed']]\n",
    "simplified_vol1.to_csv('../output/local/index_output/vol1_index_output.csv')\n",
    "\n",
    "simplified_vol2 = prune_authors_vol2[['closest_genus',\n",
    "                                      'closest_epithet',\n",
    "                                      'closest_infra_name',\n",
    "                                      'authors',\n",
    "                                      'taxon_rank',\n",
    "                                      'taxon_rank_detailed']]\n",
    "simplified_vol2.to_csv('../output/local/index_output/vol2_index_output.csv')\n",
    "                                \n",
    "simplified_vol3 = prune_authors_vol3[['closest_genus',\n",
    "                                      'closest_epithet',\n",
    "                                      'closest_infra_name',\n",
    "                                      'authors',\n",
    "                                      'taxon_rank',\n",
    "                                      'taxon_rank_detailed']]\n",
    "simplified_vol3.to_csv('../output/local/index_output/vol3_index_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_italics_simplified_vol1 = prune_authors_vol1.loc[(prune_authors_vol1['span_flags'] != 6),\n",
    "                                                     ['closest_genus',\n",
    "                                                      'closest_epithet',\n",
    "                                                      'closest_infra_name',\n",
    "                                                      'authors',\n",
    "                                                      'taxon_rank',\n",
    "                                                      'taxon_rank_detailed']]\n",
    "non_italics_simplified_vol1.to_csv('../output/local/index_output/vol1_nonitalics.csv')\n",
    "\n",
    "non_italics_simplified_vol2 = prune_authors_vol2.loc[(prune_authors_vol2['span_flags'] != 6),\n",
    "                                                     ['closest_genus',\n",
    "                                                      'closest_epithet',\n",
    "                                                      'closest_infra_name',\n",
    "                                                      'authors',\n",
    "                                                      'taxon_rank',\n",
    "                                                      'taxon_rank_detailed']]\n",
    "non_italics_simplified_vol2.to_csv('../output/local/index_output/vol2_nonitalics.csv')\n",
    "\n",
    "non_italics_simplified_vol3 = prune_authors_vol3.loc[(prune_authors_vol3['span_flags'] != 6),\n",
    "                                                     ['closest_genus',\n",
    "                                                      'closest_epithet',\n",
    "                                                      'closest_infra_name',\n",
    "                                                      'authors',\n",
    "                                                      'taxon_rank',\n",
    "                                                      'taxon_rank_detailed']]\n",
    "non_italics_simplified_vol3.to_csv('../output/local/index_output/vol3_nonitalics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
