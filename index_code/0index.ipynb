{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING BOOKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_path = '../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 1.pdf'\n",
    "vol2_path = '../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 2.pdf'\n",
    "vol3_path = '../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 3.pdf'\n",
    "\n",
    "vol1_doc = fitz.open(vol1_path)\n",
    "vol2_doc = fitz.open(vol2_path)\n",
    "vol3_doc = fitz.open(vol3_path)\n",
    "\n",
    "vol1_pages = [vol1_doc[i] for i in range(vol1_doc.page_count)]\n",
    "vol2_pages = [vol2_doc[i] for i in range(vol2_doc.page_count)]\n",
    "vol3_pages = [vol3_doc[i] for i in range(vol3_doc.page_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_char_df = pd.read_pickle(\"../input/char_df/vol1_df.pkl\")\n",
    "vol2_char_df = pd.read_pickle(\"../input/char_df/vol2_df.pkl\")\n",
    "vol3_char_df = pd.read_pickle(\"../input/char_df/vol3_df.pkl\")\n",
    "\n",
    "vol1_index = list(range(616, 639)) #inclusive\n",
    "vol2_index = list(range(703, 725))\n",
    "vol3_index = list(range(555, 583))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DPI = 300\n",
    "mat = fitz.Matrix(TARGET_DPI/ 72, TARGET_DPI/ 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding strict matching genera, epithet, and column numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genus_match(row):\n",
    "    word_rspace_removed = row['word'].rstrip()\n",
    "    return row['word_num'] == 0 and \\\n",
    "           word_rspace_removed.isalpha() and \\\n",
    "           word_rspace_removed[0].isupper() and word_rspace_removed[1:].islower()\n",
    "           \n",
    "def epithet_match(row):\n",
    "    word_rspace_removed = row['word'].rstrip()\n",
    "    return row['word_num'] == 0 and \\\n",
    "           word_rspace_removed.isalpha() and \\\n",
    "           word_rspace_removed.islower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rightmost point of any bounding box:\n",
    "def get_center_x0(vol_char_df, page_num, bias = 30):\n",
    "    \"\"\"WARNING: Bias = 30 large bias causes miscatagorization in page number in book\"\"\"\n",
    "    df = vol_char_df[vol_char_df['page_num'] == page_num]\n",
    "    \n",
    "    right_bound = df['line_bbox'].apply(lambda x : x[2]).max() \n",
    "    #leftmost point of any bounding box:\n",
    "    left_bound = df['line_bbox'].apply(lambda x : x[0]).min()\n",
    "\n",
    "    return 0.5*(right_bound + left_bound) - bias\n",
    "\n",
    "\n",
    "def get_col_num(coords, center_x0):\n",
    "    x0, y0, x1, y1 = coords\n",
    "    return int(x0 >= center_x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:12<00:00,  1.79it/s]\n",
      "100%|██████████| 22/22 [00:13<00:00,  1.63it/s]\n",
      "100%|██████████| 28/28 [00:14<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_col_num = [(vol1_char_df, vol1_index, vol1_doc),\n",
    "                        (vol2_char_df, vol2_index, vol2_doc),\n",
    "                        (vol3_char_df, vol3_index, vol3_doc)]\n",
    "\n",
    "for vol_char_df ,vol_index, doc in all_vol_data_col_num: \n",
    "    #for each volume check if genus pattern / epithet pattern exists within the index part of the book\n",
    "    vol_char_df['genus_index_pat_match'] = (vol_char_df['page_num'].isin(vol_index)) & (vol_char_df.apply(genus_match, axis = 1))\n",
    "    vol_char_df['epithet_index_pat_match'] = (vol_char_df['page_num'].isin(vol_index)) & (vol_char_df.apply(epithet_match, axis = 1))\n",
    "    \n",
    "    for page_num in tqdm(vol_index):\n",
    "        center_x0 = get_center_x0(vol_char_df, page_num)\n",
    "        #find center based on x0 coordinate of each line\n",
    "        vol_char_df['col_num'] = vol_char_df['line_bbox'].apply(lambda coords : get_col_num(coords, center_x0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genus / epithet flagging \n",
    "flagging pages where number of strict genus or epithet patern matches is less than 3 per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***FLAGS***\n",
      " number of pages to check: 3\n",
      "  genera\n",
      "\t number of genera: 1, page number: 2, column number: 0\n",
      "\t number of genera: 0, page number: 20, column number: 1\n",
      "\t number of genera: 1, page number: 23, column number: 0\n",
      "  epithets\n",
      "\t number of epithets: 2, page number: 23, column number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:03<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***FLAGS***\n",
      " number of pages to check: 2\n",
      "  genera\n",
      "\t number of genera: 2, page number: 4, column number: 0\n",
      "\t number of genera: 1, page number: 4, column number: 1\n",
      "\t number of genera: 0, page number: 5, column number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:04<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***FLAGS***\n",
      " number of pages to check: 7\n",
      "  genera\n",
      "\t number of genera: 1, page number: 2, column number: 1\n",
      "\t number of genera: 1, page number: 6, column number: 0\n",
      "\t number of genera: 1, page number: 21, column number: 0\n",
      "\t number of genera: 1, page number: 22, column number: 0\n",
      "\t number of genera: 2, page number: 24, column number: 1\n",
      "\t number of genera: 0, page number: 26, column number: 1\n",
      "\t number of genera: 2, page number: 28, column number: 0\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_flagg_strict_match = [(vol1_char_df, vol1_index, vol1_doc, \"strickt_match_vol1\"),\n",
    "                                   (vol2_char_df, vol2_index, vol2_doc, \"strickt_match_vol2\"),\n",
    "                                   (vol3_char_df, vol3_index, vol3_doc, \"strickt_match_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, vol_doc, output_name in all_vol_data_flagg_strict_match: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "    genus_flag_list = []\n",
    "    epithet_flag_list = []\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = vol_doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        genus_db = vol_char_df[(vol_char_df['page_num'] == page_num)\n",
    "                                & (vol_char_df['genus_index_pat_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['epithet_index_pat_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #genus pattern match flag should check with half page and not entire page:\n",
    "        for col in range(2):\n",
    "            num_genus_col = genus_db[genus_db[\"col_num\"] == col].shape[0]\n",
    "            num_epithet_col = epithet_db[epithet_db[\"col_num\"] == col].shape[0]\n",
    "            if num_genus_col <= 2:\n",
    "                genus_flag_list.append((num_genus_col, page_num - vol_index[0] + 1, col))\n",
    "            if num_epithet_col <= 2:\n",
    "                epithet_flag_list.append((num_epithet_col, page_num - vol_index[0] + 1, col))\n",
    "\n",
    "        for coord in genus_db['word_bbox']:\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "\n",
    "        for coord in epithet_db['word_bbox']:\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=5)\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])    \n",
    "    \n",
    "    num_flag_pages = len(set([g[1] for g in genus_flag_list] + [e[1] for e in epithet_flag_list]))\n",
    "    if num_flag_pages > 0: \n",
    "        print(\"***FLAGS***\")\n",
    "        print(f\" number of pages to check: {num_flag_pages}\")\n",
    "        if genus_flag_list:\n",
    "            print(\"  genera\")\n",
    "            [print(f\"\\t number of genera: {g_flag[0]}, page number: {g_flag[1]}, column number: {g_flag[2]}\") for g_flag in genus_flag_list]\n",
    "        if epithet_flag_list:\n",
    "            print(\"  epithets\")\n",
    "            [print(f\"\\t number of epithets: {e_flag[0]}, page number: {e_flag[1]}, column number: {e_flag[2]}\") for e_flag in epithet_flag_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on flags need to make sure: \n",
    "- first find epithet coord match \n",
    "- then find genus coord match s.t. word is not in epithet coord match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### match based on coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_coord_match(x, x_ref_left, x_ref_right, margin):\n",
    "    return (x_ref_left - margin <= x[0] and x[0] <= x_ref_left + margin) or (x_ref_right - margin <= x[0] and x[0] <= x_ref_right + margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### epithets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 22.71it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 21.34it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 24.99it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "                            (vol2_char_df, vol2_index),\n",
    "                            (vol3_char_df, vol3_index)]\n",
    "\n",
    "for vol_char_df, vol_index in all_vol_data_coord_match: \n",
    "    vol_char_df[\"epithet_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"epithet_index_pat_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        epithet_char_df = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"epithet_index_pat_match\"] == True)]\n",
    "        epithet_df = epithet_char_df.loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"])].drop_duplicates()\n",
    "        page_epithet_2dic = [{}, {}]\n",
    "        \n",
    "        for i in range(epithet_df.shape[0]):\n",
    "            e_index = str(page_num) + \"_\" + str(i)\n",
    "            p0 = epithet_df['word_bbox'].iloc[i]\n",
    "            x_ref = p0[0]\n",
    "            col = epithet_df['col_num'].iloc[i]\n",
    "\n",
    "            ref_neighbors_df = epithet_df[(epithet_df[\"page_num\"] == page_num) & \n",
    "                                          (epithet_df[\"word_bbox\"].apply(lambda x : x_ref - margin <= x[0] and x[0] <= x_ref + margin))]\n",
    "            \n",
    "            num_neighbors = ref_neighbors_df.shape[0]\n",
    "            mean_neighbors = ref_neighbors_df[\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            page_epithet_2dic[col][e_index] = (num_neighbors, mean_neighbors)\n",
    "        \n",
    "        mean_left_epithet = max(page_epithet_2dic[0].values(), default = [-1, -1])[1]\n",
    "        mean_right_epithet = max(page_epithet_2dic[1].values(), default = [-1, -1])[1]\n",
    "\n",
    "        if mean_left_epithet == -1 or mean_right_epithet == -1:\n",
    "            mean_valid_col = max(mean_left_epithet, mean_right_epithet)\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"epithet_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_valid_col, mean_valid_col, margin))\n",
    "        elif mean_left_epithet == -1 and mean_right_epithet == -1:\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"epithet_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : False)\n",
    "        else: \n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"epithet_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_left_epithet, mean_right_epithet, margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  5.68it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  5.70it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  6.01it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_epithet_coord_match_test = [(vol1_char_df, vol1_index, vol1_doc, \"epithet_coord_match_pruned_vol1\"),\n",
    "                                         (vol2_char_df, vol2_index, vol2_doc, \"epithet_coord_match_pruned_vol2\"),\n",
    "                                         (vol3_char_df, vol3_index, vol3_doc, \"epithet_coord_match_pruned_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_epithet_coord_match_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "    \n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        epithet_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['epithet_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['epithet_index_pat_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #epithet Coord is orange-pinkish, 5\n",
    "        for coord in epithet_coord_db[\"pruned_word_bbox\"] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "\n",
    "        #epithet is blue, 3\n",
    "        for coord in epithet_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=3)\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 32.02it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 29.64it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 34.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reminder:\n",
    "# all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "#                             (vol2_char_df, vol2_index),\n",
    "#                             (vol3_char_df, vol3_index)]\n",
    "# DOES NOT CHECK IF COORD IS SAME AS EPITHET UNTIL NEXT SECTION!\n",
    "\n",
    "for vol_char_df, vol_index in all_vol_data_coord_match: \n",
    "    #genus and not epithet\n",
    "    vol_char_df[\"genus_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"genus_index_pat_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        genus_char_df = vol_char_df[(vol_char_df[\"page_num\"] == page_num) &\n",
    "                                    (vol_char_df[\"genus_index_pat_match\"] == True)]\n",
    "        genus_df = genus_char_df.loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"])].drop_duplicates()\n",
    "        page_genus_2dic = [{}, {}]\n",
    "        \n",
    "        epithet_left_coord_mean = vol_char_df[(vol_char_df[\"epithet_coord_match\"] == True) &\n",
    "                                              (vol_char_df[\"page_num\"] == page_num) &\n",
    "                                              (vol_char_df[\"col_num\"] == 0)\n",
    "                                             ]['pruned_word_bbox'].apply(lambda x : x[0]).mean()\n",
    "        epithet_right_coord_mean = vol_char_df[(vol_char_df[\"epithet_coord_match\"] == True) &\n",
    "                                               (vol_char_df[\"page_num\"] == page_num) &\n",
    "                                               (vol_char_df[\"col_num\"] == 1)\n",
    "                                             ]['pruned_word_bbox'].apply(lambda x : x[0]).mean()\n",
    "        epithet_coord_mean_list = [epithet_left_coord_mean, epithet_right_coord_mean]\n",
    "\n",
    "        for i in range(genus_df.shape[0]):\n",
    "            g_index = str(page_num) + \"_\" + str(i)\n",
    "            p0 = genus_df['word_bbox'].iloc[i]\n",
    "            x_ref = p0[0]\n",
    "            col = genus_df['col_num'].iloc[i]\n",
    "\n",
    "            ref_neighbors_df = genus_df[(genus_df[\"page_num\"] == page_num) & \n",
    "                                        (genus_df[\"word_bbox\"].apply(lambda x : x_ref - margin <= x[0] and x[0] <= x_ref + margin))]\n",
    "\n",
    "            num_neighbors = ref_neighbors_df.shape[0]\n",
    "            mean_neighbors = ref_neighbors_df[\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            if mean_neighbors > epithet_coord_mean_list[col]: \n",
    "                mean_neighbors = -1\n",
    "            page_genus_2dic[col][g_index] = (num_neighbors, mean_neighbors)\n",
    "        \n",
    "        mean_left_genus = max(page_genus_2dic[0].values(), default = [-1, -1])[1]\n",
    "        mean_right_genus = max(page_genus_2dic[1].values(), default = [-1, -1])[1]\n",
    "\n",
    "        if mean_left_genus == -1 or mean_right_genus == -1:\n",
    "            mean_valid_col = max(mean_left_genus, mean_right_genus)\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"genus_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_valid_col, mean_valid_col, margin))\n",
    "        elif mean_left_genus == -1 and mean_right_genus == -1:\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"genus_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : False)\n",
    "        else: \n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"genus_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match(x, mean_left_genus, mean_right_genus, margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  5.71it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  5.77it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  5.99it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_genus_coord_match_test = [(vol1_char_df, vol1_index, vol1_doc, \"genus_coord_match_vol1\"),\n",
    "                                       (vol2_char_df, vol2_index, vol2_doc, \"genus_coord_match_vol2\"),\n",
    "                                       (vol3_char_df, vol3_index, vol3_doc, \"genus_coord_match_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_genus_coord_match_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "\n",
    "        genus_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['genus_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['epithet_coord_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in genus_coord_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # #epithet is red, 3\n",
    "        for coord in epithet_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#000099\"), width=3)\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### improving the coord matches \n",
    "takes genus coming before epithet into account now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_genus_match(row):\n",
    "    word_rspace_removed = row['word'].rstrip()\n",
    "    return row['genus_coord_match'] == True and \\\n",
    "           row['epithet_coord_match'] == False and \\\n",
    "           word_rspace_removed.find(\"Flore\") == -1 and \\\n",
    "           ((word_rspace_removed.isupper() == False and \\\n",
    "             word_rspace_removed.isnumeric() == False) or \\\n",
    "            ((word_rspace_removed == 'X') or (word_rspace_removed =='×')))\n",
    "           # removing this for-    hg now ... and row['genus_mean_coord'] < row['epithet_mean_coord'] #important to check this only when epithet_coord_match is false?\n",
    "\n",
    "def potential_epithet_match(row):\n",
    "    word_rspace_removed = row['word'].rstrip()\n",
    "    return row['epithet_coord_match'] == True and \\\n",
    "           ((word_rspace_removed.isupper() == False and \\\n",
    "             word_rspace_removed.isnumeric() == False) or \\\n",
    "            (word_rspace_removed == 'X') or (word_rspace_removed =='×'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_char_df['potential_genus_match'] = vol1_char_df.apply(potential_genus_match, axis = 1)\n",
    "vol1_char_df['potential_epithet_match'] = vol1_char_df.apply(potential_epithet_match, axis = 1)\n",
    "\n",
    "vol2_char_df['potential_genus_match'] = vol2_char_df.apply(potential_genus_match, axis = 1)\n",
    "vol2_char_df['potential_epithet_match'] = vol2_char_df.apply(potential_epithet_match, axis = 1)\n",
    "\n",
    "vol3_char_df['potential_genus_match'] = vol3_char_df.apply(potential_genus_match, axis = 1)\n",
    "vol3_char_df['potential_epithet_match'] = vol3_char_df.apply(potential_epithet_match, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  5.77it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  5.89it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  6.11it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_GE_potential_match_test = [(vol1_char_df, vol1_index, vol1_doc, \"GE_potential_match_vol1\"),\n",
    "                                        (vol2_char_df, vol2_index, vol2_doc, \"GE_potential_match_vol2\"),\n",
    "                                        (vol3_char_df, vol3_index, vol3_doc, \"GE_potential_match_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_GE_potential_match_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        genus_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['potential_genus_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        epithet_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['potential_epithet_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in genus_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # #epithet is red, 3\n",
    "        for coord in epithet_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#000099\"), width=3)\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOME HARDCODING PARTS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erianthus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol_num</th>\n",
       "      <th>page_num</th>\n",
       "      <th>block_num</th>\n",
       "      <th>block_num_absolute</th>\n",
       "      <th>block_bbox</th>\n",
       "      <th>line_num</th>\n",
       "      <th>line_wmode</th>\n",
       "      <th>line_dir</th>\n",
       "      <th>line_bbox</th>\n",
       "      <th>span_num</th>\n",
       "      <th>...</th>\n",
       "      <th>char</th>\n",
       "      <th>char_origin</th>\n",
       "      <th>char_bbox</th>\n",
       "      <th>genus_index_pat_match</th>\n",
       "      <th>epithet_index_pat_match</th>\n",
       "      <th>col_num</th>\n",
       "      <th>epithet_coord_match</th>\n",
       "      <th>genus_coord_match</th>\n",
       "      <th>potential_genus_match</th>\n",
       "      <th>potential_epithet_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1734317</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>J</td>\n",
       "      <td>(239.9900665283203, 357.20001220703125)</td>\n",
       "      <td>(239.9900665283203, 352.70001220703125, 242.33...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734318</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>(242.32186889648438, 357.20001220703125)</td>\n",
       "      <td>(242.32186889648438, 352.70001220703125, 243.8...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734319</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>d</td>\n",
       "      <td>(243.81723022460938, 357.20001220703125)</td>\n",
       "      <td>(243.81723022460938, 352.70001220703125, 246.8...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734320</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>,</td>\n",
       "      <td>(246.8169708251953, 357.20001220703125)</td>\n",
       "      <td>(246.8169708251953, 352.70001220703125, 248.32...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734321</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>(248.3123321533203, 357.20001220703125)</td>\n",
       "      <td>(248.3123321533203, 352.70001220703125, 250.31...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734322</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>l</td>\n",
       "      <td>(250.30714416503906, 357.20001220703125)</td>\n",
       "      <td>(250.30714416503906, 352.70001220703125, 251.9...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734323</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>(251.9709930419922, 357.20001220703125)</td>\n",
       "      <td>(251.9709930419922, 352.70001220703125, 255.64...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734324</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>(255.638671875, 357.20001220703125)</td>\n",
       "      <td>(255.638671875, 352.70001220703125, 257.642547...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734325</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>l</td>\n",
       "      <td>(257.63348388671875, 357.20001220703125)</td>\n",
       "      <td>(257.63348388671875, 352.70001220703125, 259.3...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734326</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>(259.2973327636719, 357.20001220703125)</td>\n",
       "      <td>(259.2973327636719, 352.70001220703125, 263.64...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734327</th>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(230.63999938964844, 352.70001220703125, 265.1...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>(263.6429138183594, 357.20001220703125)</td>\n",
       "      <td>(263.6429138183594, 352.70001220703125, 265.14...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        vol_num  page_num  block_num  block_num_absolute  \\\n",
       "1734317       1       624         75                 120   \n",
       "1734318       1       624         75                 120   \n",
       "1734319       1       624         75                 120   \n",
       "1734320       1       624         75                 120   \n",
       "1734321       1       624         75                 120   \n",
       "1734322       1       624         75                 120   \n",
       "1734323       1       624         75                 120   \n",
       "1734324       1       624         75                 120   \n",
       "1734325       1       624         75                 120   \n",
       "1734326       1       624         75                 120   \n",
       "1734327       1       624         75                 120   \n",
       "\n",
       "                                                block_bbox  line_num  \\\n",
       "1734317  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734318  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734319  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734320  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734321  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734322  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734323  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734324  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734325  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734326  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "1734327  (230.63999938964844, 352.70001220703125, 265.1...         0   \n",
       "\n",
       "         line_wmode    line_dir  \\\n",
       "1734317           0  (1.0, 0.0)   \n",
       "1734318           0  (1.0, 0.0)   \n",
       "1734319           0  (1.0, 0.0)   \n",
       "1734320           0  (1.0, 0.0)   \n",
       "1734321           0  (1.0, 0.0)   \n",
       "1734322           0  (1.0, 0.0)   \n",
       "1734323           0  (1.0, 0.0)   \n",
       "1734324           0  (1.0, 0.0)   \n",
       "1734325           0  (1.0, 0.0)   \n",
       "1734326           0  (1.0, 0.0)   \n",
       "1734327           0  (1.0, 0.0)   \n",
       "\n",
       "                                                 line_bbox  span_num  ...  \\\n",
       "1734317  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734318  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734319  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734320  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734321  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734322  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734323  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734324  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734325  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734326  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "1734327  (230.63999938964844, 352.70001220703125, 265.1...         1  ...   \n",
       "\n",
       "         char                               char_origin  \\\n",
       "1734317     J   (239.9900665283203, 357.20001220703125)   \n",
       "1734318     .  (242.32186889648438, 357.20001220703125)   \n",
       "1734319     d  (243.81723022460938, 357.20001220703125)   \n",
       "1734320     ,   (246.8169708251953, 357.20001220703125)   \n",
       "1734321     I   (248.3123321533203, 357.20001220703125)   \n",
       "1734322     l  (250.30714416503906, 357.20001220703125)   \n",
       "1734323     L   (251.9709930419922, 357.20001220703125)   \n",
       "1734324     I       (255.638671875, 357.20001220703125)   \n",
       "1734325     l  (257.63348388671875, 357.20001220703125)   \n",
       "1734326     U   (259.2973327636719, 357.20001220703125)   \n",
       "1734327     .   (263.6429138183594, 357.20001220703125)   \n",
       "\n",
       "                                                 char_bbox  \\\n",
       "1734317  (239.9900665283203, 352.70001220703125, 242.33...   \n",
       "1734318  (242.32186889648438, 352.70001220703125, 243.8...   \n",
       "1734319  (243.81723022460938, 352.70001220703125, 246.8...   \n",
       "1734320  (246.8169708251953, 352.70001220703125, 248.32...   \n",
       "1734321  (248.3123321533203, 352.70001220703125, 250.31...   \n",
       "1734322  (250.30714416503906, 352.70001220703125, 251.9...   \n",
       "1734323  (251.9709930419922, 352.70001220703125, 255.64...   \n",
       "1734324  (255.638671875, 352.70001220703125, 257.642547...   \n",
       "1734325  (257.63348388671875, 352.70001220703125, 259.3...   \n",
       "1734326  (259.2973327636719, 352.70001220703125, 263.64...   \n",
       "1734327  (263.6429138183594, 352.70001220703125, 265.14...   \n",
       "\n",
       "         genus_index_pat_match  epithet_index_pat_match  col_num  \\\n",
       "1734317                  False                    False        1   \n",
       "1734318                  False                    False        1   \n",
       "1734319                  False                    False        1   \n",
       "1734320                  False                    False        1   \n",
       "1734321                  False                    False        1   \n",
       "1734322                  False                    False        1   \n",
       "1734323                  False                    False        1   \n",
       "1734324                  False                    False        1   \n",
       "1734325                  False                    False        1   \n",
       "1734326                  False                    False        1   \n",
       "1734327                  False                    False        1   \n",
       "\n",
       "        epithet_coord_match genus_coord_match  potential_genus_match  \\\n",
       "1734317                True             False                  False   \n",
       "1734318                True             False                  False   \n",
       "1734319                True             False                  False   \n",
       "1734320                True             False                  False   \n",
       "1734321                True             False                  False   \n",
       "1734322                True             False                  False   \n",
       "1734323                True             False                  False   \n",
       "1734324                True             False                  False   \n",
       "1734325                True             False                  False   \n",
       "1734326                True             False                  False   \n",
       "1734327                True             False                  False   \n",
       "\n",
       "        potential_epithet_match  \n",
       "1734317                    True  \n",
       "1734318                    True  \n",
       "1734319                    True  \n",
       "1734320                    True  \n",
       "1734321                    True  \n",
       "1734322                    True  \n",
       "1734323                    True  \n",
       "1734324                    True  \n",
       "1734325                    True  \n",
       "1734326                    True  \n",
       "1734327                    True  \n",
       "\n",
       "[11 rows x 34 columns]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[vol1_char_df['word'].str.contains('d,IlLIlU')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on this image output in volumen 1:\n",
    " ![Erianthus](Erianthus.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1734312          Bieb.\n",
       "1734313           J_JI\n",
       "1734314           J_JI\n",
       "1734315           J_JI\n",
       "1734316           J_JI\n",
       "1734317    J.d,IlLIlU.\n",
       "1734318    J.d,IlLIlU.\n",
       "1734319    J.d,IlLIlU.\n",
       "1734320    J.d,IlLIlU.\n",
       "1734321    J.d,IlLIlU.\n",
       "1734322    J.d,IlLIlU.\n",
       "1734323    J.d,IlLIlU.\n",
       "1734324    J.d,IlLIlU.\n",
       "1734325    J.d,IlLIlU.\n",
       "1734326    J.d,IlLIlU.\n",
       "1734327    J.d,IlLIlU.\n",
       "1734328         hostii\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_old_char_vol1 = vol1_char_df.loc[1734312:1734328]\n",
    "weird_old_char_vol1['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1734312    2\n",
       "1734313    0\n",
       "1734314    0\n",
       "1734315    0\n",
       "1734316    0\n",
       "1734317    1\n",
       "1734318    1\n",
       "1734319    1\n",
       "1734320    1\n",
       "1734321    1\n",
       "1734322    1\n",
       "1734323    1\n",
       "1734324    1\n",
       "1734325    1\n",
       "1734326    1\n",
       "1734327    1\n",
       "1734328    0\n",
       "Name: word_num, dtype: int64"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_old_char_vol1['word_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually fixing the OCR error for J_JI J.d,IlLIlU. hostii Griseb.\n",
    "vol1_char_df.loc[1734313:1734327, 'word'] = 'Erianthus'\n",
    "vol1_char_df.loc[1734313:1734327, 'word_num'] = 0\n",
    "vol1_char_df.loc[1734313:1734327, 'pruned_word'] = 'Erianthus'\n",
    "temp_word_x0 = vol1_char_df.loc[1734313:1734327, 'word_bbox'].apply(lambda x : x[0]).min()\n",
    "temp_word_y0 = vol1_char_df.loc[1734313:1734327, 'word_bbox'].apply(lambda x : x[1]).min()\n",
    "temp_word_x1 = vol1_char_df.loc[1734313:1734327, 'word_bbox'].apply(lambda x : x[2]).max()\n",
    "temp_word_y1 = vol1_char_df.loc[1734313:1734327, 'word_bbox'].apply(lambda x : x[3]).max()\n",
    "vol1_char_df.loc[1734313:1734327, 'word_bbox'] =vol1_char_df.loc[1734313:1734327, 'word_bbox'].apply(lambda x : (temp_word_x0, temp_word_y0, temp_word_x1, temp_word_y1))\n",
    "\n",
    "vol1_char_df.loc[1734313:1734327, 'potential_epithet_match'] = False\n",
    "vol1_char_df.loc[1734313:1734327, 'potential_genus_match'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infra species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 22.91it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 21.57it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 24.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reminder:\n",
    "# all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "#                             (vol2_char_df, vol2_index),\n",
    "#                             (vol3_char_df, vol3_index)]\n",
    "for vol_char_df, vol_index in all_vol_data_coord_match: \n",
    "    vol_char_df[\"infra_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"potential_epithet_match\"] == True) | (vol_char_df[\"potential_genus_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        \n",
    "        mean_left_epithet = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        mean_left_genus = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        if math.isnan(mean_left_genus):\n",
    "            mean_left_genus_all = vol_char_df[(vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_left_epithet_all = vol_char_df[(vol_char_df[\"col_num\"] == 0) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_left_tab = mean_left_epithet_all - mean_left_genus_all\n",
    "        else: \n",
    "            mean_left_tab = mean_left_epithet - mean_left_genus\n",
    "        \n",
    "        mean_right_epithet = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        mean_right_genus = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "        if math.isnan(mean_right_genus):\n",
    "            mean_right_genus_all = vol_char_df[(vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_genus_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_right_epithet_all = vol_char_df[(vol_char_df[\"col_num\"] == 1) & (vol_char_df[\"potential_epithet_match\"] == True)][\"word_bbox\"].apply(lambda x : x[0]).mean()\n",
    "            mean_right_tab = mean_right_epithet_all - mean_right_genus_all\n",
    "        else: \n",
    "            mean_right_tab = mean_right_epithet - mean_right_genus\n",
    "\n",
    "\n",
    "        vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"word_num\"] == 0)  , \"infra_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"word_num\"] == 0)][\"word_bbox\"].apply(lambda x : is_coord_match(x, mean_left_epithet + mean_left_tab, mean_right_epithet + mean_right_tab, margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes longer but makes more sense generally. We will skip it here\n",
    "# def potential_author_match_infra_coord(row):\n",
    "#     word = row['word']\n",
    "#     pruned_word = row['pruned_word']\n",
    "#     lower_word = word.lower()\n",
    "#     latin_connectives = r\"^\\s?et[\\s|.]?$|^\\s?in[\\s|.]?$|^\\s?non[\\s|.]?$|^\\s?&[\\s|.]?$|^\\s?er[\\s|.]?$|^\\s?nec[\\s|.]?$|^\\s?mult[\\s|.]?$|^\\s?ex[\\s|.]?$|^\\s?fil[\\s|.]?$\"\n",
    "#     infra_symbols = r\"^var[\\s|.|\\b]?$|^subsp[\\s|.|\\b]?$|^ssp[\\s|.|\\b]?$|^spp[\\s|.|\\b]?$|^x[\\s|.|\\b]?$|^×[\\s|.|\\b]?$\"\n",
    "#     is_latin_connectives = re.search(latin_connectives, word) != None\n",
    "#     is_infra_symbol = re.search(infra_symbols, lower_word) != None\n",
    "#     if pruned_word:\n",
    "#         is_upper_first = pruned_word[0].isupper()\n",
    "#     else:\n",
    "#         is_upper_first = False\n",
    "#     return (not is_infra_symbol) and (is_upper_first or is_latin_connectives)\n",
    "\n",
    "def potential_author_match_infra_coord(word):\n",
    "    lower_word = word.lower()\n",
    "    latin_connectives = r\"^\\s?et[\\s|.]?$|^\\s?in[\\s|.]?$|^\\s?non[\\s|.]?$|^\\s?&[\\s|.]?$|^\\s?er[\\s|.]?$|^\\s?nec[\\s|.]?$|^\\s?mult[\\s|.]?$|^\\s?ex[\\s|.]?$|^\\s?fil[\\s|.]?$\"\n",
    "    infra_symbols = r\"^var[\\s|.|\\b]?$|^subsp[\\s|.|\\b]?$|^ssp[\\s|.|\\b]?$|^spp[\\s|.|\\b]?$|^x[\\s|.|\\b]?$|^×[\\s|.|\\b]?$\"\n",
    "    is_latin_connectives = re.search(latin_connectives, word) != None\n",
    "    is_infra_symbol = re.search(infra_symbols, lower_word) != None\n",
    "    return (not is_infra_symbol) and (word[0].isupper() or is_latin_connectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_infra_symbols(word):\n",
    "    infra_symbols = r\"^var[\\s|.|\\b]?$|^subsp[\\s|.|\\b]?$|^ssp[\\s|.|\\b]?$|^spp[\\s|.|\\b]?$|^x[\\s|.|\\b]?$|^×[\\s|.|\\b]?$\"\n",
    "    return re.search(infra_symbols, word) != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder:\n",
    "# all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "#                             (vol2_char_df, vol2_index),\n",
    "#                             (vol3_char_df, vol3_index)]\n",
    "for vol_char_df, _ in all_vol_data_coord_match:\n",
    "    vol_char_df[\"potential_infra_match\"] = (vol_char_df['word'].apply(has_infra_symbols)) | \\\n",
    "                                           ((vol_char_df[\"infra_coord_match\"] == True) & (vol_char_df['word'].apply(potential_author_match_infra_coord) == False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:24<00:00,  1.14it/s]\n",
      "100%|██████████| 22/22 [00:22<00:00,  1.03s/it]\n",
      "100%|██████████| 23/23 [00:21<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_dat_infra_match_test = [(vol1_char_df, vol1_index, vol1_doc, \"potential_infra_match_vol1\"),\n",
    "                                (vol2_char_df, vol2_index, vol2_doc, \"potential_infra_match_vol2\"),\n",
    "                                (vol3_char_df, vol3_index, vol3_doc, \"potential_infra_match_vol3\")][::-1]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_dat_infra_match_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "\n",
    "        infra_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['infra_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        infra_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "                                & (vol_char_df['potential_infra_match'] == True)\n",
    "                                ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                ].drop_duplicates()\n",
    "\n",
    "        with_infra_symbols = vol_char_df[(vol_char_df['page_num'] == page_num) &\n",
    "                                         (vol_char_df['infra_coord_match'] == True) & \n",
    "                                         (vol_char_df['word'].apply(has_infra_symbols) == True)\n",
    "                                        ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                                        ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in infra_coord_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0-5, y0-5, x1+5, y1+5), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=7)\n",
    "\n",
    "        for coord in infra_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0-3, y0-3, x1+3, y1+3), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # #epithet is red, 3\n",
    "        for coord in with_infra_symbols['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#990000\"), width=3)\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### page num processings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1_char_df['index_page_num'] = vol1_char_df['page_num'] - vol1_index[0] + 1\n",
    "vol2_char_df['index_page_num'] = vol2_char_df['page_num'] - vol2_index[0] + 1\n",
    "vol3_char_df['index_page_num'] = vol3_char_df['page_num'] - vol3_index[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:12<00:00,  1.77it/s]\n",
      "100%|██████████| 22/22 [00:13<00:00,  1.59it/s]\n",
      "100%|██████████| 28/28 [00:14<00:00,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# all_vol_data_col_num = [(vol1_char_df, vol1_index, vol1_doc),\n",
    "#                         (vol2_char_df, vol2_index, vol2_doc),\n",
    "#                         (vol3_char_df, vol3_index, vol3_doc)]\n",
    "\n",
    "for vol_char_df ,vol_index, vol_doc in all_vol_data_col_num: \n",
    "    #for each volume check if genus pattern / epithet pattern exists within the index part of the book\n",
    "    for page_num in tqdm(vol_index):\n",
    "        center_x0 = get_center_x0(vol_char_df, page_num, - 30)\n",
    "        #find center based on x0 coordinate of each line\n",
    "        vol_char_df['col_num_for_PN'] = vol_char_df['line_bbox'].apply(lambda coords : get_col_num(coords, center_x0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_page_num(row):\n",
    "    return row['pruned_word'].isnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 16.84it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.85it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 22.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reminder:\n",
    "# all_vol_data_coord_match = [(vol1_char_df, vol1_index),\n",
    "#                             (vol2_char_df, vol2_index),\n",
    "#                             (vol3_char_df, vol3_index)]\n",
    "for vol_char_df, vol_index in all_vol_data_coord_match: \n",
    "    vol_char_df['page_num_index_pat_match'] = (vol_char_df['page_num'].isin(vol_index)) & (vol_char_df.apply(is_page_num, axis = 1))\n",
    "    vol_char_df[\"page_num_coord_match\"] = vol_char_df[\"word_bbox\"].apply(lambda x : False)\n",
    "    for page_num in tqdm(vol_index):\n",
    "        margin = 1.25 * vol_char_df[(vol_char_df[\"page_num_index_pat_match\"] == True)][\"char_bbox\"].apply(lambda x : x[2] - x[0]).mean()\n",
    "        page_num_char_df = vol_char_df[(vol_char_df[\"page_num\"] == page_num) & (vol_char_df[\"page_num_index_pat_match\"] == True)]\n",
    "        page_num_df = page_num_char_df.loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"])].drop_duplicates()\n",
    "        page_page_num_2dic = [{}, {}]\n",
    "        \n",
    "        for i in range(page_num_df.shape[0]):\n",
    "            e_index = str(page_num) + \"_\" + str(i)\n",
    "            p0 = page_num_df['word_bbox'].iloc[i]\n",
    "            x_ref = p0[2]\n",
    "            col = page_num_df['col_num_for_PN'].iloc[i]\n",
    "\n",
    "            ref_neighbors_df = page_num_df[(page_num_df[\"page_num\"] == page_num) & \n",
    "                                           (page_num_df[\"word_bbox\"].apply(lambda x : x_ref - margin <= x[2] and x[2] <= x_ref + margin))]\n",
    "            \n",
    "            num_neighbors = ref_neighbors_df.shape[0]\n",
    "            mean_neighbors = ref_neighbors_df[\"word_bbox\"].apply(lambda x : x[2]).mean()\n",
    "            page_page_num_2dic[col][e_index] = (num_neighbors, mean_neighbors)\n",
    "        \n",
    "        mean_left_page_num = max(page_page_num_2dic[0].values(), default = [-1, -1])[1]\n",
    "        mean_right_page_num = max(page_page_num_2dic[1].values(), default = [-1, -1])[1]\n",
    "\n",
    "        if mean_left_page_num == -1 or mean_right_page_num == -1:\n",
    "            mean_valid_col = max(mean_left_page_num, mean_right_page_num)\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"page_num_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match([x[2]], mean_valid_col, mean_valid_col, margin))\n",
    "        elif mean_left_page_num == -1 and mean_right_page_num == -1:\n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"page_num_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : False)\n",
    "        else: \n",
    "            vol_char_df.loc[(vol_char_df[\"page_num\"] == page_num) , \"page_num_coord_match\"] = vol_char_df[(vol_char_df[\"page_num\"] == page_num)][\"pruned_word_bbox\"].apply(lambda x : is_coord_match([x[2]], mean_left_page_num, mean_right_page_num, margin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:04<00:00,  6.29it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  6.05it/s]\n",
      "100%|██████████| 23/23 [00:03<00:00,  5.95it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_PN_test = [(vol1_char_df, vol1_index, vol1_doc, \"potential_page_num_match_vol1\"),\n",
    "                        (vol2_char_df, vol2_index, vol2_doc, \"potential_page_num_match_vol2\"),\n",
    "                        (vol3_char_df, vol3_index, vol3_doc, \"potential_page_num_match_vol3\")][::-1]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_PN_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "\n",
    "        page_num_coord_db = vol_char_df[(vol_char_df['page_num'] == page_num) & \n",
    "                                     (vol_char_df['page_num_coord_match'] == True)\n",
    "                            ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "                            ].drop_duplicates()\n",
    "\n",
    "        # infra_db = vol_char_df[(vol_char_df['page_num'] == page_num) \n",
    "        #                         & (vol_char_df['potential_infra_match'] == True)\n",
    "        #                         ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "        #                         ].drop_duplicates()\n",
    "\n",
    "        # with_infra_symbols = vol_char_df[(vol_char_df['page_num'] == page_num) &\n",
    "        #                                  (vol_char_df['infra_coord_match'] == True) & \n",
    "        #                                  (vol_char_df['word'].apply(has_infra_symbols) == True)\n",
    "        #                                 ].loc[:,~vol_char_df.columns.isin([\"char_num\", \"char\", \"char_origin\",\t\"char_bbox\"])\n",
    "        #                                 ].drop_duplicates()\n",
    "\n",
    "        #genus Coord is orange-pinkish, 5\n",
    "        for coord in page_num_coord_db['word_bbox'] :\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=3)\n",
    "\n",
    "        # for coord in infra_db['word_bbox'] :\n",
    "        #     x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "        #     draw.rectangle((x0-3, y0-3, x1+3, y1+3), fill=None, outline=ImageColor.getrgb(\"#FF7F50\"), width=5)\n",
    "            \n",
    "        # # #epithet is red, 3\n",
    "        # for coord in with_infra_symbols['word_bbox'] :\n",
    "        #     x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "        #     draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#990000\"), width=3)\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catching & hardcoding issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking potential_infra_match that are not with typical symbols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_page_num, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_infra_match'] == True) & (vol1_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_page_num, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_infra_match'] == True) & (vol2_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1559345</th>\n",
       "      <td>3</td>\n",
       "      <td>(3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559874</th>\n",
       "      <td>3</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561502</th>\n",
       "      <td>4</td>\n",
       "      <td>fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566359</th>\n",
       "      <td>6</td>\n",
       "      <td>deris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570483</th>\n",
       "      <td>8</td>\n",
       "      <td>cock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576678</th>\n",
       "      <td>11</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578491</th>\n",
       "      <td>12</td>\n",
       "      <td>picha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581443</th>\n",
       "      <td>13</td>\n",
       "      <td>adoxifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582167</th>\n",
       "      <td>14</td>\n",
       "      <td>fil.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584378</th>\n",
       "      <td>15</td>\n",
       "      <td>yar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587338</th>\n",
       "      <td>16</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589927</th>\n",
       "      <td>17</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592932</th>\n",
       "      <td>19</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594835</th>\n",
       "      <td>20</td>\n",
       "      <td>turcicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596384</th>\n",
       "      <td>20</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598587</th>\n",
       "      <td>22</td>\n",
       "      <td>berlain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num         word\n",
       "1559345               3           (3\n",
       "1559874               3           f.\n",
       "1561502               4           fa\n",
       "1566359               6       deris \n",
       "1570483               8         cock\n",
       "1576678              11           f.\n",
       "1578491              12       picha \n",
       "1581443              13  adoxifolium\n",
       "1582167              14        fil. \n",
       "1584378              15         yar.\n",
       "1587338              16           f.\n",
       "1589927              17           f.\n",
       "1592932              19           f.\n",
       "1594835              20     turcicus\n",
       "1596384              20            y\n",
       "1598587              22      berlain"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_infra_match'] == True) & (vol3_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_infra_index = [1566359, 1570483, 1578491, 1581443, 1582167, 1594835, 1598587]\n",
    "#temp_df_hard_code_infra = vol3_char_df[(vol3_char_df['potential_infra_match'] == True) & (vol3_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"pruned_word\"]].drop_duplicates()\n",
    "#temp_df_hard_code_infra[temp_df_hard_code_infra['pruned_word'].apply(lambda x : len(x) > 3)].index \n",
    "#nice ways but won't have everything in them ... so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1570487\n",
      "6 1566365\n",
      "4 1570887\n",
      "4 1570887\n",
      "6 1578497\n",
      "11 1581454\n",
      "5 1582172\n",
      "8 1594843\n",
      "7 1598594\n",
      "11 1581454\n"
     ]
    }
   ],
   "source": [
    "def get_index_end(vol_df, start_index):\n",
    "    len_word = len(vol_df.loc[start_index,'word'])\n",
    "    print(len_word, start_index + len_word)\n",
    "    return start_index + len_word - 1\n",
    "\n",
    "set_epithet_index = [1581443]\n",
    "remove_infra_index = [1570483, 1566359, 1570883, 1570883, 1578491, 1581443, 1582167, 1594835, 1598587]\n",
    "for i in remove_infra_index:\n",
    "    vol3_char_df.loc[i : get_index_end(vol3_char_df, i),'potential_infra_match'] = False\n",
    "\n",
    "for i in set_epithet_index:\n",
    "    vol3_char_df.loc[i : get_index_end(vol3_char_df, i),'potential_epithet_match'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1559345</th>\n",
       "      <td>3</td>\n",
       "      <td>(3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559874</th>\n",
       "      <td>3</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561502</th>\n",
       "      <td>4</td>\n",
       "      <td>fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576678</th>\n",
       "      <td>11</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584378</th>\n",
       "      <td>15</td>\n",
       "      <td>yar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587338</th>\n",
       "      <td>16</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589927</th>\n",
       "      <td>17</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592932</th>\n",
       "      <td>19</td>\n",
       "      <td>f.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596384</th>\n",
       "      <td>20</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num  word\n",
       "1559345               3    (3\n",
       "1559874               3    f.\n",
       "1561502               4    fa\n",
       "1576678              11    f.\n",
       "1584378              15  yar.\n",
       "1587338              16    f.\n",
       "1589927              17    f.\n",
       "1592932              19    f.\n",
       "1596384              20     y"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cock keeps needing to be pruned multiple times ....??? not sure why ugh\n",
    "vol3_char_df[(vol3_char_df['potential_infra_match'] == True) & (vol3_char_df['word'].apply(has_infra_symbols) == False)][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1596384 -> var with space in between it somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1596385\n"
     ]
    }
   ],
   "source": [
    "ending = get_index_end(vol3_char_df, 1596384)+2\n",
    "vol3_char_df.loc[1596384 : ending, 'word'] = 'var.'\n",
    "vol3_char_df.loc[1596384 : ending, 'word_num'] = 0\n",
    "vol3_char_df.loc[1596384 : ending, 'pruned_word'] = 'var'\n",
    "vol3_char_df.loc[1596384 : ending, 'potential_infra_match'] = True \n",
    "#have to run it again this is problematic now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upper case beggining / latin words in epithet coordd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_author_match_epithet_coord(word):\n",
    "    latin_connectives = r\"^\\s?et[\\s|.]?$|^\\s?in[\\s|.]?$|^\\s?non[\\s|.]?$|^\\s?&[\\s|.]?$|^\\s?er[\\s|.]?$|^\\s?nec[\\s|.]?$|^\\s?mult[\\s|.]?$|^\\s?ex[\\s|.]?$|^\\s?fil[\\s|.]?$|^\\s?f[\\s|.]?$\"\n",
    "    is_latin_connectives = re.search(latin_connectives, word) != None\n",
    "    is_hybrid = word == \"X\"\n",
    "    return is_latin_connectives or (word[0].isupper() and (not is_hybrid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKED: for vol1 all are okay and are just typos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1753028</th>\n",
       "      <td>18</td>\n",
       "      <td>Phoenicia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753527</th>\n",
       "      <td>18</td>\n",
       "      <td>Syriacus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755122</th>\n",
       "      <td>19</td>\n",
       "      <td>Jilicaulis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num        word\n",
       "1753028              18   Phoenicia\n",
       "1753527              18    Syriacus\n",
       "1755122              19  Jilicaulis"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_epithet_match'] == True) & (vol1_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKED Vol2 \n",
    "\n",
    "Hbanoticus -> typo for libanoticus \n",
    "\n",
    "Hppii -> typo for lippii\n",
    "\n",
    "letting fuzzy matching take care of it later :)\n",
    "\n",
    "**TODO**: Ma -> is supposed to be chia (not easy for fuzzy matching to fix...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1915513</th>\n",
       "      <td>4</td>\n",
       "      <td>Hbanoticus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922530</th>\n",
       "      <td>8</td>\n",
       "      <td>Hppii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937158</th>\n",
       "      <td>14</td>\n",
       "      <td>Ma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num        word\n",
       "1915513               4  Hbanoticus\n",
       "1922530               8       Hppii\n",
       "1937158              14          Ma"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_epithet_match'] == True) & (vol2_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKED vol3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1554632</th>\n",
       "      <td>1</td>\n",
       "      <td>Krascheninnikovii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565497</th>\n",
       "      <td>6</td>\n",
       "      <td>Wagenitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566524</th>\n",
       "      <td>6</td>\n",
       "      <td>Fritsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575185</th>\n",
       "      <td>10</td>\n",
       "      <td>Holub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575488</th>\n",
       "      <td>11</td>\n",
       "      <td>Holub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577207</th>\n",
       "      <td>11</td>\n",
       "      <td>et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578956</th>\n",
       "      <td>12</td>\n",
       "      <td>Eichwaldii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579044</th>\n",
       "      <td>12</td>\n",
       "      <td>Schrank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582101</th>\n",
       "      <td>14</td>\n",
       "      <td>Kuntze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583001</th>\n",
       "      <td>14</td>\n",
       "      <td>Kuntze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584639</th>\n",
       "      <td>15</td>\n",
       "      <td>Majoranamaracus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586349</th>\n",
       "      <td>16</td>\n",
       "      <td>Schiman-Czeika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586394</th>\n",
       "      <td>16</td>\n",
       "      <td>Czeika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592464</th>\n",
       "      <td>19</td>\n",
       "      <td>Berth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603606</th>\n",
       "      <td>24</td>\n",
       "      <td>DOteriifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608442</th>\n",
       "      <td>26</td>\n",
       "      <td>Turra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609136</th>\n",
       "      <td>26</td>\n",
       "      <td>Moretti,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610970</th>\n",
       "      <td>27</td>\n",
       "      <td>Fischer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611185</th>\n",
       "      <td>27</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num               word\n",
       "1554632               1  Krascheninnikovii\n",
       "1565497               6          Wagenitz \n",
       "1566524               6           Fritsch \n",
       "1575185              10              Holub\n",
       "1575488              11             Holub \n",
       "1577207              11                 et\n",
       "1578956              12         Eichwaldii\n",
       "1579044              12           Schrank \n",
       "1582101              14            Kuntze \n",
       "1583001              14             Kuntze\n",
       "1584639              15    Majoranamaracus\n",
       "1586349              16     Schiman-Czeika\n",
       "1586394              16             Czeika\n",
       "1592464              19             Berth.\n",
       "1603606              24      DOteriifolium\n",
       "1608442              26             Turra \n",
       "1609136              26           Moretti,\n",
       "1610970              27           Fischer \n",
       "1611185              27                non"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_epithet_match'] == True) & (vol3_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 1565506\n",
      "8 1566532\n",
      "5 1575190\n",
      "6 1575494\n",
      "2 1577209\n",
      "8 1579052\n",
      "7 1582108\n",
      "6 1583007\n",
      "14 1586363\n",
      "6 1586400\n",
      "6 1592470\n",
      "6 1608448\n",
      "8 1609144\n",
      "8 1610978\n",
      "3 1611188\n"
     ]
    }
   ],
   "source": [
    "# Eichwaldii, Krascheninnikovii, DOteriifolium (p should be p) -> oki \n",
    "# Majoranamaracus -> hybrid situation -> fixed later\n",
    "not_epithet_index_list = [1565497, 1566524, 1575185, 1575488, 1577207, 1579044, 1582101, 1583001, 1586349, 1586394, 1592464, 1608442, 1609136, 1610970, 1611185]\n",
    "\n",
    "for i in not_epithet_index_list:\n",
    "    vol3_char_df.loc[i : get_index_end(vol3_char_df, i),'potential_epithet_match'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1554632</th>\n",
       "      <td>1</td>\n",
       "      <td>Krascheninnikovii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578956</th>\n",
       "      <td>12</td>\n",
       "      <td>Eichwaldii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584639</th>\n",
       "      <td>15</td>\n",
       "      <td>Majoranamaracus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603606</th>\n",
       "      <td>24</td>\n",
       "      <td>DOteriifolium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num               word\n",
       "1554632               1  Krascheninnikovii\n",
       "1578956              12         Eichwaldii\n",
       "1584639              15    Majoranamaracus\n",
       "1603606              24      DOteriifolium"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_epithet_match'] == True) & (vol3_char_df['word'].apply(potential_author_match_epithet_coord))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [**TODO FIX LATER**] epithet coord word has uppper case in the middle (but not the first letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_upper_not_first(word):\n",
    "    return word[1:].lower() != word[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1716055</th>\n",
       "      <td>1</td>\n",
       "      <td>peregrina(Hack.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716156</th>\n",
       "      <td>1</td>\n",
       "      <td>umbeUulata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734633</th>\n",
       "      <td>9</td>\n",
       "      <td>elatior'L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736494</th>\n",
       "      <td>10</td>\n",
       "      <td>sessUis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737303</th>\n",
       "      <td>11</td>\n",
       "      <td>pilosaHuds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741588</th>\n",
       "      <td>13</td>\n",
       "      <td>phleoides^Vill.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747388</th>\n",
       "      <td>15</td>\n",
       "      <td>albaL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752078</th>\n",
       "      <td>18</td>\n",
       "      <td>aegUops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752829</th>\n",
       "      <td>18</td>\n",
       "      <td>glaucaVahl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761043</th>\n",
       "      <td>22</td>\n",
       "      <td>auCheriana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num              word\n",
       "1716055               1  peregrina(Hack.)\n",
       "1716156               1        umbeUulata\n",
       "1734633               9        elatior'L.\n",
       "1736494              10           sessUis\n",
       "1737303              11       pilosaHuds.\n",
       "1741588              13  phleoides^Vill.)\n",
       "1747388              15            albaL.\n",
       "1752078              18           aegUops\n",
       "1752829              18        glaucaVahl\n",
       "1761043              22        auCheriana"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_epithet_match'] == True) & (vol1_char_df['word'].apply(has_upper_not_first))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1914061</th>\n",
       "      <td>4</td>\n",
       "      <td>corîdûpUcaÈu^Sretoï.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917935</th>\n",
       "      <td>6</td>\n",
       "      <td>securidacaiÇL.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941855</th>\n",
       "      <td>17</td>\n",
       "      <td>corymbulosum(Planch.)Reichenb.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953489</th>\n",
       "      <td>22</td>\n",
       "      <td>aqUatilis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num                            word\n",
       "1914061               4            corîdûpUcaÈu^Sretoï.\n",
       "1917935               6                 securidacaiÇL.)\n",
       "1941855              17  corymbulosum(Planch.)Reichenb.\n",
       "1953489              22                       aqUatilis"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_epithet_match'] == True) & (vol2_char_df['word'].apply(has_upper_not_first))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1568523</th>\n",
       "      <td>7</td>\n",
       "      <td>gaiUardotii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579879</th>\n",
       "      <td>13</td>\n",
       "      <td>albu^L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585656</th>\n",
       "      <td>15</td>\n",
       "      <td>sieberiC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597633</th>\n",
       "      <td>21</td>\n",
       "      <td>desertiTUéh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603606</th>\n",
       "      <td>24</td>\n",
       "      <td>DOteriifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608206</th>\n",
       "      <td>26</td>\n",
       "      <td>agMmoniifolium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612787</th>\n",
       "      <td>28</td>\n",
       "      <td>'Abd-el-'asissi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num             word\n",
       "1568523               7      gaiUardotii\n",
       "1579879              13          albu^L.\n",
       "1585656              15        sieberiC.\n",
       "1597633              21     desertiTUéh.\n",
       "1603606              24    DOteriifolium\n",
       "1608206              26   agMmoniifolium\n",
       "1612787              28  'Abd-el-'asissi"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_epithet_match'] == True) & (vol3_char_df['word'].apply(has_upper_not_first))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Potential genus mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "potential genus match but name is not alphabetic or is of length < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_genus_name(word):\n",
    "    word_no_space = word.replace(\" \", \"\")\n",
    "    return ((not word_no_space.isalpha()) or (len(word_no_space) < 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1730943</th>\n",
       "      <td>8</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738656</th>\n",
       "      <td>11</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754704</th>\n",
       "      <td>19</td>\n",
       "      <td>j.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num word\n",
       "1730943               8    c\n",
       "1738656              11    f\n",
       "1754704              19   j."
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()\n",
    "#skipping over all these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1730944\n",
      "1 1738657\n",
      "2 1754706\n"
     ]
    }
   ],
   "source": [
    "not_genus_index_list_vol1 = [1730943, 1738656, 1754704]\n",
    "for i in not_genus_index_list_vol1:\n",
    "    vol1_char_df.loc[i : get_index_end(vol1_char_df, i),'potential_genus_match'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_page_num, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1_char_df[(vol1_char_df['potential_genus_match'] == True) & (vol1_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921256</th>\n",
       "      <td>7</td>\n",
       "      <td>•Ceratophyllum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921779</th>\n",
       "      <td>7</td>\n",
       "      <td>Chelidonium^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939484</th>\n",
       "      <td>16</td>\n",
       "      <td>Jussiaea-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939606</th>\n",
       "      <td>16</td>\n",
       "      <td>VV.1l.*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num            word\n",
       "1921256               7  •Ceratophyllum\n",
       "1921779               7    Chelidonium^\n",
       "1939484              16       Jussiaea-\n",
       "1939606              16         VV.1l.*"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_genus_match'] == True) & (vol2_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1939613\n"
     ]
    }
   ],
   "source": [
    "not_genus_index_list_vol2 = [1939606]\n",
    "for i in not_genus_index_list_vol2:\n",
    "    vol2_char_df.loc[i : get_index_end(vol2_char_df, i),'potential_genus_match'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921256</th>\n",
       "      <td>7</td>\n",
       "      <td>•Ceratophyllum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921779</th>\n",
       "      <td>7</td>\n",
       "      <td>Chelidonium^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939484</th>\n",
       "      <td>16</td>\n",
       "      <td>Jussiaea-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num            word\n",
       "1921256               7  •Ceratophyllum\n",
       "1921779               7    Chelidonium^\n",
       "1939484              16       Jussiaea-"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol2_char_df[(vol2_char_df['potential_genus_match'] == True) & (vol2_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_page_num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1559728</th>\n",
       "      <td>3</td>\n",
       "      <td>BallotaL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569974</th>\n",
       "      <td>8</td>\n",
       "      <td>CordiaL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584638</th>\n",
       "      <td>15</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601635</th>\n",
       "      <td>23</td>\n",
       "      <td>SolidagoL.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index_page_num        word\n",
       "1559728               3  BallotaL. \n",
       "1569974               8   CordiaL. \n",
       "1584638              15           x\n",
       "1601635              23  SolidagoL."
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_char_df[(vol3_char_df['potential_genus_match'] == True) & (vol3_char_df['word'].apply(flag_genus_name))][[\"index_page_num\", \"word\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pruning char_df and getting index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['potential_genus_match', 'potential_epithet_match', 'potential_infra_match']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in vol1_char_df.columns if c.startswith('potential')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making sure page_num is in index\n",
    "#making sure the genus level word is not all uppercase (a family name)\n",
    "#making sure the pruned_word is not numeric (removing page_number as it's not in order usually) and removing page_num_coord_match\n",
    "\n",
    "all_vol_data = [(vol1_char_df, vol1_index),\n",
    "                (vol2_char_df, vol2_index),\n",
    "                (vol3_char_df, vol3_index)]\n",
    "\n",
    "result = [] \n",
    "ignore_word_list = [\"NOUVELLE\", \"Flore\", \"FLORE\", \"INDEX\", \"\"]\n",
    "for vol_char_df, vol_index in all_vol_data:\n",
    "    curr_result_df = vol_char_df[(vol_char_df['page_num'].isin(vol_index)) &\n",
    "                                (~((vol_char_df[\"word\"].str.isupper()) & (vol_char_df[\"word\"].apply(lambda x : len(x) > 2)) & (vol_char_df['genus_coord_match'] == True))) & \n",
    "                                (~(vol_char_df[\"pruned_word\"].isin(ignore_word_list))) &\n",
    "                                (~(vol_char_df[\"pruned_word\"].str.isnumeric() & (vol_char_df[\"word\"] != \"(3\"))) & \n",
    "                                (~(vol_char_df[\"page_num_coord_match\"] == True))\n",
    "                                ].copy()\n",
    "    result.append(curr_result_df)\n",
    "\n",
    "vol1_index_df, vol2_index_df, vol3_index_df = result[0], result[1], result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.06it/s]\n",
      "100%|██████████| 22/22 [00:03<00:00,  6.29it/s]\n",
      "100%|██████████| 28/28 [00:04<00:00,  6.40it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_PN_test = [(vol1_index_df, vol1_index, vol1_doc, \"valid_words_vol1\"),\n",
    "                        (vol2_index_df, vol2_index, vol2_doc, \"valid_words_vol2\"),\n",
    "                        (vol3_index_df, vol3_index, vol3_doc, \"valid_words_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_PN_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        temp_coords = vol_char_df[vol_char_df['page_num'] == page_num]['word_bbox'].drop_duplicates()\n",
    "        for coord in temp_coords:\n",
    "            x0, y0, x1, y1 = [f*TARGET_DPI/ 72 for f in coord]\n",
    "            draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=3)\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keeping word level\n",
    "vol_index_df_list = [vol1_index_df, vol2_index_df, vol3_index_df]\n",
    "result_df = []\n",
    "for vol_index_df in vol_index_df_list:\n",
    "    keep_cols = vol_index_df.columns.difference([\"char_num\", \"char\", \"char_origin\", \"char_bbox\"], sort=False).tolist()\n",
    "\n",
    "    vol_index_df = vol_index_df.copy().loc[:,keep_cols].drop_duplicates().reset_index()\n",
    "    vol_index_df.rename(columns={\"index\": \"char_index\"}, inplace = True)\n",
    "    result_df.append(vol_index_df)\n",
    "\n",
    "vol1_index_df, vol2_index_df, vol3_index_df = result_df[0], result_df[1], result_df[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_hybrid_symbols(word):\n",
    "    infra_symbols = r\"^X[\\s|.|\\b]?$|^x[\\s|.|\\b]?$|^×[\\s|.|\\b]?$\"\n",
    "    return re.search(infra_symbols, word) != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_hybrids = []\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['is_hybrid'] = np.NaN\n",
    "    vol_index_df.loc[(vol_index_df['potential_infra_match'] == True) | (vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True), 'is_hybrid'] = (vol_index_df['word'].apply(has_hybrid_symbols) == True) & ((vol_index_df['potential_infra_match'] == True) | (vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True))\n",
    "    \n",
    "    hybrid_genera_indecies = vol_index_df[(vol_index_df['potential_genus_match'] == True) & (vol_index_df['word'].apply(has_hybrid_symbols) == True)].index + 1\n",
    "    hybrid_epithet_indecies = vol_index_df[(vol_index_df['potential_epithet_match'] == True) & (vol_index_df['word'].apply(has_hybrid_symbols) == True)].index + 1\n",
    "    \n",
    "    vol_index_df.loc[hybrid_epithet_indecies, 'is_hybrid'] = True\n",
    "    vol_index_df.loc[hybrid_epithet_indecies, 'potential_epithet_match'] = True \n",
    "\n",
    "    vol_index_df.loc[hybrid_genera_indecies, 'is_hybrid'] = True\n",
    "    vol_index_df.loc[hybrid_genera_indecies, 'potential_genus_match'] = True\n",
    "\n",
    "    drop_list = list(hybrid_epithet_indecies - 1) + list(hybrid_genera_indecies -1)\n",
    "    \n",
    "    vol_index_df = vol_index_df[~vol_index_df.index.isin(drop_list)].copy()\n",
    "    vol_index_df['is_hybrid'].ffill(inplace=True)\n",
    "\n",
    "    result_df_hybrids.append(vol_index_df)\n",
    "\n",
    "vol1_index_df, vol2_index_df, vol3_index_df = result_df_hybrids[0], result_df_hybrids[1], result_df_hybrids[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['closest_epithet_v2'] = np.nan\n",
    "def extract_potential_genus_names(row):\n",
    "    if row['potential_genus_match'] == True:\n",
    "        return row['word'] + \"_\" + str(row['page_num']) + \"_\" + str(row['block_num']) + \"_\" + str(row['line_num'])\n",
    "    else:\n",
    "        return np.nan\n",
    "        \n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['closest_genus'] = vol_index_df.apply(extract_potential_genus_names, axis = 1)\n",
    "    vol_index_df['closest_genus'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['closest_epithet_v2'] = np.nan\n",
    "def extract_potential_epithet_names(row):\n",
    "    if row['potential_epithet_match'] == True:\n",
    "        return row['word'] + \"_\" + str(row['page_num']) + \"_\" + str(row['block_num']) + \"_\" + str(row['line_num'])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['closest_epithet'] = vol_index_df.apply(extract_potential_epithet_names, axis = 1)\n",
    "    vol_index_df.loc[vol_index_df['potential_genus_match'] == True, 'closest_epithet'] = -1\n",
    "    vol_index_df['closest_epithet'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_potential_infra_type(row):\n",
    "    if row['potential_infra_match'] == True:\n",
    "        return row['word'] + \"_\" + str(row['page_num']) + \"_\" + str(row['block_num']) + \"_\" + str(row['line_num'])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df.loc[(vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True), 'closest_infra_type'] = -1\n",
    "    vol_index_df['closest_infra_type'] = vol_index_df.apply(extract_potential_infra_type, axis = 1)\n",
    "    vol_index_df.loc[(vol_index_df['potential_infra_match'] == False) & ((vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True)), 'closest_infra_type'] = -1\n",
    "    vol_index_df['closest_infra_type'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    infra_name_match_indecies = vol_index_df[vol_index_df['potential_infra_match'] == True].index + 1\n",
    "    vol_index_df['closest_infra_name'] = np.NaN\n",
    "    vol_index_df.loc[infra_name_match_indecies, 'closest_infra_name'] = vol_index_df.apply(lambda row : row['word'] + \"_\" + str(row['page_num']) + \"_\" + str(row['block_num']) + \"_\" + str(row['line_num']) , axis = 1)\n",
    "    vol_index_df['potential_infra_name_match'] = vol_index_df.index.isin(infra_name_match_indecies)\n",
    "    vol_index_df.loc[(vol_index_df['potential_infra_match'] == True) | (vol_index_df['potential_epithet_match'] == True) | (vol_index_df['potential_genus_match'] == True), 'closest_infra_name'] = -1\n",
    "    vol_index_df['closest_infra_name'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['potential_author_match'] = (vol_index_df['potential_genus_match'] == False) & \\\n",
    "                                             (vol_index_df['potential_epithet_match'] == False) & \\\n",
    "                                             (vol_index_df['potential_infra_match'] == False) & \\\n",
    "                                             (vol_index_df['potential_infra_name_match'] == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_bbox</th>\n",
       "      <th>pruned_word</th>\n",
       "      <th>pruned_word_bbox</th>\n",
       "      <th>genus_index_pat_match</th>\n",
       "      <th>epithet_index_pat_match</th>\n",
       "      <th>col_num</th>\n",
       "      <th>epithet_coord_match</th>\n",
       "      <th>genus_coord_match</th>\n",
       "      <th>potential_genus_match</th>\n",
       "      <th>...</th>\n",
       "      <th>col_num_for_PN</th>\n",
       "      <th>page_num_index_pat_match</th>\n",
       "      <th>page_num_coord_match</th>\n",
       "      <th>is_hybrid</th>\n",
       "      <th>closest_genus</th>\n",
       "      <th>closest_epithet</th>\n",
       "      <th>closest_infra_type</th>\n",
       "      <th>closest_infra_name</th>\n",
       "      <th>potential_infra_name_match</th>\n",
       "      <th>potential_author_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>micrantha</td>\n",
       "      <td>(26.639999389648438, 548.4010009765625, 63.269...</td>\n",
       "      <td>micrantha</td>\n",
       "      <td>(26.639999389648438, 548.4010009765625, 63.269...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>micrantha_555_25_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Willd.</td>\n",
       "      <td>(65.68165588378906, 547.4830322265625, 89.5377...</td>\n",
       "      <td>Willd</td>\n",
       "      <td>(65.68165588378906, 547.4830322265625, 87.0438...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>micrantha_555_25_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>non</td>\n",
       "      <td>(113.14447021484375, 547.4830322265625, 127.13...</td>\n",
       "      <td>non</td>\n",
       "      <td>(113.14447021484375, 547.4830322265625, 127.13...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>micrantha_555_25_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Willd.</td>\n",
       "      <td>(129.73193359375, 547.4830322265625, 153.38996...</td>\n",
       "      <td>Willd</td>\n",
       "      <td>(129.73193359375, 547.4830322265625, 150.93576...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>micrantha_555_25_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>odorata</td>\n",
       "      <td>(26.639999389648438, 558.0009765625, 54.857971...</td>\n",
       "      <td>odorata</td>\n",
       "      <td>(26.639999389648438, 558.0009765625, 54.857971...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>odorata_555_25_1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>W.</td>\n",
       "      <td>(58.12398147583008, 557.0830078125, 69.0228958...</td>\n",
       "      <td>W</td>\n",
       "      <td>(58.12398147583008, 557.0830078125, 66.5350189...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>odorata_555_25_1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Koch</td>\n",
       "      <td>(72.80469512939453, 557.0830078125, 93.1729583...</td>\n",
       "      <td>Koch</td>\n",
       "      <td>(72.80469512939453, 557.0830078125, 93.1729583...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>odorata_555_25_1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>subsp.</td>\n",
       "      <td>(35.7599983215332, 566.6829833984375, 59.72493...</td>\n",
       "      <td>subsp</td>\n",
       "      <td>(35.7599983215332, 566.6829833984375, 57.20934...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>odorata_555_25_1</td>\n",
       "      <td>subsp._555_26_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>kotschyi</td>\n",
       "      <td>(62.08212661743164, 567.6009521484375, 91.2802...</td>\n",
       "      <td>kotschyi</td>\n",
       "      <td>(62.08212661743164, 567.6009521484375, 91.2802...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>odorata_555_25_1</td>\n",
       "      <td>subsp._555_26_0</td>\n",
       "      <td>kotschyi_555_26_0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>(Boiss.)</td>\n",
       "      <td>(93.81856536865234, 566.6829833984375, 120.712...</td>\n",
       "      <td>Boiss</td>\n",
       "      <td>(96.63214874267578, 566.6829833984375, 115.825...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>odorata_555_25_1</td>\n",
       "      <td>subsp._555_26_0</td>\n",
       "      <td>kotschyi_555_26_0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Bornm.</td>\n",
       "      <td>(123.61263275146484, 566.6829833984375, 152.07...</td>\n",
       "      <td>Bornm</td>\n",
       "      <td>(123.61263275146484, 566.6829833984375, 149.57...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>odorata_555_25_1</td>\n",
       "      <td>subsp._555_26_0</td>\n",
       "      <td>kotschyi_555_26_0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>var.</td>\n",
       "      <td>(36.0, 576.2830200195312, 50.695560455322266, ...</td>\n",
       "      <td>var</td>\n",
       "      <td>(36.0, 576.2830200195312, 48.10472869873047, 5...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>odorata_555_25_1</td>\n",
       "      <td>var._555_27_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>grata</td>\n",
       "      <td>(53.26164245605469, 577.2009887695312, 72.5696...</td>\n",
       "      <td>grata</td>\n",
       "      <td>(53.26164245605469, 577.2009887695312, 72.5696...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>odorata_555_25_1</td>\n",
       "      <td>var._555_27_0</td>\n",
       "      <td>grata_555_27_0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Fenzl</td>\n",
       "      <td>(75.3336181640625, 576.2830200195312, 96.17961...</td>\n",
       "      <td>Fenzl</td>\n",
       "      <td>(75.3336181640625, 576.2830200195312, 96.17961...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>odorata_555_25_1</td>\n",
       "      <td>var._555_27_0</td>\n",
       "      <td>grata_555_27_0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>oligocephala</td>\n",
       "      <td>(26.8799991607666, 585.8829956054688, 74.90390...</td>\n",
       "      <td>oligocephala</td>\n",
       "      <td>(26.8799991607666, 585.8829956054688, 74.90390...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>oligocephala_555_28_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>DC.</td>\n",
       "      <td>(78.94608306884766, 585.8829956054688, 94.4722...</td>\n",
       "      <td>DC</td>\n",
       "      <td>(78.94608306884766, 585.8829956054688, 91.7834...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>oligocephala_555_28_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>A</td>\n",
       "      <td>(184.0800018310547, 170.50289916992188, 187.37...</td>\n",
       "      <td>A</td>\n",
       "      <td>(184.0800018310547, 170.50289916992188, 187.37...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>oligocephala_555_28_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>santohna</td>\n",
       "      <td>(229.1999969482422, 146.40098571777344, 262.20...</td>\n",
       "      <td>santohna</td>\n",
       "      <td>(229.1999969482422, 146.40098571777344, 262.20...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>santohna_555_37_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>auct.</td>\n",
       "      <td>(264.9126281738281, 145.4829864501953, 283.453...</td>\n",
       "      <td>auct</td>\n",
       "      <td>(264.9126281738281, 145.4829864501953, 280.858...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>santohna_555_37_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>mult,</td>\n",
       "      <td>(286.5807800292969, 145.4829864501953, 306.630...</td>\n",
       "      <td>mult</td>\n",
       "      <td>(286.5807800292969, 145.4829864501953, 304.059...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>santohna_555_37_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>non</td>\n",
       "      <td>(309.7579650878906, 145.4829864501953, 323.588...</td>\n",
       "      <td>non</td>\n",
       "      <td>(309.7579650878906, 145.4829864501953, 323.588...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>santohna_555_37_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>L.</td>\n",
       "      <td>(326.2978820800781, 145.4829864501953, 334.233...</td>\n",
       "      <td>L</td>\n",
       "      <td>(326.2978820800781, 145.4829864501953, 331.741...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>santohna_555_37_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>sulphurea</td>\n",
       "      <td>(229.44000244140625, 154.5609893798828, 265.15...</td>\n",
       "      <td>sulphurea</td>\n",
       "      <td>(229.44000244140625, 154.5609893798828, 265.15...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>sulphurea_555_37_1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Boiss.</td>\n",
       "      <td>(266.65679931640625, 153.6429901123047, 288.20...</td>\n",
       "      <td>Boiss</td>\n",
       "      <td>(266.65679931640625, 153.6429901123047, 286.07...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>sulphurea_555_37_1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>teretifolia</td>\n",
       "      <td>(229.1999969482422, 164.64100646972656, 264.34...</td>\n",
       "      <td>teretifolia</td>\n",
       "      <td>(229.1999969482422, 164.64100646972656, 264.34...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>teretifolia_555_37_2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Ledeb.</td>\n",
       "      <td>(266.8674621582031, 163.72300720214844, 292.96...</td>\n",
       "      <td>Ledeb</td>\n",
       "      <td>(266.8674621582031, 163.72300720214844, 290.41...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>teretifolia_555_37_2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>non</td>\n",
       "      <td>(295.8695068359375, 163.72300720214844, 309.69...</td>\n",
       "      <td>non</td>\n",
       "      <td>(295.8695068359375, 163.72300720214844, 309.69...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>teretifolia_555_37_2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Willd.</td>\n",
       "      <td>(312.410400390625, 163.72300720214844, 335.672...</td>\n",
       "      <td>Willd</td>\n",
       "      <td>(312.410400390625, 163.72300720214844, 333.297...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>teretifolia_555_37_2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>urumoffii</td>\n",
       "      <td>(229.67999267578125, 174.00099182128906, 262.9...</td>\n",
       "      <td>urumoffii</td>\n",
       "      <td>(229.67999267578125, 174.00099182128906, 262.9...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>urumoffii_555_38_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Hal.</td>\n",
       "      <td>(264.4543151855469, 173.08299255371094, 280.86...</td>\n",
       "      <td>Hal</td>\n",
       "      <td>(264.4543151855469, 173.08299255371094, 278.20...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>urumoffii_555_38_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>wilhelmsii</td>\n",
       "      <td>(229.44000244140625, 182.92298889160156, 267.7...</td>\n",
       "      <td>wilhelmsii</td>\n",
       "      <td>(229.44000244140625, 182.92298889160156, 267.7...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>wilhelmsii_555_39_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>C.</td>\n",
       "      <td>(271.31927490234375, 182.92298889160156, 279.6...</td>\n",
       "      <td>C</td>\n",
       "      <td>(271.31927490234375, 182.92298889160156, 277.2...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>wilhelmsii_555_39_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Koch</td>\n",
       "      <td>(283.4022216796875, 182.92298889160156, 303.41...</td>\n",
       "      <td>Koch</td>\n",
       "      <td>(283.4022216796875, 182.92298889160156, 303.41...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Achillea_555_17_0</td>\n",
       "      <td>wilhelmsii_555_39_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Acinos</td>\n",
       "      <td>(220.32000732421875, 195.3610076904297, 244.57...</td>\n",
       "      <td>Acinos</td>\n",
       "      <td>(220.32000732421875, 195.3610076904297, 244.57...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Acinos_555_40_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Miller</td>\n",
       "      <td>(247.83506774902344, 194.44300842285156, 270.9...</td>\n",
       "      <td>Miller</td>\n",
       "      <td>(247.83506774902344, 194.44300842285156, 270.9...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Acinos_555_40_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>rotundifolius</td>\n",
       "      <td>(229.1999969482422, 205.2010040283203, 275.246...</td>\n",
       "      <td>rotundifolius</td>\n",
       "      <td>(229.1999969482422, 205.2010040283203, 275.246...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Acinos_555_40_0</td>\n",
       "      <td>rotundifolius_555_41_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Pers.</td>\n",
       "      <td>(277.3585510253906, 204.2830047607422, 295.930...</td>\n",
       "      <td>Pers</td>\n",
       "      <td>(277.3585510253906, 204.2830047607422, 293.453...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Acinos_555_40_0</td>\n",
       "      <td>rotundifolius_555_41_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>non</td>\n",
       "      <td>(298.61883544921875, 204.2830047607422, 312.76...</td>\n",
       "      <td>non</td>\n",
       "      <td>(298.61883544921875, 204.2830047607422, 312.76...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Acinos_555_40_0</td>\n",
       "      <td>rotundifolius_555_41_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Friv.</td>\n",
       "      <td>(315.2616882324219, 204.2830047607422, 333.336...</td>\n",
       "      <td>Friv</td>\n",
       "      <td>(315.2616882324219, 204.2830047607422, 330.860...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Acinos_555_40_0</td>\n",
       "      <td>rotundifolius_555_41_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>nee</td>\n",
       "      <td>(336.0241394042969, 204.2830047607422, 349.002...</td>\n",
       "      <td>nee</td>\n",
       "      <td>(336.0241394042969, 204.2830047607422, 349.002...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Acinos_555_40_0</td>\n",
       "      <td>rotundifolius_555_41_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Host</td>\n",
       "      <td>(351.305908203125, 204.2830047607422, 368.8645...</td>\n",
       "      <td>Host</td>\n",
       "      <td>(351.305908203125, 204.2830047607422, 368.8645...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Acinos_555_40_0</td>\n",
       "      <td>rotundifolius_555_41_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Aetheorhiza</td>\n",
       "      <td>(220.55999755859375, 215.80299377441406, 266.2...</td>\n",
       "      <td>Aetheorhiza</td>\n",
       "      <td>(220.55999755859375, 215.80299377441406, 266.2...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Aetheorhiza_555_42_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Cass.</td>\n",
       "      <td>(270.40948486328125, 215.80299377441406, 289.8...</td>\n",
       "      <td>Cass</td>\n",
       "      <td>(270.40948486328125, 215.80299377441406, 287.5...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Aetheorhiza_555_42_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>bulbosa</td>\n",
       "      <td>(229.9199981689453, 225.4029998779297, 258.743...</td>\n",
       "      <td>bulbosa</td>\n",
       "      <td>(229.9199981689453, 225.4029998779297, 258.743...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Aetheorhiza_555_42_0</td>\n",
       "      <td>bulbosa_555_43_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>(L.)</td>\n",
       "      <td>(262.6929931640625, 225.4029998779297, 276.527...</td>\n",
       "      <td>L</td>\n",
       "      <td>(265.73626708984375, 225.4029998779297, 271.18...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Aetheorhiza_555_42_0</td>\n",
       "      <td>bulbosa_555_43_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Cass.</td>\n",
       "      <td>(280.97039794921875, 225.4029998779297, 300.39...</td>\n",
       "      <td>Cass</td>\n",
       "      <td>(280.97039794921875, 225.4029998779297, 298.07...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Aetheorhiza_555_42_0</td>\n",
       "      <td>bulbosa_555_43_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Ajuga</td>\n",
       "      <td>(220.8000030517578, 236.92298889160156, 242.75...</td>\n",
       "      <td>Ajuga</td>\n",
       "      <td>(220.8000030517578, 236.92298889160156, 242.75...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Ajuga_555_44_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>L.</td>\n",
       "      <td>(247.1943817138672, 236.92298889160156, 255.03...</td>\n",
       "      <td>L</td>\n",
       "      <td>(247.1943817138672, 236.92298889160156, 252.63...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Ajuga_555_44_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>chamaepitys</td>\n",
       "      <td>(229.67999267578125, 247.6809844970703, 274.67...</td>\n",
       "      <td>chamaepitys</td>\n",
       "      <td>(229.67999267578125, 247.6809844970703, 274.67...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Ajuga_555_44_0</td>\n",
       "      <td>chamaepitys_555_45_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>(L.)</td>\n",
       "      <td>(276.17584228515625, 246.7629852294922, 290.01...</td>\n",
       "      <td>L</td>\n",
       "      <td>(279.2191162109375, 246.7629852294922, 284.663...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Ajuga_555_44_0</td>\n",
       "      <td>chamaepitys_555_45_0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word                                          word_bbox  \\\n",
       "100      micrantha  (26.639999389648438, 548.4010009765625, 63.269...   \n",
       "101         Willd.  (65.68165588378906, 547.4830322265625, 89.5377...   \n",
       "102            non  (113.14447021484375, 547.4830322265625, 127.13...   \n",
       "103         Willd.  (129.73193359375, 547.4830322265625, 153.38996...   \n",
       "104        odorata  (26.639999389648438, 558.0009765625, 54.857971...   \n",
       "105             W.  (58.12398147583008, 557.0830078125, 69.0228958...   \n",
       "106           Koch  (72.80469512939453, 557.0830078125, 93.1729583...   \n",
       "107         subsp.  (35.7599983215332, 566.6829833984375, 59.72493...   \n",
       "108       kotschyi  (62.08212661743164, 567.6009521484375, 91.2802...   \n",
       "109       (Boiss.)  (93.81856536865234, 566.6829833984375, 120.712...   \n",
       "110         Bornm.  (123.61263275146484, 566.6829833984375, 152.07...   \n",
       "111           var.  (36.0, 576.2830200195312, 50.695560455322266, ...   \n",
       "112          grata  (53.26164245605469, 577.2009887695312, 72.5696...   \n",
       "113          Fenzl  (75.3336181640625, 576.2830200195312, 96.17961...   \n",
       "114   oligocephala  (26.8799991607666, 585.8829956054688, 74.90390...   \n",
       "115            DC.  (78.94608306884766, 585.8829956054688, 94.4722...   \n",
       "116              A  (184.0800018310547, 170.50289916992188, 187.37...   \n",
       "117       santohna  (229.1999969482422, 146.40098571777344, 262.20...   \n",
       "118          auct.  (264.9126281738281, 145.4829864501953, 283.453...   \n",
       "119          mult,  (286.5807800292969, 145.4829864501953, 306.630...   \n",
       "120            non  (309.7579650878906, 145.4829864501953, 323.588...   \n",
       "121             L.  (326.2978820800781, 145.4829864501953, 334.233...   \n",
       "122      sulphurea  (229.44000244140625, 154.5609893798828, 265.15...   \n",
       "123         Boiss.  (266.65679931640625, 153.6429901123047, 288.20...   \n",
       "124    teretifolia  (229.1999969482422, 164.64100646972656, 264.34...   \n",
       "125         Ledeb.  (266.8674621582031, 163.72300720214844, 292.96...   \n",
       "126            non  (295.8695068359375, 163.72300720214844, 309.69...   \n",
       "127         Willd.  (312.410400390625, 163.72300720214844, 335.672...   \n",
       "128      urumoffii  (229.67999267578125, 174.00099182128906, 262.9...   \n",
       "129           Hal.  (264.4543151855469, 173.08299255371094, 280.86...   \n",
       "130     wilhelmsii  (229.44000244140625, 182.92298889160156, 267.7...   \n",
       "131             C.  (271.31927490234375, 182.92298889160156, 279.6...   \n",
       "132           Koch  (283.4022216796875, 182.92298889160156, 303.41...   \n",
       "133         Acinos  (220.32000732421875, 195.3610076904297, 244.57...   \n",
       "134         Miller  (247.83506774902344, 194.44300842285156, 270.9...   \n",
       "135  rotundifolius  (229.1999969482422, 205.2010040283203, 275.246...   \n",
       "136          Pers.  (277.3585510253906, 204.2830047607422, 295.930...   \n",
       "137            non  (298.61883544921875, 204.2830047607422, 312.76...   \n",
       "138          Friv.  (315.2616882324219, 204.2830047607422, 333.336...   \n",
       "139            nee  (336.0241394042969, 204.2830047607422, 349.002...   \n",
       "140           Host  (351.305908203125, 204.2830047607422, 368.8645...   \n",
       "141    Aetheorhiza  (220.55999755859375, 215.80299377441406, 266.2...   \n",
       "142          Cass.  (270.40948486328125, 215.80299377441406, 289.8...   \n",
       "143        bulbosa  (229.9199981689453, 225.4029998779297, 258.743...   \n",
       "144           (L.)  (262.6929931640625, 225.4029998779297, 276.527...   \n",
       "145          Cass.  (280.97039794921875, 225.4029998779297, 300.39...   \n",
       "146          Ajuga  (220.8000030517578, 236.92298889160156, 242.75...   \n",
       "147             L.  (247.1943817138672, 236.92298889160156, 255.03...   \n",
       "148    chamaepitys  (229.67999267578125, 247.6809844970703, 274.67...   \n",
       "149           (L.)  (276.17584228515625, 246.7629852294922, 290.01...   \n",
       "\n",
       "       pruned_word                                   pruned_word_bbox  \\\n",
       "100      micrantha  (26.639999389648438, 548.4010009765625, 63.269...   \n",
       "101          Willd  (65.68165588378906, 547.4830322265625, 87.0438...   \n",
       "102            non  (113.14447021484375, 547.4830322265625, 127.13...   \n",
       "103          Willd  (129.73193359375, 547.4830322265625, 150.93576...   \n",
       "104        odorata  (26.639999389648438, 558.0009765625, 54.857971...   \n",
       "105              W  (58.12398147583008, 557.0830078125, 66.5350189...   \n",
       "106           Koch  (72.80469512939453, 557.0830078125, 93.1729583...   \n",
       "107          subsp  (35.7599983215332, 566.6829833984375, 57.20934...   \n",
       "108       kotschyi  (62.08212661743164, 567.6009521484375, 91.2802...   \n",
       "109          Boiss  (96.63214874267578, 566.6829833984375, 115.825...   \n",
       "110          Bornm  (123.61263275146484, 566.6829833984375, 149.57...   \n",
       "111            var  (36.0, 576.2830200195312, 48.10472869873047, 5...   \n",
       "112          grata  (53.26164245605469, 577.2009887695312, 72.5696...   \n",
       "113          Fenzl  (75.3336181640625, 576.2830200195312, 96.17961...   \n",
       "114   oligocephala  (26.8799991607666, 585.8829956054688, 74.90390...   \n",
       "115             DC  (78.94608306884766, 585.8829956054688, 91.7834...   \n",
       "116              A  (184.0800018310547, 170.50289916992188, 187.37...   \n",
       "117       santohna  (229.1999969482422, 146.40098571777344, 262.20...   \n",
       "118           auct  (264.9126281738281, 145.4829864501953, 280.858...   \n",
       "119           mult  (286.5807800292969, 145.4829864501953, 304.059...   \n",
       "120            non  (309.7579650878906, 145.4829864501953, 323.588...   \n",
       "121              L  (326.2978820800781, 145.4829864501953, 331.741...   \n",
       "122      sulphurea  (229.44000244140625, 154.5609893798828, 265.15...   \n",
       "123          Boiss  (266.65679931640625, 153.6429901123047, 286.07...   \n",
       "124    teretifolia  (229.1999969482422, 164.64100646972656, 264.34...   \n",
       "125          Ledeb  (266.8674621582031, 163.72300720214844, 290.41...   \n",
       "126            non  (295.8695068359375, 163.72300720214844, 309.69...   \n",
       "127          Willd  (312.410400390625, 163.72300720214844, 333.297...   \n",
       "128      urumoffii  (229.67999267578125, 174.00099182128906, 262.9...   \n",
       "129            Hal  (264.4543151855469, 173.08299255371094, 278.20...   \n",
       "130     wilhelmsii  (229.44000244140625, 182.92298889160156, 267.7...   \n",
       "131              C  (271.31927490234375, 182.92298889160156, 277.2...   \n",
       "132           Koch  (283.4022216796875, 182.92298889160156, 303.41...   \n",
       "133         Acinos  (220.32000732421875, 195.3610076904297, 244.57...   \n",
       "134         Miller  (247.83506774902344, 194.44300842285156, 270.9...   \n",
       "135  rotundifolius  (229.1999969482422, 205.2010040283203, 275.246...   \n",
       "136           Pers  (277.3585510253906, 204.2830047607422, 293.453...   \n",
       "137            non  (298.61883544921875, 204.2830047607422, 312.76...   \n",
       "138           Friv  (315.2616882324219, 204.2830047607422, 330.860...   \n",
       "139            nee  (336.0241394042969, 204.2830047607422, 349.002...   \n",
       "140           Host  (351.305908203125, 204.2830047607422, 368.8645...   \n",
       "141    Aetheorhiza  (220.55999755859375, 215.80299377441406, 266.2...   \n",
       "142           Cass  (270.40948486328125, 215.80299377441406, 287.5...   \n",
       "143        bulbosa  (229.9199981689453, 225.4029998779297, 258.743...   \n",
       "144              L  (265.73626708984375, 225.4029998779297, 271.18...   \n",
       "145           Cass  (280.97039794921875, 225.4029998779297, 298.07...   \n",
       "146          Ajuga  (220.8000030517578, 236.92298889160156, 242.75...   \n",
       "147              L  (247.1943817138672, 236.92298889160156, 252.63...   \n",
       "148    chamaepitys  (229.67999267578125, 247.6809844970703, 274.67...   \n",
       "149              L  (279.2191162109375, 246.7629852294922, 284.663...   \n",
       "\n",
       "     genus_index_pat_match  epithet_index_pat_match  col_num  \\\n",
       "100                  False                     True        0   \n",
       "101                  False                    False        0   \n",
       "102                  False                    False        0   \n",
       "103                  False                    False        0   \n",
       "104                  False                     True        0   \n",
       "105                  False                    False        0   \n",
       "106                  False                    False        0   \n",
       "107                  False                    False        0   \n",
       "108                  False                    False        0   \n",
       "109                  False                    False        0   \n",
       "110                  False                    False        0   \n",
       "111                  False                    False        0   \n",
       "112                  False                    False        0   \n",
       "113                  False                    False        0   \n",
       "114                  False                     True        0   \n",
       "115                  False                    False        0   \n",
       "116                  False                    False        0   \n",
       "117                  False                     True        1   \n",
       "118                  False                    False        1   \n",
       "119                  False                    False        1   \n",
       "120                  False                    False        1   \n",
       "121                  False                    False        1   \n",
       "122                  False                     True        1   \n",
       "123                  False                    False        1   \n",
       "124                  False                     True        1   \n",
       "125                  False                    False        1   \n",
       "126                  False                    False        1   \n",
       "127                  False                    False        1   \n",
       "128                  False                     True        1   \n",
       "129                  False                    False        1   \n",
       "130                  False                     True        1   \n",
       "131                  False                    False        1   \n",
       "132                  False                    False        1   \n",
       "133                   True                    False        1   \n",
       "134                  False                    False        1   \n",
       "135                  False                     True        1   \n",
       "136                  False                    False        1   \n",
       "137                  False                    False        1   \n",
       "138                  False                    False        1   \n",
       "139                  False                    False        1   \n",
       "140                  False                    False        1   \n",
       "141                   True                    False        1   \n",
       "142                  False                    False        1   \n",
       "143                  False                     True        1   \n",
       "144                  False                    False        1   \n",
       "145                  False                    False        1   \n",
       "146                   True                    False        1   \n",
       "147                  False                    False        1   \n",
       "148                  False                     True        1   \n",
       "149                  False                    False        1   \n",
       "\n",
       "     epithet_coord_match  genus_coord_match  potential_genus_match  ...  \\\n",
       "100                 True              False                  False  ...   \n",
       "101                False              False                  False  ...   \n",
       "102                False              False                  False  ...   \n",
       "103                False              False                  False  ...   \n",
       "104                 True              False                  False  ...   \n",
       "105                False              False                  False  ...   \n",
       "106                False              False                  False  ...   \n",
       "107                False              False                  False  ...   \n",
       "108                False              False                  False  ...   \n",
       "109                False              False                  False  ...   \n",
       "110                False              False                  False  ...   \n",
       "111                False              False                  False  ...   \n",
       "112                False              False                  False  ...   \n",
       "113                False              False                  False  ...   \n",
       "114                 True              False                  False  ...   \n",
       "115                False              False                  False  ...   \n",
       "116                False              False                  False  ...   \n",
       "117                 True              False                  False  ...   \n",
       "118                False              False                  False  ...   \n",
       "119                False              False                  False  ...   \n",
       "120                False              False                  False  ...   \n",
       "121                False              False                  False  ...   \n",
       "122                 True              False                  False  ...   \n",
       "123                False              False                  False  ...   \n",
       "124                 True              False                  False  ...   \n",
       "125                False              False                  False  ...   \n",
       "126                False              False                  False  ...   \n",
       "127                False              False                  False  ...   \n",
       "128                 True              False                  False  ...   \n",
       "129                False              False                  False  ...   \n",
       "130                 True              False                  False  ...   \n",
       "131                False              False                  False  ...   \n",
       "132                False              False                  False  ...   \n",
       "133                False               True                   True  ...   \n",
       "134                False              False                  False  ...   \n",
       "135                 True              False                  False  ...   \n",
       "136                False              False                  False  ...   \n",
       "137                False              False                  False  ...   \n",
       "138                False              False                  False  ...   \n",
       "139                False              False                  False  ...   \n",
       "140                False              False                  False  ...   \n",
       "141                False               True                   True  ...   \n",
       "142                False              False                  False  ...   \n",
       "143                 True              False                  False  ...   \n",
       "144                False              False                  False  ...   \n",
       "145                False              False                  False  ...   \n",
       "146                False               True                   True  ...   \n",
       "147                False              False                  False  ...   \n",
       "148                 True              False                  False  ...   \n",
       "149                False              False                  False  ...   \n",
       "\n",
       "     col_num_for_PN  page_num_index_pat_match  page_num_coord_match  \\\n",
       "100               0                     False                 False   \n",
       "101               0                     False                 False   \n",
       "102               0                     False                 False   \n",
       "103               0                     False                 False   \n",
       "104               0                     False                 False   \n",
       "105               0                     False                 False   \n",
       "106               0                     False                 False   \n",
       "107               0                     False                 False   \n",
       "108               0                     False                 False   \n",
       "109               0                     False                 False   \n",
       "110               0                     False                 False   \n",
       "111               0                     False                 False   \n",
       "112               0                     False                 False   \n",
       "113               0                     False                 False   \n",
       "114               0                     False                 False   \n",
       "115               0                     False                 False   \n",
       "116               0                     False                 False   \n",
       "117               0                     False                 False   \n",
       "118               0                     False                 False   \n",
       "119               0                     False                 False   \n",
       "120               0                     False                 False   \n",
       "121               0                     False                 False   \n",
       "122               0                     False                 False   \n",
       "123               0                     False                 False   \n",
       "124               0                     False                 False   \n",
       "125               0                     False                 False   \n",
       "126               0                     False                 False   \n",
       "127               0                     False                 False   \n",
       "128               0                     False                 False   \n",
       "129               0                     False                 False   \n",
       "130               0                     False                 False   \n",
       "131               0                     False                 False   \n",
       "132               0                     False                 False   \n",
       "133               0                     False                 False   \n",
       "134               0                     False                 False   \n",
       "135               0                     False                 False   \n",
       "136               0                     False                 False   \n",
       "137               0                     False                 False   \n",
       "138               0                     False                 False   \n",
       "139               0                     False                 False   \n",
       "140               0                     False                 False   \n",
       "141               0                     False                 False   \n",
       "142               0                     False                 False   \n",
       "143               0                     False                 False   \n",
       "144               0                     False                 False   \n",
       "145               0                     False                 False   \n",
       "146               0                     False                 False   \n",
       "147               0                     False                 False   \n",
       "148               0                     False                 False   \n",
       "149               0                     False                 False   \n",
       "\n",
       "     is_hybrid         closest_genus         closest_epithet  \\\n",
       "100      False     Achillea_555_17_0      micrantha_555_25_0   \n",
       "101      False     Achillea_555_17_0      micrantha_555_25_0   \n",
       "102      False     Achillea_555_17_0      micrantha_555_25_0   \n",
       "103      False     Achillea_555_17_0      micrantha_555_25_0   \n",
       "104      False     Achillea_555_17_0        odorata_555_25_1   \n",
       "105      False     Achillea_555_17_0        odorata_555_25_1   \n",
       "106      False     Achillea_555_17_0        odorata_555_25_1   \n",
       "107      False     Achillea_555_17_0        odorata_555_25_1   \n",
       "108      False     Achillea_555_17_0        odorata_555_25_1   \n",
       "109      False     Achillea_555_17_0        odorata_555_25_1   \n",
       "110      False     Achillea_555_17_0        odorata_555_25_1   \n",
       "111      False     Achillea_555_17_0        odorata_555_25_1   \n",
       "112      False     Achillea_555_17_0        odorata_555_25_1   \n",
       "113      False     Achillea_555_17_0        odorata_555_25_1   \n",
       "114      False     Achillea_555_17_0   oligocephala_555_28_0   \n",
       "115      False     Achillea_555_17_0   oligocephala_555_28_0   \n",
       "116      False     Achillea_555_17_0   oligocephala_555_28_0   \n",
       "117      False     Achillea_555_17_0       santohna_555_37_0   \n",
       "118      False     Achillea_555_17_0       santohna_555_37_0   \n",
       "119      False     Achillea_555_17_0       santohna_555_37_0   \n",
       "120      False     Achillea_555_17_0       santohna_555_37_0   \n",
       "121      False     Achillea_555_17_0       santohna_555_37_0   \n",
       "122      False     Achillea_555_17_0      sulphurea_555_37_1   \n",
       "123      False     Achillea_555_17_0      sulphurea_555_37_1   \n",
       "124      False     Achillea_555_17_0    teretifolia_555_37_2   \n",
       "125      False     Achillea_555_17_0    teretifolia_555_37_2   \n",
       "126      False     Achillea_555_17_0    teretifolia_555_37_2   \n",
       "127      False     Achillea_555_17_0    teretifolia_555_37_2   \n",
       "128      False     Achillea_555_17_0      urumoffii_555_38_0   \n",
       "129      False     Achillea_555_17_0      urumoffii_555_38_0   \n",
       "130      False     Achillea_555_17_0     wilhelmsii_555_39_0   \n",
       "131      False     Achillea_555_17_0     wilhelmsii_555_39_0   \n",
       "132      False     Achillea_555_17_0     wilhelmsii_555_39_0   \n",
       "133      False       Acinos_555_40_0                      -1   \n",
       "134      False       Acinos_555_40_0                      -1   \n",
       "135      False       Acinos_555_40_0  rotundifolius_555_41_0   \n",
       "136      False       Acinos_555_40_0  rotundifolius_555_41_0   \n",
       "137      False       Acinos_555_40_0  rotundifolius_555_41_0   \n",
       "138      False       Acinos_555_40_0  rotundifolius_555_41_0   \n",
       "139      False       Acinos_555_40_0  rotundifolius_555_41_0   \n",
       "140      False       Acinos_555_40_0  rotundifolius_555_41_0   \n",
       "141      False  Aetheorhiza_555_42_0                      -1   \n",
       "142      False  Aetheorhiza_555_42_0                      -1   \n",
       "143      False  Aetheorhiza_555_42_0        bulbosa_555_43_0   \n",
       "144      False  Aetheorhiza_555_42_0        bulbosa_555_43_0   \n",
       "145      False  Aetheorhiza_555_42_0        bulbosa_555_43_0   \n",
       "146      False        Ajuga_555_44_0                      -1   \n",
       "147      False        Ajuga_555_44_0                      -1   \n",
       "148      False        Ajuga_555_44_0    chamaepitys_555_45_0   \n",
       "149      False        Ajuga_555_44_0    chamaepitys_555_45_0   \n",
       "\n",
       "     closest_infra_type  closest_infra_name potential_infra_name_match  \\\n",
       "100                  -1                  -1                      False   \n",
       "101                  -1                  -1                      False   \n",
       "102                  -1                  -1                      False   \n",
       "103                  -1                  -1                      False   \n",
       "104                  -1                  -1                      False   \n",
       "105                  -1                  -1                      False   \n",
       "106                  -1                  -1                      False   \n",
       "107     subsp._555_26_0                  -1                      False   \n",
       "108     subsp._555_26_0   kotschyi_555_26_0                       True   \n",
       "109     subsp._555_26_0   kotschyi_555_26_0                      False   \n",
       "110     subsp._555_26_0   kotschyi_555_26_0                      False   \n",
       "111       var._555_27_0                  -1                      False   \n",
       "112       var._555_27_0      grata_555_27_0                       True   \n",
       "113       var._555_27_0      grata_555_27_0                      False   \n",
       "114                  -1                  -1                      False   \n",
       "115                  -1                  -1                      False   \n",
       "116                  -1                  -1                      False   \n",
       "117                  -1                  -1                      False   \n",
       "118                  -1                  -1                      False   \n",
       "119                  -1                  -1                      False   \n",
       "120                  -1                  -1                      False   \n",
       "121                  -1                  -1                      False   \n",
       "122                  -1                  -1                      False   \n",
       "123                  -1                  -1                      False   \n",
       "124                  -1                  -1                      False   \n",
       "125                  -1                  -1                      False   \n",
       "126                  -1                  -1                      False   \n",
       "127                  -1                  -1                      False   \n",
       "128                  -1                  -1                      False   \n",
       "129                  -1                  -1                      False   \n",
       "130                  -1                  -1                      False   \n",
       "131                  -1                  -1                      False   \n",
       "132                  -1                  -1                      False   \n",
       "133                  -1                  -1                      False   \n",
       "134                  -1                  -1                      False   \n",
       "135                  -1                  -1                      False   \n",
       "136                  -1                  -1                      False   \n",
       "137                  -1                  -1                      False   \n",
       "138                  -1                  -1                      False   \n",
       "139                  -1                  -1                      False   \n",
       "140                  -1                  -1                      False   \n",
       "141                  -1                  -1                      False   \n",
       "142                  -1                  -1                      False   \n",
       "143                  -1                  -1                      False   \n",
       "144                  -1                  -1                      False   \n",
       "145                  -1                  -1                      False   \n",
       "146                  -1                  -1                      False   \n",
       "147                  -1                  -1                      False   \n",
       "148                  -1                  -1                      False   \n",
       "149                  -1                  -1                      False   \n",
       "\n",
       "    potential_author_match  \n",
       "100                  False  \n",
       "101                   True  \n",
       "102                   True  \n",
       "103                   True  \n",
       "104                  False  \n",
       "105                   True  \n",
       "106                   True  \n",
       "107                  False  \n",
       "108                  False  \n",
       "109                   True  \n",
       "110                   True  \n",
       "111                  False  \n",
       "112                  False  \n",
       "113                   True  \n",
       "114                  False  \n",
       "115                   True  \n",
       "116                   True  \n",
       "117                  False  \n",
       "118                   True  \n",
       "119                   True  \n",
       "120                   True  \n",
       "121                   True  \n",
       "122                  False  \n",
       "123                   True  \n",
       "124                  False  \n",
       "125                   True  \n",
       "126                   True  \n",
       "127                   True  \n",
       "128                  False  \n",
       "129                   True  \n",
       "130                  False  \n",
       "131                   True  \n",
       "132                   True  \n",
       "133                  False  \n",
       "134                   True  \n",
       "135                  False  \n",
       "136                   True  \n",
       "137                   True  \n",
       "138                   True  \n",
       "139                   True  \n",
       "140                   True  \n",
       "141                  False  \n",
       "142                   True  \n",
       "143                  False  \n",
       "144                   True  \n",
       "145                   True  \n",
       "146                  False  \n",
       "147                   True  \n",
       "148                  False  \n",
       "149                   True  \n",
       "\n",
       "[50 rows x 24 columns]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol3_index_df.iloc[100:150, 20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df.replace(-1, np.NaN, inplace = True)\n",
    "    vol_index_df.replace(np.NaN, \"\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "#author grouping \n",
    "# \n",
    "author_grouping = ['closest_genus', 'closest_epithet', 'closest_infra_name']\n",
    "merge_on = ['closest_genus', 'closest_epithet', 'closest_infra_name']\n",
    "def concatenate(group):\n",
    "    return group.loc[group['potential_author_match'] == True, 'word'].str.cat(sep=' ')\n",
    "\n",
    "result_df_authors = [] \n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]: \n",
    "    #author_grouping = ['closest_genus', 'closest_epithet']\n",
    "    #merge_on = ['closest_genus', 'closest_epithet']\n",
    "    groups = vol_index_df.groupby(author_grouping)\n",
    "    concatenated = groups.apply(concatenate).reset_index()\n",
    "\n",
    "    # add the concatenated values to the original dataframe\n",
    "    result = vol_index_df.merge(concatenated[merge_on + [0]], on=merge_on, how='left').rename(columns={0: 'authors'})\n",
    "    result_df_authors.append(result)\n",
    "    \n",
    "vol1_index_df, vol2_index_df, vol3_index_df = result_df_authors[0], result_df_authors[1], result_df_authors[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "#     #vol_index_df.replace(\"\", np.NaN,inplace = True)\n",
    "#     vol_index_df.replace(np.NaN, \"\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  4.66it/s]\n",
      "100%|██████████| 22/22 [00:04<00:00,  4.68it/s]\n",
      "100%|██████████| 28/28 [00:05<00:00,  4.73it/s]\n"
     ]
    }
   ],
   "source": [
    "all_vol_data_cat_test = [(vol1_index_df, vol1_index, vol1_doc, \"catagorized_vol1\"),\n",
    "                         (vol2_index_df, vol2_index, vol2_doc, \"catagorized_vol2\"),\n",
    "                         (vol3_index_df, vol3_index, vol3_doc, \"catagorized_vol3\")]\n",
    "\n",
    "for vol_char_df, vol_index, doc, output_name in all_vol_data_cat_test: \n",
    "    #for each volume \n",
    "    image_list = []\n",
    "\n",
    "    for page_num in tqdm(vol_index):\n",
    "        pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "        image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        for col_num in [0, 1]:\n",
    "            temp_df = vol_char_df[(vol_char_df['page_num'] == page_num) & (vol_char_df['col_num'] == col_num)]\n",
    "            #genus Coord is orange-pinkish, 5\n",
    "            for name, group in temp_df.groupby(['closest_genus'])['word_bbox']:\n",
    "                x0 = (group.apply(lambda x : x[0]).min())*TARGET_DPI/ 72\n",
    "                y0 = (group.apply(lambda x : x[1]).min())*TARGET_DPI/ 72\n",
    "                x1 = (group.apply(lambda x : x[2]).max())*TARGET_DPI/ 72\n",
    "                y1 = (group.apply(lambda x : x[3]).max())*TARGET_DPI/ 72\n",
    "                draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#6939a3\"), width=3)\n",
    "\n",
    "            for name, group in temp_df.groupby(['closest_epithet'])['word_bbox']:\n",
    "                if name != '':\n",
    "                    x0 = (group.apply(lambda x : x[0]).min())*TARGET_DPI/ 72\n",
    "                    y0 = (group.apply(lambda x : x[1]).min())*TARGET_DPI/ 72\n",
    "                    x1 = (group.apply(lambda x : x[2]).max())*TARGET_DPI/ 72\n",
    "                    y1 = (group.apply(lambda x : x[3]).max())*TARGET_DPI/ 72\n",
    "                    draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#003399\"), width=3)\n",
    "\n",
    "            for name, group in temp_df.groupby(['closest_infra_name'])['word_bbox']:\n",
    "                if name != '':\n",
    "                    x0 = (group.apply(lambda x : x[0]).min())*TARGET_DPI/ 72\n",
    "                    y0 = (group.apply(lambda x : x[1]).min())*TARGET_DPI/ 72\n",
    "                    x1 = (group.apply(lambda x : x[2]).max())*TARGET_DPI/ 72\n",
    "                    y1 = (group.apply(lambda x : x[3]).max())*TARGET_DPI/ 72\n",
    "                    draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#8c690b\"), width=3)\n",
    "\n",
    "            temp_df_author_only = temp_df[temp_df['potential_author_match'] == True]\n",
    "            for name, group in temp_df_author_only.groupby(['closest_genus', 'closest_epithet', 'closest_infra_name'])['word_bbox']:\n",
    "                x0 = (group.apply(lambda x : x[0]).min())*TARGET_DPI/ 72\n",
    "                y0 = (group.apply(lambda x : x[1]).min())*TARGET_DPI/ 72\n",
    "                x1 = (group.apply(lambda x : x[2]).max())*TARGET_DPI/ 72\n",
    "                y1 = (group.apply(lambda x : x[3]).max())*TARGET_DPI/ 72\n",
    "\n",
    "                draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(\"#9e9e9e\"), width=3)\n",
    "\n",
    "\n",
    "        image_list.append(image)\n",
    "\n",
    "    #save pages of the volume\n",
    "    image_list[0].save('../output/local/'+output_name+'.pdf' ,save_all=True, append_images=image_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_words(word):\n",
    "    head, sep, tail = word.partition('_')\n",
    "    return head \n",
    "\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    vol_index_df['closest_genus'] = vol_index_df['closest_genus'].apply(fix_words)\n",
    "    vol_index_df['closest_epithet'] = vol_index_df['closest_epithet'].apply(fix_words)\n",
    "    vol_index_df['closest_infra_type'] = vol_index_df['closest_infra_type'].apply(fix_words)\n",
    "    vol_index_df['closest_infra_name'] = vol_index_df['closest_infra_name'].apply(fix_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_prune_authors_list = []\n",
    "for vol_index_df in [vol1_index_df, vol2_index_df, vol3_index_df]:\n",
    "    result_prune_authors = vol_index_df[(vol_index_df['potential_genus_match'] == True) |\n",
    "                                        (vol_index_df['potential_epithet_match'] == True) |\n",
    "                                        (vol_index_df['potential_infra_name_match'] == True)]\n",
    "    result_prune_authors_list.append(result_prune_authors)\n",
    "\n",
    "prune_authors_vol1, prune_authors_vol2, prune_authors_vol3 =  result_prune_authors_list[0], result_prune_authors_list[1], result_prune_authors_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_vol1 = prune_authors_vol1[['closest_genus',\n",
    "                                      'closest_epithet',\n",
    "                                      'closest_infra_type',\n",
    "                                      'closest_infra_name',\n",
    "                                      'authors']]\n",
    "simplified_vol1.to_csv('../output/local/index_output/vol1_index_output.csv')\n",
    "\n",
    "simplified_vol2 = prune_authors_vol2[['closest_genus',\n",
    "                                      'closest_epithet',\n",
    "                                      'closest_infra_type',\n",
    "                                      'closest_infra_name',\n",
    "                                      'authors']]\n",
    "simplified_vol2.to_csv('../output/local/index_output/vol2_index_output.csv')\n",
    "                                \n",
    "simplified_vol3 = prune_authors_vol3[['closest_genus',\n",
    "                                      'closest_epithet',\n",
    "                                      'closest_infra_type',\n",
    "                                      'closest_infra_name',\n",
    "                                      'authors']]\n",
    "simplified_vol3.to_csv('../output/local/index_output/vol3_index_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_italics_simplified_vol1 = prune_authors_vol1.loc[(prune_authors_vol1['span_flags'] != 6),\n",
    "                                                     ['closest_genus',\n",
    "                                                      'closest_epithet',\n",
    "                                                      'closest_infra_type',\n",
    "                                                      'closest_infra_name',\n",
    "                                                      'authors']]\n",
    "non_italics_simplified_vol1.to_csv('../output/local/index_output/vol1_nonitalics.csv')\n",
    "\n",
    "non_italics_simplified_vol2 = prune_authors_vol2.loc[(prune_authors_vol2['span_flags'] != 6),\n",
    "                                                     ['closest_genus',\n",
    "                                                      'closest_epithet',\n",
    "                                                      'closest_infra_type',\n",
    "                                                      'closest_infra_name',\n",
    "                                                      'authors']]\n",
    "non_italics_simplified_vol2.to_csv('../output/local/index_output/vol2_nonitalics.csv')\n",
    "\n",
    "non_italics_simplified_vol3 = prune_authors_vol3.loc[(prune_authors_vol3['span_flags'] != 6),\n",
    "                                                     ['closest_genus',\n",
    "                                                      'closest_epithet',\n",
    "                                                      'closest_infra_type',\n",
    "                                                      'closest_infra_name',\n",
    "                                                      'authors']]\n",
    "non_italics_simplified_vol3.to_csv('../output/local/index_output/vol3_nonitalics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
